
R version 4.4.1 (2024-06-14) -- "Race for Your Life"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # tarfile <- "clonal_analysis_PCAWG.tar.gz"
> # data <- read.delim(file = untar(tarfile,compressed="gzip"),sep="\t")
> .libPaths(new="~/R/rstudio_v3/") 
> library(tickTack)
Warning message:
package ‘tickTack’ was built under R version 4.4.2 
> 
> 
> set.seed(seed=123)
> spath <-  "../../data"
> sfile <-  "clonal_analysis_PCAWG.tar.gz"
> 
> outputdir <- "../../data"
> data <- untar(file.path(spath,sfile), exdir = outputdir)
> 
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> # Rename columns from list
> # setNames(old = c(cna), 
> #          new = c(segments))
> # fit <- fit %>% mutate(segments = fit$cna)
> 
> library(tibble)
> 
> tolerance = 0.0001
> iter = 200
> grad_samples = 10
> elbo_samples = 100
> # samples_metadata <- readRDS("./samples_info.rds")
> # load data
> 
> vector_names <- list.files("../../data/clonal_analysis_PCAWG/")
> 
> 
> # s <- vector_names[1]
> 
> 
> lapply(vector_names, function(s){
+   
+   tryCatch({
+   
+   fit <- readRDS(paste0("../../data/clonal_analysis_PCAWG/",s,"/fit.rds"))
+   original_dir <- getwd()
+   
+   
+   dir.create(file.path(original_dir, paste0("results_tickTack/",s)), showWarnings = FALSE)
+   new_dir = paste0(original_dir, paste0("/results_tickTack/",s))
+   dir.create(file.path(new_dir, paste0("results")), showWarnings = FALSE)
+   dir.create(file.path(new_dir, paste0("plots")), showWarnings = FALSE)
+   
+   
+   x <- list( mutations = tibble(chr = fit$snvs$chr, 
+                                 from = fit$snvs$from, 
+                                 to = fit$snvs$to, 
+                                 ref = fit$snvs$ref, 
+                                 alt = fit$snvs$alt, 
+                                 DP = fit$snvs$DP, 
+                                 NV = fit$snvs$NV, 
+                                 VAF = fit$snvs$NV/fit$snvs$DP, 
+                                 sample = 1), 
+              cna = tibble(chr = fit$cna$chr, 
+                           from = fit$cna$from, 
+                           to = fit$cna$to, 
+                           Major = fit$cna$Major, 
+                           minor = fit$cna$minor,   
+                           CCF = 0, 
+                           total_cn = Major + minor), 
+              metadata = tibble(purity = fit$purity) 
+   )
+   
+   
+   data <- x
+   
+   x <- tickTack::fit_h(x, 
+                        max_attempts=2, 
+                        INIT=TRUE, 
+                        tolerance = tolerance,
+                        initial_iter = iter,
+                        grad_samples=grad_samples,
+                        elbo_samples=elbo_samples)
+   
+   
+   
+   results <- x$results_timing
+   saveRDS(x, paste0(new_dir,"/results/x_after_inference.rds"))
+   
+   results_model_selection <- tickTack::model_selection_h(results, n_components = 0)
+   saveRDS(results_model_selection, paste0(new_dir,"/results/results_model_selection.rds"))
+   
+   best_K <- results_model_selection$best_K
+   model_selection_tibble <- results_model_selection$model_selection_tibble
+   entropy <- results_model_selection$entropy_list
+   
+   # posterior_clocks <- tickTack::plot_posterior_clocks_h(results, 2)
+   # posterior_weights <- tickTack::plot_posterior_weights_h(results, 2)
+   
+   K = nrow(results_model_selection$model_selection_tibble)
+   
+   p_elbo <- list()
+   for (i in 1:K){
+     p_elbo[[i]] <- tickTack::plot_elbo_h(results$elbo_iterations[[i]]) + ggplot2::ggtitle(paste0("K = ", i))
+   }
+   p_elbo <- gridExtra::grid.arrange(grobs = p_elbo, ncol = 2)  #add global title
+   ggplot2::ggsave(paste0(new_dir,"/plots/plot_elbo.png"),plot = p_elbo, width = 30, height = 30)
+   
+   
+   library(dplyr)
+   library(ggplot2)
+   p <- tickTack::plot_timing_h(results, best_K)
+   ggsave(paste0(new_dir,"/plots/plot_timing_h.png"),plot = p, width = 25, height = 5)
+   
+   print(results$draws_and_summary[[best_K]]$summarized_results, n = nrow(results$draws_and_summary[[best_K]]$summarized_results))
+   print(results_model_selection$model_selection_tibble)
+   
+   
+   plot_model_selection_inference <- list()
+   for (i in 1:K){
+     plot_model_selection_inference[[i]] <- tickTack::plot_timing_h(results, i) + ggplot2::ggtitle(paste0("K = ", i))
+   }
+   plot_model_selection_inference <- gridExtra::grid.arrange(grobs = plot_model_selection_inference, nrow = K) #add global title
+   ggsave(paste0(new_dir,"/plots/plot_timing_all_K_h.png"),plot = plot_model_selection_inference, width = 25, height = 30)
+   
+   
+   
+   
+   # Single segment inference # Single segment inference # Single segment inference 
+   segments <- data$cna
+   mutations <- data$mutations
+   purity <- data$metadata$purity
+   
+   # Run the fit function
+   results_single <- fit(
+     segments = segments,
+     mutations = mutations,
+     purity = purity,
+     possible_k = c("2:1", "2:2", "2:0"),
+     beta_binomial = TRUE
+   )
+   
+   saveRDS(results_single, paste0(new_dir, "/results/results_single.rds"))
+   
+   
+   print(results_single$summarized_results, n= nrow(results_single$summarized_results) )
+   
+   p <- tickTack::plot_timing(results_single, segments, colour_by = "karyotype")
+   ggsave(paste0(new_dir,"/plots/plot_timing.png"),plot = p, , width = 25, height = 5)
+   
+   
+   # mtationtimer inference 
+   
+   }, error = function(e) {
+     message(sprintf("Error processing %s: %s", s, e$message))
+     NULL  # Return NULL if there is an error
+   })
+   
+   
+ } )
[1] 1
ℹ Adding segment with index 1 to segments included in the inference.
[1] 2
ℹ Adding segment with index 2 to segments included in the inference.
[1] 3
[1] 4
[1] 5
ℹ Adding segment with index 5 to segments included in the inference.
[1] 6
[1] 7
ℹ Adding segment with index 7 to segments included in the inference.
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
ℹ Adding segment with index 12 to segments included in the inference.
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
ℹ Adding segment with index 37 to segments included in the inference.
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
ℹ Adding segment with index 43 to segments included in the inference.
[1] 44
[1] 45
ℹ Adding segment with index 45 to segments included in the inference.
[1] 46
[1] 47
ℹ Adding segment with index 47 to segments included in the inference.
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
ℹ Adding segment with index 58 to segments included in the inference.
[1] 59
[1] 60
[1] 61
[1] 62
ℹ Adding segment with index 62 to segments included in the inference.
[1] 63
[1] 64
ℹ Adding segment with index 64 to segments included in the inference.
[1] 65
[1] 66
ℹ Adding segment with index 66 to segments included in the inference.
[1] 67
ℹ Adding segment with index 67 to segments included in the inference.
[1] 68
ℹ Adding segment with index 68 to segments included in the inference.
[1] 69
ℹ Adding segment with index 69 to segments included in the inference.
[1] 70
ℹ Adding segment with index 70 to segments included in the inference.
[1] 71
[1] 72
ℹ Adding segment with index 72 to segments included in the inference.
[1] 73
[1] 74
ℹ Adding segment with index 74 to segments included in the inference.
[1] 75
[1] 76
ℹ Adding segment with index 76 to segments included in the inference.
[1] 77
ℹ Adding segment with index 77 to segments included in the inference.
[1] 78
[1] 79
[1] 80
[1] 81
ℹ Adding segment with index 81 to segments included in the inference.
[1] 82
[1] 83
ℹ Adding segment with index 83 to segments included in the inference.
[1] 84
[1] 85
ℹ Adding segment with index 85 to segments included in the inference.
[1] 86
[1] 87
ℹ Adding segment with index 87 to segments included in the inference.
[1] 88
ℹ Adding segment with index 88 to segments included in the inference.
[1] 89
[1] 90
[1] 91
[1] 92
ℹ Adding segment with index 92 to segments included in the inference.
[1] 93
[1] 94
ℹ Adding segment with index 94 to segments included in the inference.
[1] 95
ℹ Adding segment with index 95 to segments included in the inference.
[1] 96
[1] 97
ℹ Adding segment with index 97 to segments included in the inference.
[1] 98
ℹ Adding segment with index 98 to segments included in the inference.
[1] 99
[1] 100
ℹ Adding segment with index 100 to segments included in the inference.
[1] 101
[1] 102
[1] 103
[1] 104
[1] 105
[1] 106
[1] 107
ℹ Adding segment with index 107 to segments included in the inference.
[1] 108
ℹ Adding segment with index 108 to segments included in the inference.
[1] 109
ℹ Adding segment with index 109 to segments included in the inference.
[1] 110
[1] 111
ℹ Adding segment with index 111 to segments included in the inference.
[1] 112
[1] 113
[1] 114
[1] 115
[1] 116
[1] 117
[1] 118
[1] 119
[1] 120
[1] 121
[1] 122
[1] 123
[1] 124
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
[1] 130
[1] 131
[1] 132
[1] 133
[1] 134
[1] 135
[1] 136
[1] 137
[1] 138
[1] 139
ℹ Adding segment with index 139 to segments included in the inference.
[1] 140
[1] 141
[1] 142
[1] 143
ℹ Adding segment with index 143 to segments included in the inference.
[1] 144
[1] 145
ℹ Adding segment with index 145 to segments included in the inference.
[1] 146
[1] 147
ℹ Adding segment with index 147 to segments included in the inference.
[1] 148
ℹ Adding segment with index 148 to segments included in the inference.
[1] 149
ℹ Adding segment with index 149 to segments included in the inference.
[1] 150
[1] 151
[1] 152
[1] 153
[1] 154
[1] 155
[1] 156
[1] 157
[1] 158
[1] 159
[1] 160
[1] 161
[1] 162
[1] 163
[1] 164
[1] 165
[1] 166
[1] 167
[1] 168
[1] 169
[1] 170
[1] 171
[1] 172
[1] 173
[1] 174
[1] 175
[1] 176
ℹ Adding segment with index 176 to segments included in the inference.
[1] 177
[1] 178
ℹ Adding segment with index 178 to segments included in the inference.
[1] 179
[1] 180
ℹ Adding segment with index 180 to segments included in the inference.
[1] 181
[1] 182
[1] 183
[1] 184
[1] 185
[1] 186
[1] 187
[1] 188
ℹ Adding segment with index 188 to segments included in the inference.
[1] 189
ℹ Adding segment with index 189 to segments included in the inference.
[1] 190
[1] 191
[1] 192
[1] 193
[1] 194
[1] 195
[1] 196
[1] 197
[1] 198
[1] 199
[1] 200
[1] 201
[1] 202
[1] 203
[1] 204
[1] 205
[1] 206
[1] 207
[1] 208
[1] 209
[1] 210
[1] 211
[1] 212
[1] 213
[1] 214
[1] 215
[1] 216
[1] 217
[1] 218
[1] 219
[1] 220
[1] 221
[1] 222
[1] 223
[1] 224
[1] 225
[1] 226
[1] 227
[1] 228
[1] 229
[1] 230
[1] 231
[1] 232
[1] 233
[1] 234
[1] 235
[1] 236
[1] 237
[1] 238
[1] 239
[1] 240
[1] 241
[1] 242
[1] 243
[1] 244
[1] 245
[1] 246
ℹ Adding segment with index 246 to segments included in the inference.
[1] 247
[1] 248
[1] 249
[1] 250
[1] 251
[1] 252
[1] 253
[1] 254
[1] 255
[1] 256
[1] 257
[1] 258
ℹ Adding segment with index 258 to segments included in the inference.
[1] 259
ℹ Adding segment with index 259 to segments included in the inference.
[1] 260
ℹ Adding segment with index 260 to segments included in the inference.
[1] 261
[1] 262
ℹ Adding segment with index 262 to segments included in the inference.
[1] 263
ℹ Adding segment with index 263 to segments included in the inference.
[1] 264
[1] 265
ℹ Adding segment with index 265 to segments included in the inference.
[1] 266
[1] 267
ℹ Adding segment with index 267 to segments included in the inference.
[1] 268
ℹ Adding segment with index 268 to segments included in the inference.
[1] 269
ℹ Adding segment with index 269 to segments included in the inference.
[1] 270
[1] 271
ℹ Adding segment with index 271 to segments included in the inference.
[1] 272
[1] 273
ℹ Adding segment with index 273 to segments included in the inference.
[1] 274
[1] 275
ℹ Adding segment with index 275 to segments included in the inference.
[1] 276
[1] 277
ℹ Adding segment with index 277 to segments included in the inference.
[1] 278
ℹ Adding segment with index 278 to segments included in the inference.
[1] 279
[1] 280
ℹ Adding segment with index 280 to segments included in the inference.
[1] 281
[1] 282
[1] 283
ℹ Adding segment with index 283 to segments included in the inference.
[1] 284
[1] 285
ℹ Adding segment with index 285 to segments included in the inference.
[1] 286
[1] 287
ℹ Adding segment with index 287 to segments included in the inference.
[1] 288
[1] 289
[1] 290
[1] 291
[1] 292
[1] 293
[1] 294
[1] 295
[1] 296
[1] 297
[1] 298
[1] 299
[1] 300
[1] 301
[1] 302
[1] 303
[1] 304
[1] 305
[1] 306
[1] 307
[1] 308
[1] 309
[1] 310
[1] 311
[1] 312
[1] 313
[1] 314
[1] 315
[1] 316
[1] 317
[1] 318
ℹ Adding segment with index 318 to segments included in the inference.
[1] 319
ℹ Adding segment with index 319 to segments included in the inference.
[1] 320
[1] 321
ℹ Adding segment with index 321 to segments included in the inference.
[1] 322
[1] 323
ℹ Adding segment with index 323 to segments included in the inference.
[1] 324
[1] 325
[1] 326
ℹ Adding segment with index 326 to segments included in the inference.
[1] 327
[1] 328
ℹ Adding segment with index 328 to segments included in the inference.
[1] 329
ℹ Adding segment with index 329 to segments included in the inference.
[1] 330
[1] 331
ℹ Adding segment with index 331 to segments included in the inference.
[1] 332
ℹ Adding segment with index 332 to segments included in the inference.
[1] 333
ℹ Adding segment with index 333 to segments included in the inference.
[1] 334
ℹ Adding segment with index 334 to segments included in the inference.
[1] 335
[1] 336
ℹ Adding segment with index 336 to segments included in the inference.
[1] 337
ℹ Adding segment with index 337 to segments included in the inference.
[1] 338
[1] 339
ℹ Adding segment with index 339 to segments included in the inference.
[1] 340
[1] 341
[1] 342
[1] 343
[1] 344
ℹ Adding segment with index 344 to segments included in the inference.
[1] 345
ℹ Adding segment with index 345 to segments included in the inference.
[1] 346
[1] 347
ℹ Adding segment with index 347 to segments included in the inference.
[1] 348
[1] 349
ℹ Adding segment with index 349 to segments included in the inference.
[1] 350
ℹ Adding segment with index 350 to segments included in the inference.
[1] 351
[1] 352
[1] 353
[1] 354
[1] 355
ℹ Adding segment with index 355 to segments included in the inference.
[1] 356
[1] 357
[1] 358
[1] 359
[1] 360
[1] 361
[1] 362
[1] 363
[1] 364
ℹ Adding segment with index 364 to segments included in the inference.
[1] 365
[1] 366
ℹ Adding segment with index 366 to segments included in the inference.
[1] 367
[1] 368
[1] 369
[1] 370
ℹ Adding segment with index 370 to segments included in the inference.
[1] 371
[1] 372
[1] 373
[1] 374
[1] 375
[1] 376
[1] 377
[1] 378
[1] 379
[1] 380
[1] 381
[1] 382
[1] 383
[1] 384
[1] 385
[1] 386
[1] 387
[1] 388
[1] 389
[1] 390
[1] 391
ℹ Adding segment with index 391 to segments included in the inference.
[1] 392
[1] 393
[1] 394
[1] 395
[1] 396
[1] 397
[1] 398
[1] 399
[1] 400
[1] 401
[1] 402
[1] 403
ℹ Adding segment with index 403 to segments included in the inference.
[1] 404
[1] 405
[1] 406
[1] 407
[1] 408
[1] 409
[1] 410
[1] 411
[1] 412
[1] 413
[1] 414
[1] 415
[1] 416
[1] 417
[1] 418
[1] 419
ℹ Adding segment with index 419 to segments included in the inference.
[1] 420
[1] 421
ℹ Adding segment with index 421 to segments included in the inference.
[1] 422
[1] 423
[1] 424
[1] 425
[1] 426
[1] 427
ℹ Adding segment with index 427 to segments included in the inference.
[1] 428
ℹ Adding segment with index 428 to segments included in the inference.
[1] 429
[1] 430
ℹ Adding segment with index 430 to segments included in the inference.
[1] 431
[1] 432
[1] 433
ℹ Adding segment with index 433 to segments included in the inference.
[1] 434
[1] 435
[1] 436
[1] 437
[1] 438
[1] 439
[1] 440
[1] 441
[1] 442
[1] 443
[1] 444
[1] 445
[1] 446
[1] 447
[1] 448
[1] 449
ℹ Adding segment with index 449 to segments included in the inference.
[1] 450
[1] 451
[1] 452
[1] 453
[1] 454
[1] 455
[1] 456
[1] 457
[1] 458
[1] 459
[1] 460
[1] 461
[1] 462
[1] 463
[1] 464
ℹ Adding segment with index 464 to segments included in the inference.
[1] 465
[1] 466
ℹ Adding segment with index 466 to segments included in the inference.
[1] 467
ℹ Adding segment with index 467 to segments included in the inference.
[1] 468
[1] 469
ℹ Adding segment with index 469 to segments included in the inference.
[1] 470
ℹ Adding segment with index 470 to segments included in the inference.
[1] 471
[1] 472
[1] 473
[1] 474
[1] 475
[1] 476
[1] 477
[1] 478
[1] 479
[1] 480
[1] 481
[1] 482
[1] 483
[1] 484
[1] 485
init_taus from clustering  0.221400507867258Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.003274 seconds 
1000 transitions using 10 leapfrog steps per transition would take 32.74 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -9093.823             1.000            1.000 
     2        -9223.889             0.507            1.000 
     3        -9056.007             0.344            0.019 
     4        -9017.629             0.259            0.019 
     5        -9019.186             0.207            0.014 
     6        -9014.840             0.173            0.014 
     7        -9013.797             0.148            0.004 
     8        -9014.290             0.130            0.004 
     9        -9014.037             0.115            0.000 
    10        -9018.577             0.104            0.001 
    11        -9013.321             0.094            0.001 
    12        -9012.590             0.087            0.001 
    13        -9014.136             0.080            0.000 
    14        -9012.287             0.074            0.000 
    15        -9011.287             0.069            0.000 
    16        -9012.682             0.065            0.000 
    17        -9011.465             0.061            0.000 
    18        -9011.142             0.058            0.000 
    19        -9010.887             0.055            0.000 
    20        -9011.368             0.052            0.000 
    21        -9010.149             0.002            0.000 
    22        -9011.189             0.001            0.000 
    23        -9010.771             0.000            0.000 
    24        -9013.053             0.000            0.000 
    25        -9010.097             0.000            0.000 
    26        -9011.444             0.000            0.000 
    27        -9012.635             0.000            0.000 
    28        -9012.929             0.000            0.000 
    29        -9011.064             0.000            0.000 
    30        -9009.621             0.000            0.000 
    31        -9009.374             0.000            0.000 
    32        -9009.173             0.000            0.000 
    33        -9010.344             0.000            0.000 
    34        -9008.743             0.000            0.000 
    35        -9013.809             0.000            0.000 
    36        -9010.054             0.000            0.000 
    37        -9011.519             0.000            0.000 
    38        -9010.276             0.000            0.000 
    39        -9009.461             0.000            0.000 
    40        -9010.580             0.000            0.000 
    41        -9010.448             0.000            0.000 
    42        -9009.366             0.000            0.000 
    43        -9010.357             0.000            0.000 
    44        -9009.150             0.000            0.000 
    45        -9009.202             0.000            0.000 
    46        -9008.352             0.000            0.000 
    47        -9009.490             0.000            0.000 
    48        -9010.378             0.000            0.000 
    49        -9009.657             0.000            0.000 
    50        -9008.786             0.000            0.000 
    51        -9008.070             0.000            0.000 
    52        -9009.623             0.000            0.000 
    53        -9008.424             0.000            0.000 
    54        -9008.554             0.000            0.000 
    55        -9008.883             0.000            0.000 
    56        -9011.019             0.000            0.000 
    57        -9008.456             0.000            0.000 
    58        -9008.641             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  12.7 seconds.
[[1]]
[[1]]$w
       [,1]
  [1,]    1
  [2,]    1
  [3,]    1
  [4,]    1
  [5,]    1
  [6,]    1
  [7,]    1
  [8,]    1
  [9,]    1
 [10,]    1
 [11,]    1
 [12,]    1
 [13,]    1
 [14,]    1
 [15,]    1
 [16,]    1
 [17,]    1
 [18,]    1
 [19,]    1
 [20,]    1
 [21,]    1
 [22,]    1
 [23,]    1
 [24,]    1
 [25,]    1
 [26,]    1
 [27,]    1
 [28,]    1
 [29,]    1
 [30,]    1
 [31,]    1
 [32,]    1
 [33,]    1
 [34,]    1
 [35,]    1
 [36,]    1
 [37,]    1
 [38,]    1
 [39,]    1
 [40,]    1
 [41,]    1
 [42,]    1
 [43,]    1
 [44,]    1
 [45,]    1
 [46,]    1
 [47,]    1
 [48,]    1
 [49,]    1
 [50,]    1
 [51,]    1
 [52,]    1
 [53,]    1
 [54,]    1
 [55,]    1
 [56,]    1
 [57,]    1
 [58,]    1
 [59,]    1
 [60,]    1
 [61,]    1
 [62,]    1
 [63,]    1
 [64,]    1
 [65,]    1
 [66,]    1
 [67,]    1
 [68,]    1
 [69,]    1
 [70,]    1
 [71,]    1
 [72,]    1
 [73,]    1
 [74,]    1
 [75,]    1
 [76,]    1
 [77,]    1
 [78,]    1
 [79,]    1
 [80,]    1
 [81,]    1
 [82,]    1
 [83,]    1
 [84,]    1
 [85,]    1
 [86,]    1
 [87,]    1
 [88,]    1
 [89,]    1
 [90,]    1
 [91,]    1
 [92,]    1
 [93,]    1
 [94,]    1
 [95,]    1
 [96,]    1
 [97,]    1
 [98,]    1
 [99,]    1
[100,]    1
[101,]    1
[102,]    1
[103,]    1

[[1]]$tau
[1] 0.2214005

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -9056.01
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.003248 seconds 
1000 transitions using 10 leapfrog steps per transition would take 32.48 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -9081.960             1.000            1.000 
     2        -9081.082             0.500            1.000 
     3        -9015.054             0.336            0.007 
     4        -9015.029             0.252            0.007 
     5        -9013.627             0.202            0.000 
     6        -9012.601             0.168            0.000 
     7        -9013.588             0.144            0.000 
     8        -9010.811             0.126            0.000 
     9        -9010.562             0.112            0.000 
    10        -9014.414             0.101            0.000 
    11        -9009.502             0.092            0.000 
    12        -9010.999             0.084            0.000 
    13        -9010.102             0.078            0.000 
    14        -9010.128             0.072            0.000 
    15        -9010.041             0.067            0.000 
    16        -9010.650             0.063            0.000 
    17        -9009.640             0.059            0.000 
    18        -9010.362             0.056            0.000 
    19        -9010.085             0.053            0.000 
    20        -9008.331             0.050            0.000 
    21        -9009.802             0.001            0.000 
    22        -9008.805             0.001            0.000 
    23        -9008.434             0.000            0.000 
    24        -9008.577             0.000            0.000 
    25        -9008.454             0.000            0.000 
    26        -9008.768             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  9.1 seconds.
[[1]]
[[1]]$w
       [,1]
  [1,]    1
  [2,]    1
  [3,]    1
  [4,]    1
  [5,]    1
  [6,]    1
  [7,]    1
  [8,]    1
  [9,]    1
 [10,]    1
 [11,]    1
 [12,]    1
 [13,]    1
 [14,]    1
 [15,]    1
 [16,]    1
 [17,]    1
 [18,]    1
 [19,]    1
 [20,]    1
 [21,]    1
 [22,]    1
 [23,]    1
 [24,]    1
 [25,]    1
 [26,]    1
 [27,]    1
 [28,]    1
 [29,]    1
 [30,]    1
 [31,]    1
 [32,]    1
 [33,]    1
 [34,]    1
 [35,]    1
 [36,]    1
 [37,]    1
 [38,]    1
 [39,]    1
 [40,]    1
 [41,]    1
 [42,]    1
 [43,]    1
 [44,]    1
 [45,]    1
 [46,]    1
 [47,]    1
 [48,]    1
 [49,]    1
 [50,]    1
 [51,]    1
 [52,]    1
 [53,]    1
 [54,]    1
 [55,]    1
 [56,]    1
 [57,]    1
 [58,]    1
 [59,]    1
 [60,]    1
 [61,]    1
 [62,]    1
 [63,]    1
 [64,]    1
 [65,]    1
 [66,]    1
 [67,]    1
 [68,]    1
 [69,]    1
 [70,]    1
 [71,]    1
 [72,]    1
 [73,]    1
 [74,]    1
 [75,]    1
 [76,]    1
 [77,]    1
 [78,]    1
 [79,]    1
 [80,]    1
 [81,]    1
 [82,]    1
 [83,]    1
 [84,]    1
 [85,]    1
 [86,]    1
 [87,]    1
 [88,]    1
 [89,]    1
 [90,]    1
 [91,]    1
 [92,]    1
 [93,]    1
 [94,]    1
 [95,]    1
 [96,]    1
 [97,]    1
 [98,]    1
 [99,]    1
[100,]    1
[101,]    1
[102,]    1
[103,]    1

[[1]]$tau
[1] 0.1655469

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -9015.05
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181910-1-a2c01a.csv\n"
init_taus from clustering  0.424561664401253 init_taus from clustering  0.106879698030301Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.005676 seconds 
1000 transitions using 10 leapfrog steps per transition would take 56.76 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -9193.953             1.000            1.000 
     2        -9136.188             0.503            1.000 
     3        -9165.134             0.336            0.006 
     4        -9084.988             0.255            0.009 
     5        -9069.603             0.204            0.006 
     6        -9059.400             0.170            0.006 
     7        -9056.357             0.146            0.003 
     8        -9050.453             0.128            0.003 
     9        -9052.192             0.114            0.002 
    10        -9048.769             0.102            0.002 
    11        -9047.664             0.093            0.001 
    12        -9042.783             0.085            0.001 
    13        -9044.117             0.079            0.001 
    14        -9044.686             0.073            0.001 
    15        -9040.794             0.068            0.001 
    16        -9039.950             0.064            0.001 
    17        -9039.445             0.060            0.000 
    18        -9039.858             0.057            0.000 
    19        -9038.312             0.054            0.000 
    20        -9039.042             0.051            0.000 
    21        -9038.107             0.001            0.000 
    22        -9037.839             0.001            0.000 
    23        -9035.089             0.001            0.000 
    24        -9034.951             0.000            0.000 
    25        -9034.591             0.000            0.000 
    26        -9032.567             0.000            0.000 
    27        -9032.916             0.000            0.000 
    28        -9031.233             0.000            0.000 
    29        -9032.933             0.000            0.000 
    30        -9032.019             0.000            0.000 
    31        -9030.924             0.000            0.000 
    32        -9031.141             0.000            0.000 
    33        -9031.274             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  39.6 seconds.
[[1]]
[[1]]$w
               [,1]        [,2]
  [1,] 4.602043e-01 0.539795695
  [2,] 9.220886e-01 0.077911432
  [3,] 7.475411e-01 0.252458946
  [4,] 5.952799e-02 0.940472007
  [5,] 5.952799e-02 0.940472007
  [6,] 7.872073e-01 0.212792742
  [7,] 5.952799e-02 0.940472007
  [8,] 2.644046e-01 0.735595354
  [9,] 9.292452e-01 0.070754760
 [10,] 7.390301e-03 0.992609699
 [11,] 5.952799e-02 0.940472007
 [12,] 5.539613e-01 0.446038660
 [13,] 2.554893e-02 0.974451071
 [14,] 4.286624e-02 0.957133755
 [15,] 7.715096e-01 0.228490362
 [16,] 8.423271e-01 0.157672919
 [17,] 5.952799e-02 0.940472007
 [18,] 2.460030e-01 0.753996964
 [19,] 7.774258e-01 0.222574245
 [20,] 2.721142e-01 0.727885828
 [21,] 6.719213e-02 0.932807868
 [22,] 5.952799e-02 0.940472007
 [23,] 8.423271e-01 0.157672919
 [24,] 8.750789e-02 0.912492106
 [25,] 1.360623e-01 0.863937661
 [26,] 9.929875e-01 0.007012532
 [27,] 5.294056e-01 0.470594435
 [28,] 8.390422e-03 0.991609578
 [29,] 1.999432e-02 0.980005685
 [30,] 5.952799e-02 0.940472007
 [31,] 5.952799e-02 0.940472007
 [32,] 5.952799e-02 0.940472007
 [33,] 8.423271e-01 0.157672919
 [34,] 5.067540e-01 0.493246004
 [35,] 4.028108e-01 0.597189239
 [36,] 2.166490e-01 0.783351030
 [37,] 8.390422e-03 0.991609578
 [38,] 1.906391e-01 0.809360907
 [39,] 9.643358e-01 0.035664243
 [40,] 4.028108e-01 0.597189239
 [41,] 5.952799e-02 0.940472007
 [42,] 3.430203e-01 0.656979688
 [43,] 1.770341e-04 0.999822966
 [44,] 7.568124e-01 0.243187555
 [45,] 9.842503e-01 0.015749656
 [46,] 5.952799e-02 0.940472007
 [47,] 5.952799e-02 0.940472007
 [48,] 2.953533e-02 0.970464670
 [49,] 8.698461e-03 0.991301539
 [50,] 8.423271e-01 0.157672919
 [51,] 2.081057e-02 0.979189430
 [52,] 5.952799e-02 0.940472007
 [53,] 3.160248e-01 0.683975217
 [54,] 8.607059e-01 0.139294081
 [55,] 1.360623e-01 0.863937661
 [56,] 5.952799e-02 0.940472007
 [57,] 1.479467e-02 0.985205330
 [58,] 5.643503e-01 0.435649687
 [59,] 1.018350e-04 0.999898165
 [60,] 9.999911e-05 0.999900001
 [61,] 5.448021e-01 0.455197858
 [62,] 1.351611e-01 0.864838948
 [63,] 8.423271e-01 0.157672919
 [64,] 2.644046e-01 0.735595354
 [65,] 4.486747e-02 0.955132532
 [66,] 1.906391e-01 0.809360907
 [67,] 5.952799e-02 0.940472007
 [68,] 3.512926e-03 0.996487074
 [69,] 2.633002e-02 0.973669980
 [70,] 1.312444e-03 0.998687556
 [71,] 8.046236e-03 0.991953764
 [72,] 2.076238e-01 0.792376183
 [73,] 5.139753e-02 0.948602467
 [74,] 3.402147e-02 0.965978534
 [75,] 5.952799e-02 0.940472007
 [76,] 9.643358e-01 0.035664243
 [77,] 1.124410e-02 0.988755899
 [78,] 7.827920e-03 0.992172080
 [79,] 6.148075e-02 0.938519247
 [80,] 4.028108e-01 0.597189239
 [81,] 9.797495e-01 0.020250460
 [82,] 5.952799e-02 0.940472007
 [83,] 1.473445e-01 0.852655499
 [84,] 3.007320e-01 0.699268006
 [85,] 9.929875e-01 0.007012532
 [86,] 5.952799e-02 0.940472007
 [87,] 9.840935e-01 0.015906477
 [88,] 5.952799e-02 0.940472007
 [89,] 9.929875e-01 0.007012532
 [90,] 8.607059e-01 0.139294081
 [91,] 5.952799e-02 0.940472007
 [92,] 5.952799e-02 0.940472007
 [93,] 8.423271e-01 0.157672919
 [94,] 3.910570e-02 0.960894300
 [95,] 4.028108e-01 0.597189239
 [96,] 5.067540e-01 0.493246004
 [97,] 7.475411e-01 0.252458946
 [98,] 9.924809e-01 0.007519149
 [99,] 8.423271e-01 0.157672919
[100,] 8.607059e-01 0.139294081
[101,] 9.964152e-01 0.003584806
[102,] 9.468195e-01 0.053180537
[103,] 8.607059e-01 0.139294081

[[1]]$tau
[1] 0.4245617 0.1068797

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -9165.13
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.006625 seconds 
1000 transitions using 10 leapfrog steps per transition would take 66.25 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -9166.727             1.000            1.000 
     2        -9094.442             0.504            1.000 
     3        -9082.990             0.336            0.008 
     4        -9070.755             0.253            0.008 
     5        -9064.575             0.202            0.001 
     6        -9062.792             0.169            0.001 
     7        -9059.884             0.145            0.001 
     8        -9057.400             0.127            0.001 
     9        -9052.225             0.113            0.001 
    10        -9051.925             0.101            0.001 
    11        -9048.280             0.092            0.001 
    12        -9045.507             0.084            0.001 
    13        -9042.996             0.078            0.000 
    14        -9043.720             0.072            0.000 
    15        -9039.885             0.068            0.000 
    16        -9040.514             0.063            0.000 
    17        -9039.151             0.060            0.000 
    18        -9038.470             0.056            0.000 
    19        -9034.614             0.053            0.000 
    20        -9038.288             0.051            0.000 
    21        -9039.262             0.001            0.000 
    22        -9036.661             0.000            0.000 
    23        -9037.678             0.000            0.000 
    24        -9034.510             0.000            0.000 
    25        -9034.549             0.000            0.000 
    26        -9035.657             0.000            0.000 
    27        -9032.380             0.000            0.000 
    28        -9032.776             0.000            0.000 
    29        -9032.717             0.000            0.000 
    30        -9032.172             0.000            0.000 
    31        -9031.511             0.000            0.000 
    32        -9029.889             0.000            0.000 
    33        -9030.529             0.000            0.000 
    34        -9033.375             0.000            0.000 
    35        -9030.524             0.000            0.000 
    36        -9030.802             0.000            0.000 
    37        -9029.380             0.000            0.000 
    38        -9028.137             0.000            0.000 
    39        -9027.401             0.000            0.000 
    40        -9027.666             0.000            0.000 
    41        -9026.890             0.000            0.000 
    42        -9027.740             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  41.3 seconds.
[[1]]
[[1]]$w
               [,1]        [,2]
  [1,] 4.602043e-01 0.539795695
  [2,] 9.220886e-01 0.077911432
  [3,] 7.475411e-01 0.252458946
  [4,] 5.952799e-02 0.940472007
  [5,] 5.952799e-02 0.940472007
  [6,] 7.872073e-01 0.212792742
  [7,] 5.952799e-02 0.940472007
  [8,] 2.644046e-01 0.735595354
  [9,] 9.292452e-01 0.070754760
 [10,] 7.390301e-03 0.992609699
 [11,] 5.952799e-02 0.940472007
 [12,] 5.539613e-01 0.446038660
 [13,] 2.554893e-02 0.974451071
 [14,] 4.286624e-02 0.957133755
 [15,] 7.715096e-01 0.228490362
 [16,] 8.423271e-01 0.157672919
 [17,] 5.952799e-02 0.940472007
 [18,] 2.460030e-01 0.753996964
 [19,] 7.774258e-01 0.222574245
 [20,] 2.721142e-01 0.727885828
 [21,] 6.719213e-02 0.932807868
 [22,] 5.952799e-02 0.940472007
 [23,] 8.423271e-01 0.157672919
 [24,] 8.750789e-02 0.912492106
 [25,] 1.360623e-01 0.863937661
 [26,] 9.929875e-01 0.007012532
 [27,] 5.294056e-01 0.470594435
 [28,] 8.390422e-03 0.991609578
 [29,] 1.999432e-02 0.980005685
 [30,] 5.952799e-02 0.940472007
 [31,] 5.952799e-02 0.940472007
 [32,] 5.952799e-02 0.940472007
 [33,] 8.423271e-01 0.157672919
 [34,] 5.067540e-01 0.493246004
 [35,] 4.028108e-01 0.597189239
 [36,] 2.166490e-01 0.783351030
 [37,] 8.390422e-03 0.991609578
 [38,] 1.906391e-01 0.809360907
 [39,] 9.643358e-01 0.035664243
 [40,] 4.028108e-01 0.597189239
 [41,] 5.952799e-02 0.940472007
 [42,] 3.430203e-01 0.656979688
 [43,] 1.770341e-04 0.999822966
 [44,] 7.568124e-01 0.243187555
 [45,] 9.842503e-01 0.015749656
 [46,] 5.952799e-02 0.940472007
 [47,] 5.952799e-02 0.940472007
 [48,] 2.953533e-02 0.970464670
 [49,] 8.698461e-03 0.991301539
 [50,] 8.423271e-01 0.157672919
 [51,] 2.081057e-02 0.979189430
 [52,] 5.952799e-02 0.940472007
 [53,] 3.160248e-01 0.683975217
 [54,] 8.607059e-01 0.139294081
 [55,] 1.360623e-01 0.863937661
 [56,] 5.952799e-02 0.940472007
 [57,] 1.479467e-02 0.985205330
 [58,] 5.643503e-01 0.435649687
 [59,] 1.018350e-04 0.999898165
 [60,] 9.999911e-05 0.999900001
 [61,] 5.448021e-01 0.455197858
 [62,] 1.351611e-01 0.864838948
 [63,] 8.423271e-01 0.157672919
 [64,] 2.644046e-01 0.735595354
 [65,] 4.486747e-02 0.955132532
 [66,] 1.906391e-01 0.809360907
 [67,] 5.952799e-02 0.940472007
 [68,] 3.512926e-03 0.996487074
 [69,] 2.633002e-02 0.973669980
 [70,] 1.312444e-03 0.998687556
 [71,] 8.046236e-03 0.991953764
 [72,] 2.076238e-01 0.792376183
 [73,] 5.139753e-02 0.948602467
 [74,] 3.402147e-02 0.965978534
 [75,] 5.952799e-02 0.940472007
 [76,] 9.643358e-01 0.035664243
 [77,] 1.124410e-02 0.988755899
 [78,] 7.827920e-03 0.992172080
 [79,] 6.148075e-02 0.938519247
 [80,] 4.028108e-01 0.597189239
 [81,] 9.797495e-01 0.020250460
 [82,] 5.952799e-02 0.940472007
 [83,] 1.473445e-01 0.852655499
 [84,] 3.007320e-01 0.699268006
 [85,] 9.929875e-01 0.007012532
 [86,] 5.952799e-02 0.940472007
 [87,] 9.840935e-01 0.015906477
 [88,] 5.952799e-02 0.940472007
 [89,] 9.929875e-01 0.007012532
 [90,] 8.607059e-01 0.139294081
 [91,] 5.952799e-02 0.940472007
 [92,] 5.952799e-02 0.940472007
 [93,] 8.423271e-01 0.157672919
 [94,] 3.910570e-02 0.960894300
 [95,] 4.028108e-01 0.597189239
 [96,] 5.067540e-01 0.493246004
 [97,] 7.475411e-01 0.252458946
 [98,] 9.924809e-01 0.007519149
 [99,] 8.423271e-01 0.157672919
[100,] 8.607059e-01 0.139294081
[101,] 9.964152e-01 0.003584806
[102,] 9.468195e-01 0.053180537
[103,] 8.607059e-01 0.139294081

[[1]]$tau
[1] 0.5461867 0.1288525

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -9082.99
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181911-1-c9a809.csv\n"
init_taus from clustering  0.259846442098926 init_taus from clustering  0.0381866498193775 init_taus from clustering  0.598528222010851Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.007487 seconds 
1000 transitions using 10 leapfrog steps per transition would take 74.87 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -9326.043             1.000            1.000 
     2        -9275.337             0.503            1.000 
     3        -9213.509             0.337            0.007 
     4        -9191.412             0.254            0.007 
     5        -9182.924             0.203            0.005 
     6        -9159.425             0.170            0.005 
     7        -9154.217             0.146            0.003 
     8        -9144.799             0.127            0.003 
     9        -9140.394             0.113            0.002 
    10        -9136.916             0.102            0.002 
    11        -9128.838             0.093            0.001 
    12        -9125.710             0.085            0.001 
    13        -9120.777             0.079            0.001 
    14        -9119.161             0.073            0.001 
    15        -9117.870             0.068            0.001 
    16        -9110.308             0.064            0.001 
    17        -9104.062             0.060            0.001 
    18        -9107.451             0.057            0.001 
    19        -9100.826             0.054            0.001 
    20        -9099.133             0.051            0.001 
    21        -9096.299             0.001            0.001 
    22        -9092.873             0.001            0.001 
    23        -9092.933             0.001            0.001 
    24        -9088.941             0.001            0.000 
    25        -9087.051             0.001            0.000 
    26        -9088.380             0.000            0.000 
    27        -9079.925             0.000            0.000 
    28        -9082.126             0.000            0.000 
    29        -9080.962             0.000            0.000 
    30        -9077.431             0.000            0.000 
    31        -9081.628             0.000            0.000 
    32        -9077.172             0.000            0.000 
    33        -9076.062             0.000            0.000 
    34        -9070.992             0.000            0.000 
    35        -9072.368             0.000            0.000 
    36        -9071.119             0.000            0.000 
    37        -9071.939             0.000            0.000 
    38        -9067.092             0.000            0.000 
    39        -9070.767             0.000            0.000 
    40        -9062.770             0.000            0.000 
    41        -9067.197             0.000            0.000 
    42        -9065.799             0.000            0.000 
    43        -9062.597             0.000            0.000 
    44        -9061.307             0.000            0.000 
    45        -9064.630             0.000            0.000 
    46        -9060.573             0.000            0.000 
    47        -9058.629             0.000            0.000 
    48        -9058.486             0.000            0.000 
    49        -9058.669             0.000            0.000 
    50        -9057.225             0.000            0.000 
    51        -9055.416             0.000            0.000 
    52        -9057.427             0.000            0.000 
    53        -9055.145             0.000            0.000 
    54        -9054.895             0.000            0.000 
    55        -9055.419             0.000            0.000 
    56        -9053.039             0.000            0.000 
    57        -9054.159             0.000            0.000 
    58        -9053.045             0.000            0.000 
    59        -9053.242             0.000            0.000 
    60        -9049.149             0.000            0.000 
    61        -9045.842             0.000            0.000 
    62        -9051.116             0.000            0.000 
    63        -9046.820             0.000            0.000 
    64        -9047.996             0.000            0.000 
    65        -9048.053             0.000            0.000 
    66        -9046.881             0.000            0.000 
    67        -9044.313             0.000            0.000 
    68        -9048.201             0.000            0.000 
    69        -9047.869             0.000            0.000 
    70        -9048.474             0.000            0.000 
    71        -9045.409             0.000            0.000 
    72        -9047.931             0.000            0.000 
    73        -9048.345             0.000            0.000 
    74        -9046.665             0.000            0.000 
    75        -9045.274             0.000            0.000 
    76        -9046.334             0.000            0.000 
    77        -9044.947             0.000            0.000 
    78        -9046.618             0.000            0.000 
    79        -9043.401             0.000            0.000 
    80        -9044.252             0.000            0.000 
    81        -9043.047             0.000            0.000 
    82        -9038.838             0.000            0.000 
    83        -9039.767             0.000            0.000 
    84        -9043.067             0.000            0.000 
    85        -9043.269             0.000            0.000 
    86        -9040.991             0.000            0.000 
    87        -9041.374             0.000            0.000 
    88        -9040.519             0.000            0.000 
    89        -9037.969             0.000            0.000 
    90        -9041.704             0.000            0.000 
    91        -9041.727             0.000            0.000 
    92        -9040.192             0.000            0.000 
    93        -9038.744             0.000            0.000 
    94        -9041.997             0.000            0.000 
    95        -9039.242             0.000            0.000 
    96        -9038.861             0.000            0.000 
    97        -9036.442             0.000            0.000 
    98        -9040.815             0.000            0.000 
    99        -9037.850             0.000            0.000 
   100        -9037.769             0.000            0.000 
   101        -9037.902             0.000            0.000 
   102        -9037.122             0.000            0.000 
   103        -9037.934             0.000            0.000 
   104        -9039.155             0.000            0.000 
   105        -9039.926             0.000            0.000 
   106        -9035.965             0.000            0.000 
   107        -9036.701             0.000            0.000 
   108        -9038.510             0.000            0.000 
   109        -9037.088             0.000            0.000 
   110        -9038.038             0.000            0.000 
   111        -9036.753             0.000            0.000 
   112        -9036.402             0.000            0.000 
   113        -9036.573             0.000            0.000 
   114        -9037.168             0.000            0.000 
   115        -9036.418             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  65.6 seconds.
[[1]]
[[1]]$w
             [,1]         [,2]         [,3]
  [1,] 0.99979394 0.0001042606 0.0001017953
  [2,] 0.81169705 0.0712125385 0.1170904114
  [3,] 0.94422575 0.0299764493 0.0257978019
  [4,] 0.02096695 0.9750035029 0.0040295443
  [5,] 0.02096695 0.9750035029 0.0040295443
  [6,] 0.92567346 0.0378121607 0.0365143824
  [7,] 0.02096695 0.9750035029 0.0040295443
  [8,] 0.96053365 0.0314142169 0.0080521362
  [9,] 0.03302629 0.0105398949 0.9564338111
 [10,] 0.04323374 0.9513681339 0.0053981233
 [11,] 0.02096695 0.9750035029 0.0040295443
 [12,] 0.99408564 0.0038337416 0.0020806150
 [13,] 0.00130899 0.9984095634 0.0002814468
 [14,] 0.59967871 0.3702483211 0.0300729661
 [15,] 0.93349256 0.0346119674 0.0318954763
 [16,] 0.02709906 0.0114136723 0.9614872655
 [17,] 0.02096695 0.9750035029 0.0040295443
 [18,] 0.95096604 0.0394913438 0.0095426178
 [19,] 0.93062433 0.0358026286 0.0335730383
 [20,] 0.96410832 0.0284274272 0.0074642504
 [21,] 0.69461923 0.2769146801 0.0284660942
 [22,] 0.02096695 0.9750035029 0.0040295443
 [23,] 0.02709906 0.0114136723 0.9614872655
 [24,] 0.75269056 0.2209039144 0.0264055290
 [25,] 0.84714081 0.1320722053 0.0207869862
 [26,] 0.60607930 0.0911041099 0.3028165885
 [27,] 0.99671264 0.0021571516 0.0011302074
 [28,] 0.35318487 0.6206493540 0.0261657775
 [29,] 0.46335642 0.5074157868 0.0292277934
 [30,] 0.02096695 0.9750035029 0.0040295443
 [31,] 0.02096695 0.9750035029 0.0040295443
 [32,] 0.02096695 0.9750035029 0.0040295443
 [33,] 0.02709906 0.0114136723 0.9614872655
 [34,] 0.99844020 0.0010219743 0.0005378259
 [35,] 0.99693042 0.0021944754 0.0008751049
 [36,] 0.93219269 0.0556367540 0.0121705599
 [37,] 0.35318487 0.6206493540 0.0261657775
 [38,] 0.91109291 0.0741610653 0.0147460287
 [39,] 0.13848138 0.0375328286 0.8239857882
 [40,] 0.99693042 0.0021944754 0.0008751049
 [41,] 0.02096695 0.9750035029 0.0040295443
 [42,] 0.98740577 0.0095073560 0.0030868757
 [43,] 0.14951529 0.8355542756 0.0149304368
 [44,] 0.94023505 0.0317339238 0.0280310290
 [45,] 0.65981489 0.0895052138 0.2506798920
 [46,] 0.02096695 0.9750035029 0.0040295443
 [47,] 0.02096695 0.9750035029 0.0040295443
 [48,] 0.52850787 0.4414344512 0.0300576749
 [49,] 0.03631232 0.9590496984 0.0046379780
 [50,] 0.02709906 0.0114136723 0.9614872655
 [51,] 0.46957577 0.5010850394 0.0293391874
 [52,] 0.02096695 0.9750035029 0.0040295443
 [53,] 0.98034503 0.0151221504 0.0045328192
 [54,] 0.87763168 0.0546245045 0.0677438164
 [55,] 0.84714081 0.1320722053 0.0207869862
 [56,] 0.02096695 0.9750035029 0.0040295443
 [57,] 0.01526417 0.9825828250 0.0021530096
 [58,] 0.99274135 0.0046729512 0.0025856963
 [59,] 0.16767463 0.8160669596 0.0162584106
 [60,] 0.16493785 0.8189992194 0.0160629283
 [61,] 0.99515623 0.0031567390 0.0016870324
 [62,] 0.84578573 0.1333222687 0.0208919974
 [63,] 0.02709906 0.0114136723 0.9614872655
 [64,] 0.96053365 0.0314142169 0.0080521362
 [65,] 0.60893194 0.3610659361 0.0300021203
 [66,] 0.91109291 0.0741610653 0.0147460287
 [67,] 0.02096695 0.9750035029 0.0040295443
 [68,] 0.07378896 0.9177058797 0.0085051627
 [69,] 0.50828499 0.4618342813 0.0298807307
 [70,] 0.10685781 0.8816382972 0.0115038962
 [71,] 0.03961573 0.9553805021 0.0050037718
 [72,] 0.92540292 0.0615583350 0.0130387431
 [73,] 0.63707471 0.3332480073 0.0296772796
 [74,] 0.55455328 0.4152715007 0.0301752169
 [75,] 0.02096695 0.9750035029 0.0040295443
 [76,] 0.13848138 0.0375328286 0.8239857882
 [77,] 0.02568489 0.9708950470 0.0034200673
 [78,] 0.04078517 0.9540828878 0.0051319392
 [79,] 0.67530511 0.2957362571 0.0289586288
 [80,] 0.99693042 0.0021944754 0.0008751049
 [81,] 0.67974791 0.0883493500 0.2319027417
 [82,] 0.02096695 0.9750035029 0.0040295443
 [83,] 0.86314009 0.1173773789 0.0194825343
 [84,] 0.97542072 0.0191064675 0.0054728087
 [85,] 0.60607930 0.0911041099 0.3028165885
 [86,] 0.02096695 0.9750035029 0.0040295443
 [87,] 0.25277945 0.0601437134 0.6870768365
 [88,] 0.02096695 0.9750035029 0.0040295443
 [89,] 0.60607930 0.0911041099 0.3028165885
 [90,] 0.87763168 0.0546245045 0.0677438164
 [91,] 0.02096695 0.9750035029 0.0040295443
 [92,] 0.02096695 0.9750035029 0.0040295443
 [93,] 0.02709906 0.0114136723 0.9614872655
 [94,] 0.58138945 0.3884482036 0.0301623483
 [95,] 0.99693042 0.0021944754 0.0008751049
 [96,] 0.99844020 0.0010219743 0.0005378259
 [97,] 0.94422575 0.0299764493 0.0257978019
 [98,] 0.32775784 0.0717823983 0.6004597632
 [99,] 0.02709906 0.0114136723 0.9614872655
[100,] 0.87763168 0.0546245045 0.0677438164
[101,] 0.37808404 0.0781810543 0.5437349025
[102,] 0.77049147 0.0785597542 0.1509487783
[103,] 0.87763168 0.0546245045 0.0677438164

[[1]]$tau
[1] 0.25984644 0.03818665 0.59852822

[[1]]$phi
[1] 0.3333333 0.3333333 0.3333333

[[1]]$kappa
[1] 5


ELBO for this run: -9213.51
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.008007 seconds 
1000 transitions using 10 leapfrog steps per transition would take 80.07 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -9474.757             1.000            1.000 
     2        -9206.393             0.515            1.000 
     3        -9177.854             0.344            0.029 
     4        -9163.653             0.258            0.029 
     5        -9139.968             0.207            0.003 
     6        -9126.638             0.173            0.003 
     7        -9127.622             0.148            0.003 
     8        -9113.112             0.130            0.003 
     9        -9117.475             0.116            0.002 
    10        -9107.681             0.104            0.002 
    11        -9102.209             0.095            0.002 
    12        -9104.422             0.087            0.002 
    13        -9106.090             0.080            0.001 
    14        -9101.028             0.074            0.001 
    15        -9090.220             0.070            0.001 
    16        -9088.769             0.065            0.001 
    17        -9085.822             0.061            0.001 
    18        -9086.003             0.058            0.001 
    19        -9086.486             0.055            0.001 
    20        -9084.278             0.052            0.001 
    21        -9082.331             0.002            0.001 
    22        -9076.347             0.001            0.001 
    23        -9076.499             0.001            0.000 
    24        -9073.882             0.001            0.000 
    25        -9074.191             0.000            0.000 
    26        -9070.199             0.000            0.000 
    27        -9069.352             0.000            0.000 
    28        -9071.648             0.000            0.000 
    29        -9066.743             0.000            0.000 
    30        -9066.591             0.000            0.000 
    31        -9069.072             0.000            0.000 
    32        -9066.390             0.000            0.000 
    33        -9062.814             0.000            0.000 
    34        -9063.032             0.000            0.000 
    35        -9059.862             0.000            0.000 
    36        -9061.340             0.000            0.000 
    37        -9060.236             0.000            0.000 
    38        -9055.897             0.000            0.000 
    39        -9059.300             0.000            0.000 
    40        -9057.664             0.000            0.000 
    41        -9052.994             0.000            0.000 
    42        -9055.976             0.000            0.000 
    43        -9054.878             0.000            0.000 
    44        -9055.630             0.000            0.000 
    45        -9052.374             0.000            0.000 
    46        -9050.360             0.000            0.000 
    47        -9052.634             0.000            0.000 
    48        -9050.541             0.000            0.000 
    49        -9050.651             0.000            0.000 
    50        -9050.076             0.000            0.000 
    51        -9052.468             0.000            0.000 
    52        -9052.117             0.000            0.000 
    53        -9048.079             0.000            0.000 
    54        -9047.598             0.000            0.000 
    55        -9047.162             0.000            0.000 
    56        -9048.959             0.000            0.000 
    57        -9046.978             0.000            0.000 
    58        -9044.525             0.000            0.000 
    59        -9046.124             0.000            0.000 
    60        -9046.621             0.000            0.000 
    61        -9044.513             0.000            0.000 
    62        -9045.894             0.000            0.000 
    63        -9044.078             0.000            0.000 
    64        -9045.121             0.000            0.000 
    65        -9043.632             0.000            0.000 
    66        -9042.368             0.000            0.000 
    67        -9040.776             0.000            0.000 
    68        -9043.274             0.000            0.000 
    69        -9044.896             0.000            0.000 
    70        -9041.800             0.000            0.000 
    71        -9042.026             0.000            0.000 
    72        -9042.803             0.000            0.000 
    73        -9041.600             0.000            0.000 
    74        -9038.887             0.000            0.000 
    75        -9039.200             0.000            0.000 
    76        -9042.046             0.000            0.000 
    77        -9041.319             0.000            0.000 
    78        -9040.521             0.000            0.000 
    79        -9040.473             0.000            0.000 
    80        -9038.144             0.000            0.000 
    81        -9040.139             0.000            0.000 
    82        -9039.821             0.000            0.000 
    83        -9036.427             0.000            0.000 
    84        -9039.993             0.000            0.000 
    85        -9036.996             0.000            0.000 
    86        -9038.109             0.000            0.000 
    87        -9038.622             0.000            0.000 
    88        -9039.232             0.000            0.000 
    89        -9042.221             0.000            0.000 
    90        -9036.736             0.000            0.000 
    91        -9037.388             0.000            0.000 
    92        -9039.058             0.000            0.000 
    93        -9038.715             0.000            0.000 
    94        -9041.068             0.000            0.000 
    95        -9035.978             0.000            0.000 
    96        -9040.640             0.000            0.000 
    97        -9038.604             0.000            0.000 
    98        -9037.495             0.000            0.000 
    99        -9037.986             0.000            0.000 
   100        -9036.130             0.000            0.000 
   101        -9037.485             0.000            0.000 
   102        -9037.815             0.000            0.000 
   103        -9035.463             0.000            0.000 
   104        -9036.943             0.000            0.000 
   105        -9037.999             0.000            0.000 
   106        -9033.497             0.000            0.000 
   107        -9036.522             0.000            0.000 
   108        -9034.592             0.000            0.000 
   109        -9035.663             0.000            0.000 
   110        -9036.348             0.000            0.000 
   111        -9035.067             0.000            0.000 
   112        -9036.435             0.000            0.000 
   113        -9039.846             0.000            0.000 
   114        -9035.656             0.000            0.000 
   115        -9034.076             0.000            0.000 
   116        -9034.910             0.000            0.000 
   117        -9035.209             0.000            0.000 
   118        -9035.793             0.000            0.000 
   119        -9035.831             0.000            0.000 
   120        -9033.929             0.000            0.000 
   121        -9035.307             0.000            0.000 
   122        -9035.347             0.000            0.000 
   123        -9037.749             0.000            0.000 
   124        -9034.594             0.000            0.000 
   125        -9036.202             0.000            0.000 
   126        -9035.715             0.000            0.000 
   127        -9035.172             0.000            0.000 
   128        -9037.704             0.000            0.000 
   129        -9035.580             0.000            0.000 
   130        -9033.237             0.000            0.000 
   131        -9034.033             0.000            0.000 
   132        -9035.987             0.000            0.000 
   133        -9035.204             0.000            0.000 
   134        -9034.891             0.000            0.000 
   135        -9035.260             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  71.0 seconds.
[[1]]
[[1]]$w
             [,1]         [,2]         [,3]
  [1,] 0.99979394 0.0001042606 0.0001017953
  [2,] 0.81169705 0.0712125385 0.1170904114
  [3,] 0.94422575 0.0299764493 0.0257978019
  [4,] 0.02096695 0.9750035029 0.0040295443
  [5,] 0.02096695 0.9750035029 0.0040295443
  [6,] 0.92567346 0.0378121607 0.0365143824
  [7,] 0.02096695 0.9750035029 0.0040295443
  [8,] 0.96053365 0.0314142169 0.0080521362
  [9,] 0.03302629 0.0105398949 0.9564338111
 [10,] 0.04323374 0.9513681339 0.0053981233
 [11,] 0.02096695 0.9750035029 0.0040295443
 [12,] 0.99408564 0.0038337416 0.0020806150
 [13,] 0.00130899 0.9984095634 0.0002814468
 [14,] 0.59967871 0.3702483211 0.0300729661
 [15,] 0.93349256 0.0346119674 0.0318954763
 [16,] 0.02709906 0.0114136723 0.9614872655
 [17,] 0.02096695 0.9750035029 0.0040295443
 [18,] 0.95096604 0.0394913438 0.0095426178
 [19,] 0.93062433 0.0358026286 0.0335730383
 [20,] 0.96410832 0.0284274272 0.0074642504
 [21,] 0.69461923 0.2769146801 0.0284660942
 [22,] 0.02096695 0.9750035029 0.0040295443
 [23,] 0.02709906 0.0114136723 0.9614872655
 [24,] 0.75269056 0.2209039144 0.0264055290
 [25,] 0.84714081 0.1320722053 0.0207869862
 [26,] 0.60607930 0.0911041099 0.3028165885
 [27,] 0.99671264 0.0021571516 0.0011302074
 [28,] 0.35318487 0.6206493540 0.0261657775
 [29,] 0.46335642 0.5074157868 0.0292277934
 [30,] 0.02096695 0.9750035029 0.0040295443
 [31,] 0.02096695 0.9750035029 0.0040295443
 [32,] 0.02096695 0.9750035029 0.0040295443
 [33,] 0.02709906 0.0114136723 0.9614872655
 [34,] 0.99844020 0.0010219743 0.0005378259
 [35,] 0.99693042 0.0021944754 0.0008751049
 [36,] 0.93219269 0.0556367540 0.0121705599
 [37,] 0.35318487 0.6206493540 0.0261657775
 [38,] 0.91109291 0.0741610653 0.0147460287
 [39,] 0.13848138 0.0375328286 0.8239857882
 [40,] 0.99693042 0.0021944754 0.0008751049
 [41,] 0.02096695 0.9750035029 0.0040295443
 [42,] 0.98740577 0.0095073560 0.0030868757
 [43,] 0.14951529 0.8355542756 0.0149304368
 [44,] 0.94023505 0.0317339238 0.0280310290
 [45,] 0.65981489 0.0895052138 0.2506798920
 [46,] 0.02096695 0.9750035029 0.0040295443
 [47,] 0.02096695 0.9750035029 0.0040295443
 [48,] 0.52850787 0.4414344512 0.0300576749
 [49,] 0.03631232 0.9590496984 0.0046379780
 [50,] 0.02709906 0.0114136723 0.9614872655
 [51,] 0.46957577 0.5010850394 0.0293391874
 [52,] 0.02096695 0.9750035029 0.0040295443
 [53,] 0.98034503 0.0151221504 0.0045328192
 [54,] 0.87763168 0.0546245045 0.0677438164
 [55,] 0.84714081 0.1320722053 0.0207869862
 [56,] 0.02096695 0.9750035029 0.0040295443
 [57,] 0.01526417 0.9825828250 0.0021530096
 [58,] 0.99274135 0.0046729512 0.0025856963
 [59,] 0.16767463 0.8160669596 0.0162584106
 [60,] 0.16493785 0.8189992194 0.0160629283
 [61,] 0.99515623 0.0031567390 0.0016870324
 [62,] 0.84578573 0.1333222687 0.0208919974
 [63,] 0.02709906 0.0114136723 0.9614872655
 [64,] 0.96053365 0.0314142169 0.0080521362
 [65,] 0.60893194 0.3610659361 0.0300021203
 [66,] 0.91109291 0.0741610653 0.0147460287
 [67,] 0.02096695 0.9750035029 0.0040295443
 [68,] 0.07378896 0.9177058797 0.0085051627
 [69,] 0.50828499 0.4618342813 0.0298807307
 [70,] 0.10685781 0.8816382972 0.0115038962
 [71,] 0.03961573 0.9553805021 0.0050037718
 [72,] 0.92540292 0.0615583350 0.0130387431
 [73,] 0.63707471 0.3332480073 0.0296772796
 [74,] 0.55455328 0.4152715007 0.0301752169
 [75,] 0.02096695 0.9750035029 0.0040295443
 [76,] 0.13848138 0.0375328286 0.8239857882
 [77,] 0.02568489 0.9708950470 0.0034200673
 [78,] 0.04078517 0.9540828878 0.0051319392
 [79,] 0.67530511 0.2957362571 0.0289586288
 [80,] 0.99693042 0.0021944754 0.0008751049
 [81,] 0.67974791 0.0883493500 0.2319027417
 [82,] 0.02096695 0.9750035029 0.0040295443
 [83,] 0.86314009 0.1173773789 0.0194825343
 [84,] 0.97542072 0.0191064675 0.0054728087
 [85,] 0.60607930 0.0911041099 0.3028165885
 [86,] 0.02096695 0.9750035029 0.0040295443
 [87,] 0.25277945 0.0601437134 0.6870768365
 [88,] 0.02096695 0.9750035029 0.0040295443
 [89,] 0.60607930 0.0911041099 0.3028165885
 [90,] 0.87763168 0.0546245045 0.0677438164
 [91,] 0.02096695 0.9750035029 0.0040295443
 [92,] 0.02096695 0.9750035029 0.0040295443
 [93,] 0.02709906 0.0114136723 0.9614872655
 [94,] 0.58138945 0.3884482036 0.0301623483
 [95,] 0.99693042 0.0021944754 0.0008751049
 [96,] 0.99844020 0.0010219743 0.0005378259
 [97,] 0.94422575 0.0299764493 0.0257978019
 [98,] 0.32775784 0.0717823983 0.6004597632
 [99,] 0.02709906 0.0114136723 0.9614872655
[100,] 0.87763168 0.0546245045 0.0677438164
[101,] 0.37808404 0.0781810543 0.5437349025
[102,] 0.77049147 0.0785597542 0.1509487783
[103,] 0.87763168 0.0546245045 0.0677438164

[[1]]$tau
[1] 0.6395557 0.0700000 0.3203835

[[1]]$phi
[1] 0.3333333 0.3333333 0.3333333

[[1]]$kappa
[1] 5


ELBO for this run: -9177.85
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181913-1-8fe9b2.csv\n"
init_taus from clustering  0.0199474795195795 init_taus from clustering  0.648424115787079 init_taus from clustering  0.201783066029317 init_taus from clustering  0.356093133049156Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.010184 seconds 
1000 transitions using 10 leapfrog steps per transition would take 101.84 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -9462.876             1.000            1.000 
     2        -9340.026             0.507            1.000 
     3        -9269.924             0.340            0.013 
     4        -9231.866             0.256            0.013 
     5        -9212.452             0.205            0.008 
     6        -9201.089             0.171            0.008 
     7        -9189.638             0.147            0.004 
     8        -9184.474             0.129            0.004 
     9        -9167.019             0.115            0.002 
    10        -9172.720             0.103            0.002 
    11        -9149.352             0.094            0.002 
    12        -9151.258             0.086            0.002 
    13        -9142.749             0.080            0.002 
    14        -9141.151             0.074            0.002 
    15        -9131.146             0.069            0.001 
    16        -9124.765             0.065            0.001 
    17        -9120.501             0.061            0.001 
    18        -9119.615             0.058            0.001 
    19        -9114.554             0.055            0.001 
    20        -9112.321             0.052            0.001 
    21        -9108.889             0.002            0.001 
    22        -9108.421             0.001            0.001 
    23        -9103.861             0.001            0.001 
    24        -9102.288             0.001            0.001 
    25        -9097.425             0.001            0.001 
    26        -9097.777             0.001            0.001 
    27        -9095.412             0.001            0.001 
    28        -9091.830             0.001            0.000 
    29        -9095.959             0.001            0.000 
    30        -9091.432             0.001            0.000 
    31        -9089.474             0.000            0.000 
    32        -9087.333             0.000            0.000 
    33        -9088.579             0.000            0.000 
    34        -9083.805             0.000            0.000 
    35        -9086.183             0.000            0.000 
    36        -9079.822             0.000            0.000 
    37        -9084.090             0.000            0.000 
    38        -9082.569             0.000            0.000 
    39        -9080.050             0.000            0.000 
    40        -9081.739             0.000            0.000 
    41        -9078.504             0.000            0.000 
    42        -9076.368             0.000            0.000 
    43        -9074.238             0.000            0.000 
    44        -9074.344             0.000            0.000 
    45        -9073.316             0.000            0.000 
    46        -9073.007             0.000            0.000 
    47        -9072.307             0.000            0.000 
    48        -9071.900             0.000            0.000 
    49        -9068.844             0.000            0.000 
    50        -9070.176             0.000            0.000 
    51        -9069.428             0.000            0.000 
    52        -9064.991             0.000            0.000 
    53        -9068.065             0.000            0.000 
    54        -9067.408             0.000            0.000 
    55        -9064.575             0.000            0.000 
    56        -9064.389             0.000            0.000 
    57        -9068.597             0.000            0.000 
    58        -9068.175             0.000            0.000 
    59        -9065.332             0.000            0.000 
    60        -9064.027             0.000            0.000 
    61        -9062.437             0.000            0.000 
    62        -9060.299             0.000            0.000 
    63        -9064.641             0.000            0.000 
    64        -9063.688             0.000            0.000 
    65        -9059.067             0.000            0.000 
    66        -9061.791             0.000            0.000 
    67        -9062.453             0.000            0.000 
    68        -9059.686             0.000            0.000 
    69        -9058.907             0.000            0.000 
    70        -9057.842             0.000            0.000 
    71        -9058.846             0.000            0.000 
    72        -9060.382             0.000            0.000 
    73        -9057.063             0.000            0.000 
    74        -9058.267             0.000            0.000 
    75        -9054.061             0.000            0.000 
    76        -9056.531             0.000            0.000 
    77        -9056.634             0.000            0.000 
    78        -9057.529             0.000            0.000 
    79        -9058.173             0.000            0.000 
    80        -9056.374             0.000            0.000 
    81        -9058.793             0.000            0.000 
    82        -9057.820             0.000            0.000 
    83        -9055.139             0.000            0.000 
    84        -9054.731             0.000            0.000 
    85        -9054.746             0.000            0.000 
    86        -9055.350             0.000            0.000 
    87        -9055.065             0.000            0.000 
    88        -9055.645             0.000            0.000 
    89        -9053.573             0.000            0.000 
    90        -9054.505             0.000            0.000 
    91        -9054.406             0.000            0.000 
    92        -9055.262             0.000            0.000 
    93        -9055.251             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  75.9 seconds.
[[1]]
[[1]]$w
               [,1]         [,2]         [,3]         [,4]
  [1,] 0.0404282692 0.0153765537 0.6968610222 0.2473341548
  [2,] 0.0001834639 0.0002061552 0.0005048914 0.9991054896
  [3,] 0.0224976555 0.0160972061 0.1651988047 0.7962063337
  [4,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
  [5,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
  [6,] 0.0160299387 0.0127193686 0.1072363871 0.8640143056
  [7,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
  [8,] 0.0131773984 0.0032090161 0.9507525955 0.0328609900
  [9,] 0.0270275365 0.7025309379 0.0630519700 0.2073895555
 [10,] 0.7921176071 0.0080258829 0.1665190140 0.0333374959
 [11,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [12,] 0.0427515592 0.0198189095 0.5246267781 0.4128027531
 [13,] 0.9652034240 0.0018534438 0.0262326661 0.0067104661
 [14,] 0.0683875821 0.0059573629 0.8886941810 0.0369608740
 [15,] 0.0185952322 0.0141484729 0.1290659238 0.8381903712
 [16,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [17,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [18,] 0.0100683969 0.0023498167 0.9646453636 0.0229364227
 [19,] 0.0176268235 0.0136230914 0.1206585234 0.8480915617
 [20,] 0.0145075108 0.0035983980 0.9443466354 0.0375474558
 [21,] 0.0306360537 0.0033232141 0.9440516330 0.0219890992
 [22,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [23,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [24,] 0.0146215321 0.0018519203 0.9708541488 0.0126723989
 [25,] 0.0007929281 0.0002067498 0.9980397626 0.0009605595
 [26,] 0.0123419494 0.0287883869 0.0450838037 0.9137858600
 [27,] 0.0429947430 0.0189276021 0.5716116176 0.3664660372
 [28,] 0.2454818005 0.0120316947 0.6785373195 0.0639491852
 [29,] 0.1500016927 0.0096294426 0.7856188556 0.0547500092
 [30,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [31,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [32,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [33,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [34,] 0.0426782204 0.0179137054 0.6139630536 0.3254450205
 [35,] 0.0349052785 0.0117248759 0.7890236572 0.1643461883
 [36,] 0.0055082167 0.0012175269 0.9824897939 0.0107844625
 [37,] 0.2454818005 0.0120316947 0.6785373195 0.0639491852
 [38,] 0.0022555476 0.0005091201 0.9934279078 0.0038074245
 [39,] 0.0397897325 0.4158399490 0.1029273474 0.4414429711
 [40,] 0.0349052785 0.0117248759 0.7890236572 0.1643461883
 [41,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [42,] 0.0265025375 0.0077786733 0.8704236726 0.0952951167
 [43,] 0.5328448751 0.0128213026 0.3948856386 0.0594481836
 [44,] 0.0209960206 0.0153789892 0.1508440336 0.8127809566
 [45,] 0.0076284655 0.0153331968 0.0293565583 0.9476817794
 [46,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [47,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [48,] 0.1066095530 0.0079299041 0.8384942709 0.0469662721
 [49,] 0.8145100276 0.0073850902 0.1477696880 0.0303351942
 [50,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [51,] 0.1454806361 0.0094738460 0.7909726150 0.0540729029
 [52,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [53,] 0.0220801314 0.0060835464 0.9016400425 0.0701962798
 [54,] 0.0051166920 0.0050695714 0.0285426621 0.9612710746
 [55,] 0.0007929281 0.0002067498 0.9980397626 0.0009605595
 [56,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [57,] 0.8918701339 0.0048466308 0.0842664501 0.0190167852
 [58,] 0.0424658000 0.0201226925 0.5045019715 0.4329095360
 [59,] 0.4987555693 0.0130984956 0.4265518335 0.0615941015
 [60,] 0.5037530754 0.0130632560 0.4218827714 0.0613008972
 [61,] 0.0429135406 0.0195138721 0.5422599648 0.3953126225
 [62,] 0.0008706260 0.0002182605 0.9978597164 0.0010513971
 [63,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [64,] 0.0131773984 0.0032090161 0.9507525955 0.0328609900
 [65,] 0.0640637911 0.0056971874 0.8946725345 0.0355664870
 [66,] 0.0022555476 0.0005091201 0.9934279078 0.0038074245
 [67,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [68,] 0.7039974977 0.0101845399 0.2417987208 0.0440192416
 [69,] 0.1191661338 0.0084722044 0.8228227020 0.0495389598
 [70,] 0.6226332877 0.0116919499 0.3134066728 0.0522680896
 [71,] 0.8036825793 0.0076998356 0.1568158935 0.0318016916
 [72,] 0.0042701149 0.0009373346 0.9868337729 0.0079587777
 [73,] 0.0517827741 0.0049066085 0.9120904001 0.0312202173
 [74,] 0.0915732348 0.0072170457 0.8577437372 0.0434659823
 [75,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [76,] 0.0397897325 0.4158399490 0.1029273474 0.4414429711
 [77,] 0.8514109469 0.0062404647 0.1172236668 0.0251249215
 [78,] 0.7999121343 0.0078072744 0.1599747350 0.0323058563
 [79,] 0.0371477860 0.0038461948 0.9338857060 0.0251203132
 [80,] 0.0349052785 0.0117248759 0.7890236572 0.1643461883
 [81,] 0.0060039057 0.0113959195 0.0235744493 0.9590257255
 [82,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [83,] 0.0001826495 0.0001133212 0.9994936673 0.0002103620
 [84,] 0.0194703453 0.0051726546 0.9176817324 0.0576752677
 [85,] 0.0123419494 0.0287883869 0.0450838037 0.9137858600
 [86,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [87,] 0.0389733888 0.2500346442 0.1093277181 0.6016642489
 [88,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [89,] 0.0123419494 0.0287883869 0.0450838037 0.9137858600
 [90,] 0.0051166920 0.0050695714 0.0285426621 0.9612710746
 [91,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [92,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [93,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [94,] 0.0773591874 0.0064704192 0.8765109992 0.0396593942
 [95,] 0.0349052785 0.0117248759 0.7890236572 0.1643461883
 [96,] 0.0426782204 0.0179137054 0.6139630536 0.3254450205
 [97,] 0.0224976555 0.0160972061 0.1651988047 0.7962063337
 [98,] 0.0352392040 0.1768884165 0.1039536084 0.6839187711
 [99,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
[100,] 0.0051166920 0.0050695714 0.0285426621 0.9612710746
[101,] 0.0318893091 0.1379483941 0.0973516251 0.7328106717
[102,] 0.0005928611 0.0008187944 0.0023209785 0.9962673661
[103,] 0.0051166920 0.0050695714 0.0285426621 0.9612710746

[[1]]$tau
[1] 0.01994748 0.64842412 0.20178307 0.35609313

[[1]]$phi
[1] 0.25 0.25 0.25 0.25

[[1]]$kappa
[1] 5


ELBO for this run: -9269.92
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.010081 seconds 
1000 transitions using 10 leapfrog steps per transition would take 100.81 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -9431.472             1.000            1.000 
     2        -9340.745             0.505            1.000 
     3        -9259.089             0.340            0.010 
     4        -9199.545             0.256            0.010 
     5        -9194.677             0.205            0.009 
     6        -9177.370             0.171            0.009 
     7        -9163.439             0.147            0.006 
     8        -9157.218             0.129            0.006 
     9        -9146.849             0.115            0.002 
    10        -9140.754             0.103            0.002 
    11        -9137.048             0.094            0.002 
    12        -9136.656             0.086            0.002 
    13        -9126.311             0.079            0.001 
    14        -9116.970             0.074            0.001 
    15        -9115.744             0.069            0.001 
    16        -9112.017             0.065            0.001 
    17        -9107.578             0.061            0.001 
    18        -9106.243             0.058            0.001 
    19        -9104.282             0.054            0.001 
    20        -9098.697             0.052            0.001 
    21        -9097.570             0.002            0.001 
    22        -9095.691             0.001            0.001 
    23        -9092.902             0.001            0.001 
    24        -9093.788             0.001            0.000 
    25        -9092.586             0.001            0.000 
    26        -9089.076             0.000            0.000 
    27        -9089.409             0.000            0.000 
    28        -9086.095             0.000            0.000 
    29        -9084.529             0.000            0.000 
    30        -9080.567             0.000            0.000 
    31        -9085.943             0.000            0.000 
    32        -9078.469             0.000            0.000 
    33        -9081.440             0.000            0.000 
    34        -9075.635             0.000            0.000 
    35        -9076.650             0.000            0.000 
    36        -9076.115             0.000            0.000 
    37        -9072.643             0.000            0.000 
    38        -9074.264             0.000            0.000 
    39        -9072.043             0.000            0.000 
    40        -9067.748             0.000            0.000 
    41        -9074.105             0.000            0.000 
    42        -9073.245             0.000            0.000 
    43        -9070.523             0.000            0.000 
    44        -9069.795             0.000            0.000 
    45        -9068.794             0.000            0.000 
    46        -9068.212             0.000            0.000 
    47        -9066.451             0.000            0.000 
    48        -9065.708             0.000            0.000 
    49        -9067.550             0.000            0.000 
    50        -9066.591             0.000            0.000 
    51        -9063.623             0.000            0.000 
    52        -9066.248             0.000            0.000 
    53        -9065.834             0.000            0.000 
    54        -9063.345             0.000            0.000 
    55        -9061.985             0.000            0.000 
    56        -9061.465             0.000            0.000 
    57        -9061.590             0.000            0.000 
    58        -9059.694             0.000            0.000 
    59        -9061.162             0.000            0.000 
    60        -9063.873             0.000            0.000 
    61        -9059.535             0.000            0.000 
    62        -9059.697             0.000            0.000 
    63        -9061.921             0.000            0.000 
    64        -9057.928             0.000            0.000 
    65        -9058.545             0.000            0.000 
    66        -9057.597             0.000            0.000 
    67        -9061.228             0.000            0.000 
    68        -9059.222             0.000            0.000 
    69        -9055.981             0.000            0.000 
    70        -9055.071             0.000            0.000 
    71        -9057.528             0.000            0.000 
    72        -9056.502             0.000            0.000 
    73        -9058.373             0.000            0.000 
    74        -9057.153             0.000            0.000 
    75        -9055.751             0.000            0.000 
    76        -9054.844             0.000            0.000 
    77        -9057.479             0.000            0.000 
    78        -9053.546             0.000            0.000 
    79        -9054.125             0.000            0.000 
    80        -9055.211             0.000            0.000 
    81        -9053.626             0.000            0.000 
    82        -9059.334             0.000            0.000 
    83        -9053.770             0.000            0.000 
    84        -9055.237             0.000            0.000 
    85        -9054.114             0.000            0.000 
    86        -9053.708             0.000            0.000 
    87        -9055.814             0.000            0.000 
    88        -9054.588             0.000            0.000 
    89        -9051.675             0.000            0.000 
    90        -9052.421             0.000            0.000 
    91        -9052.398             0.000            0.000 
    92        -9054.607             0.000            0.000 
    93        -9051.742             0.000            0.000 
    94        -9054.698             0.000            0.000 
    95        -9052.729             0.000            0.000 
    96        -9055.001             0.000            0.000 
    97        -9053.984             0.000            0.000 
    98        -9050.811             0.000            0.000 
    99        -9050.689             0.000            0.000 
   100        -9055.517             0.000            0.000 
   101        -9051.616             0.000            0.000 
   102        -9054.589             0.000            0.000 
   103        -9054.285             0.000            0.000 
   104        -9052.499             0.000            0.000 
   105        -9052.295             0.000            0.000 
   106        -9052.316             0.000            0.000 
   107        -9051.997             0.000            0.000 
   108        -9051.201             0.000            0.000 
   109        -9048.430             0.000            0.000 
   110        -9050.966             0.000            0.000 
   111        -9048.342             0.000            0.000 
   112        -9051.959             0.000            0.000 
   113        -9049.661             0.000            0.000 
   114        -9050.999             0.000            0.000 
   115        -9048.780             0.000            0.000 
   116        -9049.811             0.000            0.000 
   117        -9051.700             0.000            0.000 
   118        -9052.020             0.000            0.000 
   119        -9049.386             0.000            0.000 
   120        -9049.976             0.000            0.000 
   121        -9050.106             0.000            0.000 
   122        -9049.343             0.000            0.000 
   123        -9050.003             0.000            0.000 
   124        -9048.800             0.000            0.000 
   125        -9051.304             0.000            0.000 
   126        -9049.983             0.000            0.000 
   127        -9051.736             0.000            0.000 
   128        -9049.957             0.000            0.000 
   129        -9051.620             0.000            0.000 
   130        -9050.357             0.000            0.000 
   131        -9048.674             0.000            0.000 
   132        -9052.585             0.000            0.000 
   133        -9049.657             0.000            0.000 
   134        -9051.757             0.000            0.000 
   135        -9053.098             0.000            0.000 
   136        -9051.836             0.000            0.000 
   137        -9053.085             0.000            0.000 
   138        -9049.778             0.000            0.000 
   139        -9049.579             0.000            0.000 
   140        -9050.187             0.000            0.000 
   141        -9050.401             0.000            0.000 
   142        -9049.107             0.000            0.000 
   143        -9050.676             0.000            0.000 
   144        -9049.165             0.000            0.000 
   145        -9048.538             0.000            0.000 
   146        -9050.367             0.000            0.000 
   147        -9048.695             0.000            0.000 
   148        -9049.792             0.000            0.000 
   149        -9049.418             0.000            0.000 
   150        -9046.806             0.000            0.000 
   151        -9049.176             0.000            0.000 
   152        -9049.871             0.000            0.000 
   153        -9047.559             0.000            0.000 
   154        -9051.100             0.000            0.000 
   155        -9047.686             0.000            0.000 
   156        -9049.730             0.000            0.000 
   157        -9049.560             0.000            0.000 
   158        -9049.847             0.000            0.000 
   159        -9044.562             0.000            0.000 
   160        -9048.262             0.000            0.000 
   161        -9050.034             0.000            0.000 
   162        -9048.381             0.000            0.000 
   163        -9048.468             0.000            0.000 
   164        -9048.367             0.000            0.000 
   165        -9049.301             0.000            0.000 
   166        -9046.525             0.000            0.000 
   167        -9047.490             0.000            0.000 
   168        -9050.548             0.000            0.000 
   169        -9048.800             0.000            0.000 
   170        -9047.000             0.000            0.000 
   171        -9052.594             0.000            0.000 
   172        -9047.779             0.000            0.000 
   173        -9049.455             0.000            0.000 
   174        -9049.251             0.000            0.000 
   175        -9049.480             0.000            0.000 
   176        -9047.923             0.000            0.000 
   177        -9047.215             0.000            0.000 
   178        -9048.800             0.000            0.000 
   179        -9047.324             0.000            0.000 
   180        -9045.969             0.000            0.000 
   181        -9045.430             0.000            0.000 
   182        -9047.358             0.000            0.000 
   183        -9050.369             0.000            0.000 
   184        -9045.400             0.000            0.000 
   185        -9050.696             0.000            0.000 
   186        -9047.281             0.000            0.000 
   187        -9048.467             0.000            0.000 
   188        -9048.838             0.000            0.000 
   189        -9049.750             0.000            0.000 
   190        -9046.541             0.000            0.000 
   191        -9047.800             0.000            0.000 
   192        -9043.540             0.000            0.000 
   193        -9046.525             0.000            0.000 
   194        -9046.128             0.000            0.000 
   195        -9045.512             0.000            0.000 
   196        -9048.396             0.000            0.000 
   197        -9049.040             0.000            0.000 
   198        -9048.126             0.000            0.000 
   199        -9049.086             0.000            0.000 
   200        -9046.384             0.000            0.000 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  118.9 seconds.
[[1]]
[[1]]$w
               [,1]         [,2]         [,3]         [,4]
  [1,] 0.0404282692 0.0153765537 0.6968610222 0.2473341548
  [2,] 0.0001834639 0.0002061552 0.0005048914 0.9991054896
  [3,] 0.0224976555 0.0160972061 0.1651988047 0.7962063337
  [4,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
  [5,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
  [6,] 0.0160299387 0.0127193686 0.1072363871 0.8640143056
  [7,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
  [8,] 0.0131773984 0.0032090161 0.9507525955 0.0328609900
  [9,] 0.0270275365 0.7025309379 0.0630519700 0.2073895555
 [10,] 0.7921176071 0.0080258829 0.1665190140 0.0333374959
 [11,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [12,] 0.0427515592 0.0198189095 0.5246267781 0.4128027531
 [13,] 0.9652034240 0.0018534438 0.0262326661 0.0067104661
 [14,] 0.0683875821 0.0059573629 0.8886941810 0.0369608740
 [15,] 0.0185952322 0.0141484729 0.1290659238 0.8381903712
 [16,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [17,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [18,] 0.0100683969 0.0023498167 0.9646453636 0.0229364227
 [19,] 0.0176268235 0.0136230914 0.1206585234 0.8480915617
 [20,] 0.0145075108 0.0035983980 0.9443466354 0.0375474558
 [21,] 0.0306360537 0.0033232141 0.9440516330 0.0219890992
 [22,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [23,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [24,] 0.0146215321 0.0018519203 0.9708541488 0.0126723989
 [25,] 0.0007929281 0.0002067498 0.9980397626 0.0009605595
 [26,] 0.0123419494 0.0287883869 0.0450838037 0.9137858600
 [27,] 0.0429947430 0.0189276021 0.5716116176 0.3664660372
 [28,] 0.2454818005 0.0120316947 0.6785373195 0.0639491852
 [29,] 0.1500016927 0.0096294426 0.7856188556 0.0547500092
 [30,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [31,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [32,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [33,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [34,] 0.0426782204 0.0179137054 0.6139630536 0.3254450205
 [35,] 0.0349052785 0.0117248759 0.7890236572 0.1643461883
 [36,] 0.0055082167 0.0012175269 0.9824897939 0.0107844625
 [37,] 0.2454818005 0.0120316947 0.6785373195 0.0639491852
 [38,] 0.0022555476 0.0005091201 0.9934279078 0.0038074245
 [39,] 0.0397897325 0.4158399490 0.1029273474 0.4414429711
 [40,] 0.0349052785 0.0117248759 0.7890236572 0.1643461883
 [41,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [42,] 0.0265025375 0.0077786733 0.8704236726 0.0952951167
 [43,] 0.5328448751 0.0128213026 0.3948856386 0.0594481836
 [44,] 0.0209960206 0.0153789892 0.1508440336 0.8127809566
 [45,] 0.0076284655 0.0153331968 0.0293565583 0.9476817794
 [46,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [47,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [48,] 0.1066095530 0.0079299041 0.8384942709 0.0469662721
 [49,] 0.8145100276 0.0073850902 0.1477696880 0.0303351942
 [50,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [51,] 0.1454806361 0.0094738460 0.7909726150 0.0540729029
 [52,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [53,] 0.0220801314 0.0060835464 0.9016400425 0.0701962798
 [54,] 0.0051166920 0.0050695714 0.0285426621 0.9612710746
 [55,] 0.0007929281 0.0002067498 0.9980397626 0.0009605595
 [56,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [57,] 0.8918701339 0.0048466308 0.0842664501 0.0190167852
 [58,] 0.0424658000 0.0201226925 0.5045019715 0.4329095360
 [59,] 0.4987555693 0.0130984956 0.4265518335 0.0615941015
 [60,] 0.5037530754 0.0130632560 0.4218827714 0.0613008972
 [61,] 0.0429135406 0.0195138721 0.5422599648 0.3953126225
 [62,] 0.0008706260 0.0002182605 0.9978597164 0.0010513971
 [63,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [64,] 0.0131773984 0.0032090161 0.9507525955 0.0328609900
 [65,] 0.0640637911 0.0056971874 0.8946725345 0.0355664870
 [66,] 0.0022555476 0.0005091201 0.9934279078 0.0038074245
 [67,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [68,] 0.7039974977 0.0101845399 0.2417987208 0.0440192416
 [69,] 0.1191661338 0.0084722044 0.8228227020 0.0495389598
 [70,] 0.6226332877 0.0116919499 0.3134066728 0.0522680896
 [71,] 0.8036825793 0.0076998356 0.1568158935 0.0318016916
 [72,] 0.0042701149 0.0009373346 0.9868337729 0.0079587777
 [73,] 0.0517827741 0.0049066085 0.9120904001 0.0312202173
 [74,] 0.0915732348 0.0072170457 0.8577437372 0.0434659823
 [75,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [76,] 0.0397897325 0.4158399490 0.1029273474 0.4414429711
 [77,] 0.8514109469 0.0062404647 0.1172236668 0.0251249215
 [78,] 0.7999121343 0.0078072744 0.1599747350 0.0323058563
 [79,] 0.0371477860 0.0038461948 0.9338857060 0.0251203132
 [80,] 0.0349052785 0.0117248759 0.7890236572 0.1643461883
 [81,] 0.0060039057 0.0113959195 0.0235744493 0.9590257255
 [82,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [83,] 0.0001826495 0.0001133212 0.9994936673 0.0002103620
 [84,] 0.0194703453 0.0051726546 0.9176817324 0.0576752677
 [85,] 0.0123419494 0.0287883869 0.0450838037 0.9137858600
 [86,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [87,] 0.0389733888 0.2500346442 0.1093277181 0.6016642489
 [88,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [89,] 0.0123419494 0.0287883869 0.0450838037 0.9137858600
 [90,] 0.0051166920 0.0050695714 0.0285426621 0.9612710746
 [91,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [92,] 0.9862845818 0.0010151956 0.0095639672 0.0031362554
 [93,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
 [94,] 0.0773591874 0.0064704192 0.8765109992 0.0396593942
 [95,] 0.0349052785 0.0117248759 0.7890236572 0.1643461883
 [96,] 0.0426782204 0.0179137054 0.6139630536 0.3254450205
 [97,] 0.0224976555 0.0160972061 0.1651988047 0.7962063337
 [98,] 0.0352392040 0.1768884165 0.1039536084 0.6839187711
 [99,] 0.0008944758 0.9939234653 0.0016374851 0.0035445738
[100,] 0.0051166920 0.0050695714 0.0285426621 0.9612710746
[101,] 0.0318893091 0.1379483941 0.0973516251 0.7328106717
[102,] 0.0005928611 0.0008187944 0.0023209785 0.9962673661
[103,] 0.0051166920 0.0050695714 0.0285426621 0.9612710746

[[1]]$tau
[1] 0.0563472 0.3307747 0.1739859 0.5920372

[[1]]$phi
[1] 0.25 0.25 0.25 0.25

[[1]]$kappa
[1] 5


ELBO for this run: -9259.09
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181916-1-a005a6.csv\n"
init_taus from clustering  0.152736806522478 init_taus from clustering  0.660113622762508 init_taus from clustering  0.408898099966239 init_taus from clustering  0.261526172267302 init_taus from clustering  0.00865217407600958Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.013237 seconds 
1000 transitions using 10 leapfrog steps per transition would take 132.37 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -9762.583             1.000            1.000 
     2        -9565.098             0.510            1.000 
     3        -9391.431             0.346            0.021 
     4        -9346.672             0.261            0.021 
     5        -9313.058             0.210            0.018 
     6        -9289.863             0.175            0.018 
     7        -9274.250             0.150            0.005 
     8        -9264.798             0.132            0.005 
     9        -9248.482             0.117            0.004 
    10        -9236.156             0.106            0.004 
    11        -9225.498             0.096            0.002 
    12        -9230.164             0.088            0.002 
    13        -9224.820             0.081            0.002 
    14        -9196.246             0.076            0.002 
    15        -9209.949             0.071            0.002 
    16        -9197.428             0.067            0.002 
    17        -9188.580             0.063            0.002 
    18        -9183.223             0.059            0.002 
    19        -9176.637             0.056            0.001 
    20        -9174.787             0.053            0.001 
    21        -9172.929             0.003            0.001 
    22        -9166.504             0.002            0.001 
    23        -9160.781             0.001            0.001 
    24        -9162.181             0.001            0.001 
    25        -9160.460             0.001            0.001 
    26        -9153.151             0.001            0.001 
    27        -9152.393             0.001            0.001 
    28        -9146.427             0.001            0.001 
    29        -9147.032             0.001            0.001 
    30        -9144.357             0.001            0.001 
    31        -9154.091             0.001            0.001 
    32        -9140.211             0.001            0.001 
    33        -9138.736             0.001            0.001 
    34        -9136.511             0.001            0.001 
    35        -9135.101             0.001            0.001 
    36        -9131.654             0.000            0.000 
    37        -9131.508             0.000            0.000 
    38        -9125.653             0.000            0.000 
    39        -9124.018             0.000            0.000 
    40        -9124.789             0.000            0.000 
    41        -9124.602             0.000            0.000 
    42        -9116.774             0.000            0.000 
    43        -9118.048             0.000            0.000 
    44        -9112.935             0.000            0.000 
    45        -9119.283             0.000            0.000 
    46        -9111.433             0.000            0.000 
    47        -9115.313             0.000            0.000 
    48        -9112.123             0.000            0.000 
    49        -9105.590             0.000            0.000 
    50        -9106.696             0.000            0.000 
    51        -9105.805             0.000            0.000 
    52        -9099.478             0.000            0.000 
    53        -9101.914             0.000            0.000 
    54        -9102.902             0.000            0.000 
    55        -9103.284             0.000            0.000 
    56        -9099.083             0.000            0.000 
    57        -9099.948             0.000            0.000 
    58        -9101.451             0.000            0.000 
    59        -9097.477             0.000            0.000 
    60        -9096.603             0.000            0.000 
    61        -9094.904             0.000            0.000 
    62        -9098.848             0.000            0.000 
    63        -9093.016             0.000            0.000 
    64        -9091.961             0.000            0.000 
    65        -9089.462             0.000            0.000 
    66        -9093.003             0.000            0.000 
    67        -9090.902             0.000            0.000 
    68        -9087.952             0.000            0.000 
    69        -9086.331             0.000            0.000 
    70        -9085.268             0.000            0.000 
    71        -9088.879             0.000            0.000 
    72        -9088.894             0.000            0.000 
    73        -9085.127             0.000            0.000 
    74        -9083.932             0.000            0.000 
    75        -9085.144             0.000            0.000 
    76        -9085.722             0.000            0.000 
    77        -9082.529             0.000            0.000 
    78        -9082.565             0.000            0.000 
    79        -9079.847             0.000            0.000 
    80        -9081.586             0.000            0.000 
    81        -9081.839             0.000            0.000 
    82        -9081.224             0.000            0.000 
    83        -9078.056             0.000            0.000 
    84        -9081.647             0.000            0.000 
    85        -9078.956             0.000            0.000 
    86        -9079.262             0.000            0.000 
    87        -9079.221             0.000            0.000 
    88        -9079.989             0.000            0.000 
    89        -9076.816             0.000            0.000 
    90        -9077.635             0.000            0.000 
    91        -9075.734             0.000            0.000 
    92        -9075.608             0.000            0.000 
    93        -9075.300             0.000            0.000 
    94        -9074.813             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  68.6 seconds.
[[1]]
[[1]]$w
               [,1]         [,2]         [,3]         [,4]         [,5]
  [1,] 0.0005013291 0.0001283811 0.0003041932 0.9988935268 0.0001725697
  [2,] 0.0515739374 0.0220044802 0.6622326580 0.2466756372 0.0175132871
  [3,] 0.0665489618 0.0129742408 0.1564701834 0.7460516678 0.0179549462
  [4,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
  [5,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
  [6,] 0.0736522072 0.0166279800 0.2265440553 0.6623326688 0.0208430887
  [7,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
  [8,] 0.1806808878 0.0052339701 0.0290128428 0.7644753189 0.0205969804
  [9,] 0.0427002912 0.5006002620 0.3522076530 0.0815892367 0.0229025570
 [10,] 0.4067243264 0.0069437420 0.0212303172 0.0684928305 0.4966087839
 [11,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [12,] 0.0109109230 0.0011736684 0.0089235660 0.9766276172 0.0023642254
 [13,] 0.1026504003 0.0032150852 0.0090135641 0.0253368816 0.8597840688
 [14,] 0.9847431901 0.0004645711 0.0015859696 0.0092798052 0.0039264639
 [15,] 0.0712961409 0.0151707724 0.1964131471 0.6973231367 0.0197968030
 [16,] 0.0002644410 0.9984169302 0.0007537054 0.0003646283 0.0002002949
 [17,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [18,] 0.2256774161 0.0058062012 0.0315250407 0.7129490467 0.0240422953
 [19,] 0.0722613899 0.0157200609 0.2073776605 0.6844323254 0.0202085633
 [20,] 0.1637841866 0.0049746846 0.0278098435 0.7842588754 0.0191724099
 [21,] 0.9202329746 0.0018714908 0.0076890417 0.0548104610 0.0153960319
 [22,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [23,] 0.0002644410 0.9984169302 0.0007537054 0.0003646283 0.0002002949
 [24,] 0.8444470423 0.0032553872 0.0141085107 0.1140725459 0.0241165138
 [25,] 0.6314084603 0.0058997084 0.0278194565 0.2997681242 0.0351042505
 [26,] 0.0013568242 0.0012374261 0.9926988844 0.0041050247 0.0006018406
 [27,] 0.0057163638 0.0006118856 0.0041532110 0.9882836837 0.0012348559
 [28,] 0.9496909075 0.0013676962 0.0047353499 0.0215482908 0.0226577557
 [29,] 0.9939354322 0.0002465085 0.0006614659 0.0030220073 0.0021345861
 [30,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [31,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [32,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [33,] 0.0002644410 0.9984169302 0.0007537054 0.0003646283 0.0002002949
 [34,] 0.0022231170 0.0002784902 0.0014677196 0.9955162355 0.0005144378
 [35,] 0.0134892166 0.0008555545 0.0051384953 0.9782387428 0.0022779909
 [36,] 0.3117393846 0.0065052150 0.0341233215 0.6182946617 0.0293374173
 [37,] 0.9496909075 0.0013676962 0.0047353499 0.0215482908 0.0226577557
 [38,] 0.4028485434 0.0067910468 0.0344962205 0.5226447566 0.0332194328
 [39,] 0.0438565219 0.2062097649 0.6351073755 0.0928670139 0.0219593237
 [40,] 0.0134892166 0.0008555545 0.0051384953 0.9782387428 0.0022779909
 [41,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [42,] 0.0551851236 0.0024853988 0.0148728443 0.9195044306 0.0079522027
 [43,] 0.7197337942 0.0056134195 0.0184453647 0.0688554489 0.1873519727
 [44,] 0.0685329750 0.0138158005 0.1711033416 0.7278513648 0.0186965181
 [45,] 0.0069285433 0.0052847682 0.9614923855 0.0235595760 0.0027347270
 [46,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [47,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [48,] 0.9993551441 0.0001061979 0.0001245819 0.0002383745 0.0001757016
 [49,] 0.3730515668 0.0067930924 0.0206138880 0.0656036076 0.5339378452
 [50,] 0.0002644410 0.9984169302 0.0007537054 0.0003646283 0.0002002949
 [51,] 0.9951427462 0.0002152037 0.0005427112 0.0024202886 0.0016790504
 [52,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [53,] 0.0874814217 0.0034129073 0.0199565453 0.8774306421 0.0117184836
 [54,] 0.0732435215 0.0224826629 0.4196350621 0.4618966478 0.0227421057
 [55,] 0.6314084603 0.0058997084 0.0278194565 0.2997681242 0.0351042505
 [56,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [57,] 0.2454574395 0.0056748866 0.0167004592 0.0504256079 0.6817416068
 [58,] 0.0134589506 0.0014752563 0.0115874444 0.9705389258 0.0029394229
 [59,] 0.7526278645 0.0051812302 0.0171721268 0.0653923300 0.1596264484
 [60,] 0.7479041866 0.0052468566 0.0173678581 0.0659424230 0.1635386756
 [61,] 0.0088260271 0.0009394376 0.0069022316 0.9814286994 0.0019036044
 [62,] 0.6354510291 0.0058655214 0.0276210528 0.2960351637 0.0350272330
 [63,] 0.0002644410 0.9984169302 0.0007537054 0.0003646283 0.0002002949
 [64,] 0.1806808878 0.0052339701 0.0290128428 0.7644753189 0.0205969804
 [65,] 0.9809874414 0.0005536389 0.0019573609 0.0117287613 0.0047727975
 [66,] 0.4028485434 0.0067910468 0.0344962205 0.5226447566 0.0332194328
 [67,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [68,] 0.5275303063 0.0070145161 0.0220262194 0.0747412958 0.3686876625
 [69,] 0.9994293980 0.0001043333 0.0001170758 0.0001938458 0.0001553472
 [70,] 0.6250049474 0.0065399064 0.0209968781 0.0745220148 0.2729362533
 [71,] 0.3894984623 0.0068739223 0.0209363442 0.0670744756 0.5156167956
 [72,] 0.3417991885 0.0066463265 0.0344832461 0.5862611424 0.0308100965
 [73,] 0.9665127260 0.0008875704 0.0033704630 0.0214681066 0.0077611340
 [74,] 0.9967375916 0.0001721256 0.0003878912 0.0017725478 0.0009298439
 [75,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [76,] 0.0438565219 0.2062097649 0.6351073755 0.0928670139 0.0219593237
 [77,] 0.3145256893 0.0063908716 0.0191333578 0.0594633546 0.6004867267
 [78,] 0.3951526543 0.0068985070 0.0210377706 0.0675538954 0.5093571728
 [79,] 0.9385483751 0.0014961033 0.0060163891 0.0412866572 0.0126524754
 [80,] 0.0134892166 0.0008555545 0.0051384953 0.9782387428 0.0022779909
 [81,] 0.0103353018 0.0073622140 0.9419121655 0.0363956511 0.0039946676
 [82,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [83,] 0.5812132820 0.0062728680 0.0300693968 0.3467282281 0.0357162251
 [84,] 0.1104359239 0.0039611311 0.0228193237 0.8486305657 0.0141530556
 [85,] 0.0013568242 0.0012374261 0.9926988844 0.0041050247 0.0006018406
 [86,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [87,] 0.0303036704 0.0851679637 0.8002278571 0.0698979903 0.0144025184
 [88,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [89,] 0.0013568242 0.0012374261 0.9926988844 0.0041050247 0.0006018406
 [90,] 0.0732435215 0.0224826629 0.4196350621 0.4618966478 0.0227421057
 [91,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [92,] 0.0031544097 0.0002631461 0.0005254295 0.0011406319 0.9949163829
 [93,] 0.0002644410 0.9984169302 0.0007537054 0.0003646283 0.0002002949
 [94,] 0.9908214480 0.0003180342 0.0009809773 0.0054046414 0.0024748990
 [95,] 0.0134892166 0.0008555545 0.0051384953 0.9782387428 0.0022779909
 [96,] 0.0022231170 0.0002784902 0.0014677196 0.9955162355 0.0005144378
 [97,] 0.0665489618 0.0129742408 0.1564701834 0.7460516678 0.0179549462
 [98,] 0.0202351861 0.0435616880 0.8775634864 0.0493131978 0.0093264417
 [99,] 0.0002644410 0.9984169302 0.0007537054 0.0003646283 0.0002002949
[100,] 0.0732435215 0.0224826629 0.4196350621 0.4618966478 0.0227421057
[101,] 0.0138140899 0.0252242123 0.9197502401 0.0349655414 0.0062459163
[102,] 0.0358542918 0.0182229931 0.7807326000 0.1524650287 0.0127250864
[103,] 0.0732435215 0.0224826629 0.4196350621 0.4618966478 0.0227421057

[[1]]$tau
[1] 0.152736807 0.660113623 0.408898100 0.261526172 0.008652174

[[1]]$phi
[1] 0.2 0.2 0.2 0.2 0.2

[[1]]$kappa
[1] 5


ELBO for this run: -9391.43
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.013101 seconds 
1000 transitions using 10 leapfrog steps per transition would take 131.01 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -9648.429             1.000            1.000 
     2        -9522.237             0.507            1.000 
     3        -9370.339             0.343            0.016 
     4        -9302.591             0.259            0.016 
     5        -9275.345             0.208            0.013 
     6        -9254.388             0.174            0.013 
     7        -9228.550             0.149            0.007 
     8        -9225.853             0.131            0.007 
     9        -9202.529             0.116            0.003 
    10        -9193.043             0.105            0.003 
    11        -9190.721             0.095            0.003 
    12        -9182.255             0.087            0.003 
    13        -9167.067             0.081            0.003 
    14        -9174.616             0.075            0.003 
    15        -9160.030             0.070            0.002 
    16        -9161.545             0.066            0.002 
    17        -9163.425             0.062            0.002 
    18        -9154.855             0.059            0.002 
    19        -9147.865             0.056            0.002 
    20        -9136.507             0.053            0.002 
    21        -9145.935             0.003            0.001 
    22        -9132.033             0.002            0.001 
    23        -9142.207             0.002            0.001 
    24        -9133.062             0.001            0.001 
    25        -9132.714             0.001            0.001 
    26        -9131.418             0.001            0.001 
    27        -9124.433             0.001            0.001 
    28        -9121.592             0.001            0.001 
    29        -9121.776             0.001            0.001 
    30        -9125.798             0.001            0.001 
    31        -9119.390             0.001            0.001 
    32        -9113.508             0.001            0.001 
    33        -9117.944             0.001            0.001 
    34        -9109.523             0.001            0.001 
    35        -9112.533             0.001            0.001 
    36        -9110.115             0.001            0.001 
    37        -9108.091             0.001            0.001 
    38        -9104.694             0.001            0.001 
    39        -9103.853             0.001            0.000 
    40        -9105.555             0.001            0.000 
    41        -9102.814             0.000            0.000 
    42        -9103.931             0.000            0.000 
    43        -9103.724             0.000            0.000 
    44        -9098.169             0.000            0.000 
    45        -9101.512             0.000            0.000 
    46        -9097.954             0.000            0.000 
    47        -9099.873             0.000            0.000 
    48        -9095.879             0.000            0.000 
    49        -9095.413             0.000            0.000 
    50        -9093.563             0.000            0.000 
    51        -9091.743             0.000            0.000 
    52        -9095.113             0.000            0.000 
    53        -9090.902             0.000            0.000 
    54        -9086.710             0.000            0.000 
    55        -9091.437             0.000            0.000 
    56        -9084.680             0.000            0.000 
    57        -9084.852             0.000            0.000 
    58        -9085.861             0.000            0.000 
    59        -9086.032             0.000            0.000 
    60        -9086.195             0.000            0.000 
    61        -9084.315             0.000            0.000 
    62        -9086.294             0.000            0.000 
    63        -9085.022             0.000            0.000 
    64        -9080.603             0.000            0.000 
    65        -9079.275             0.000            0.000 
    66        -9081.876             0.000            0.000 
    67        -9082.219             0.000            0.000 
    68        -9077.018             0.000            0.000 
    69        -9076.559             0.000            0.000 
    70        -9078.871             0.000            0.000 
    71        -9081.019             0.000            0.000 
    72        -9079.017             0.000            0.000 
    73        -9081.861             0.000            0.000 
    74        -9077.026             0.000            0.000 
    75        -9079.842             0.000            0.000 
    76        -9077.656             0.000            0.000 
    77        -9077.502             0.000            0.000 
    78        -9077.132             0.000            0.000 
    79        -9077.679             0.000            0.000 
    80        -9076.975             0.000            0.000 
    81        -9075.081             0.000            0.000 
    82        -9073.128             0.000            0.000 
    83        -9075.698             0.000            0.000 
    84        -9071.567             0.000            0.000 
    85        -9074.533             0.000            0.000 
    86        -9072.969             0.000            0.000 
    87        -9070.617             0.000            0.000 
    88        -9072.131             0.000            0.000 
    89        -9071.486             0.000            0.000 
    90        -9074.896             0.000            0.000 
    91        -9069.843             0.000            0.000 
    92        -9071.151             0.000            0.000 
    93        -9067.946             0.000            0.000 
    94        -9070.991             0.000            0.000 
    95        -9070.110             0.000            0.000 
Chain 1 stan::variational::advi::calc_ELBO: The number of dropped evaluations has reached its maximum amount (100). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  95.4 seconds.
An error occurred during inference: Fitting failed. Unable to retrieve the metadata.
Error processing 0009b464-b376-4fbc-8a56-da538269a02f: object 'tol_rel_obj' not found
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
Error processing 003819bc-c415-4e76-887c-931d60ed39e7: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
ℹ Adding segment with index 2 to segments included in the inference.
[1] 3
[1] 4
ℹ Adding segment with index 4 to segments included in the inference.
[1] 5
ℹ Adding segment with index 5 to segments included in the inference.
[1] 6
ℹ Adding segment with index 6 to segments included in the inference.
[1] 7
[1] 8
ℹ Adding segment with index 8 to segments included in the inference.
[1] 9
[1] 10
ℹ Adding segment with index 10 to segments included in the inference.
[1] 11
[1] 12
ℹ Adding segment with index 12 to segments included in the inference.
[1] 13
ℹ Adding segment with index 13 to segments included in the inference.
[1] 14
[1] 15
[1] 16
ℹ Adding segment with index 16 to segments included in the inference.
[1] 17
ℹ Adding segment with index 17 to segments included in the inference.
[1] 18
[1] 19
ℹ Adding segment with index 19 to segments included in the inference.
[1] 20
ℹ Adding segment with index 20 to segments included in the inference.
[1] 21
ℹ Adding segment with index 21 to segments included in the inference.
[1] 22
[1] 23
ℹ Adding segment with index 23 to segments included in the inference.
[1] 24
[1] 25
ℹ Adding segment with index 25 to segments included in the inference.
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
ℹ Adding segment with index 36 to segments included in the inference.
[1] 37
[1] 38
ℹ Adding segment with index 38 to segments included in the inference.
[1] 39
[1] 40
ℹ Adding segment with index 40 to segments included in the inference.
[1] 41
ℹ Adding segment with index 41 to segments included in the inference.
[1] 42
ℹ Adding segment with index 42 to segments included in the inference.
[1] 43
ℹ Adding segment with index 43 to segments included in the inference.
[1] 44
[1] 45
ℹ Adding segment with index 45 to segments included in the inference.
[1] 46
[1] 47
ℹ Adding segment with index 47 to segments included in the inference.
[1] 48
ℹ Adding segment with index 48 to segments included in the inference.
[1] 49
ℹ Adding segment with index 49 to segments included in the inference.
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
ℹ Adding segment with index 54 to segments included in the inference.
[1] 55
[1] 56
ℹ Adding segment with index 56 to segments included in the inference.
[1] 57
ℹ Adding segment with index 57 to segments included in the inference.
[1] 58
ℹ Adding segment with index 58 to segments included in the inference.
[1] 59
ℹ Adding segment with index 59 to segments included in the inference.
[1] 60
ℹ Adding segment with index 60 to segments included in the inference.
[1] 61
[1] 62
ℹ Adding segment with index 62 to segments included in the inference.
[1] 63
[1] 64
ℹ Adding segment with index 64 to segments included in the inference.
[1] 65
[1] 66
[1] 67
[1] 68
ℹ Adding segment with index 68 to segments included in the inference.
[1] 69
[1] 70
ℹ Adding segment with index 70 to segments included in the inference.
[1] 71
ℹ Adding segment with index 71 to segments included in the inference.
[1] 72
ℹ Adding segment with index 72 to segments included in the inference.
[1] 73
[1] 74
ℹ Adding segment with index 74 to segments included in the inference.
[1] 75
[1] 76
ℹ Adding segment with index 76 to segments included in the inference.
[1] 77
ℹ Adding segment with index 77 to segments included in the inference.
[1] 78
ℹ Adding segment with index 78 to segments included in the inference.
[1] 79
ℹ Adding segment with index 79 to segments included in the inference.
[1] 80
[1] 81
ℹ Adding segment with index 81 to segments included in the inference.
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
ℹ Adding segment with index 87 to segments included in the inference.
[1] 88
[1] 89
ℹ Adding segment with index 89 to segments included in the inference.
[1] 90
ℹ Adding segment with index 90 to segments included in the inference.
[1] 91
[1] 92
ℹ Adding segment with index 92 to segments included in the inference.
[1] 93
ℹ Adding segment with index 93 to segments included in the inference.
[1] 94
ℹ Adding segment with index 94 to segments included in the inference.
[1] 95
ℹ Adding segment with index 95 to segments included in the inference.
[1] 96
ℹ Adding segment with index 96 to segments included in the inference.
[1] 97
ℹ Adding segment with index 97 to segments included in the inference.
[1] 98
ℹ Adding segment with index 98 to segments included in the inference.
[1] 99
ℹ Adding segment with index 99 to segments included in the inference.
[1] 100
ℹ Adding segment with index 100 to segments included in the inference.
[1] 101
ℹ Adding segment with index 101 to segments included in the inference.
[1] 102
[1] 103
ℹ Adding segment with index 103 to segments included in the inference.
[1] 104
ℹ Adding segment with index 104 to segments included in the inference.
[1] 105
ℹ Adding segment with index 105 to segments included in the inference.
[1] 106
ℹ Adding segment with index 106 to segments included in the inference.
[1] 107
ℹ Adding segment with index 107 to segments included in the inference.
init_taus from clustering  0.126723610065475Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.007522 seconds 
1000 transitions using 10 leapfrog steps per transition would take 75.22 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17664.863             1.000            1.000 
     2       -17610.638             0.502            1.000 
     3       -17602.406             0.335            0.003 
     4       -17599.289             0.251            0.003 
     5       -17596.484             0.201            0.000 
     6       -17598.957             0.167            0.000 
     7       -17594.896             0.143            0.000 
     8       -17597.229             0.126            0.000 
     9       -17595.088             0.112            0.000 
    10       -17594.458             0.100            0.000 
    11       -17596.730             0.091            0.000 
    12       -17596.552             0.084            0.000 
    13       -17597.509             0.077            0.000 
    14       -17595.385             0.072            0.000 
    15       -17595.783             0.067            0.000 
    16       -17592.433             0.063            0.000 
    17       -17591.726             0.059            0.000 
    18       -17594.870             0.056            0.000 
    19       -17592.278             0.053            0.000 
    20       -17593.916             0.050            0.000 
    21       -17592.819             0.000            0.000 
    22       -17593.736             0.000            0.000 
    23       -17595.389             0.000            0.000 
    24       -17593.988             0.000            0.000 
    25       -17592.183             0.000            0.000 
    26       -17593.751             0.000            0.000   MEAN ELBO CONVERGED   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  19.2 seconds.
[[1]]
[[1]]$w
      [,1]
 [1,]    1
 [2,]    1
 [3,]    1
 [4,]    1
 [5,]    1
 [6,]    1
 [7,]    1
 [8,]    1
 [9,]    1
[10,]    1
[11,]    1
[12,]    1
[13,]    1
[14,]    1
[15,]    1
[16,]    1
[17,]    1
[18,]    1
[19,]    1
[20,]    1
[21,]    1
[22,]    1
[23,]    1
[24,]    1
[25,]    1
[26,]    1
[27,]    1
[28,]    1
[29,]    1
[30,]    1
[31,]    1
[32,]    1
[33,]    1
[34,]    1
[35,]    1
[36,]    1
[37,]    1
[38,]    1
[39,]    1
[40,]    1
[41,]    1
[42,]    1
[43,]    1
[44,]    1
[45,]    1
[46,]    1
[47,]    1
[48,]    1
[49,]    1
[50,]    1
[51,]    1
[52,]    1
[53,]    1
[54,]    1
[55,]    1
[56,]    1
[57,]    1
[58,]    1
[59,]    1
[60,]    1
[61,]    1

[[1]]$tau
[1] 0.1267236

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -17602.4
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.00702 seconds 
1000 transitions using 10 leapfrog steps per transition would take 70.2 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17614.078             1.000            1.000 
     2       -17604.690             0.500            1.000 
     3       -17602.862             0.334            0.001 
     4       -17597.172             0.250            0.001 
     5       -17598.208             0.200            0.000 
     6       -17594.293             0.167            0.000 
     7       -17595.573             0.143            0.000 
     8       -17595.158             0.125            0.000 
     9       -17594.055             0.111            0.000 
    10       -17594.161             0.100            0.000 
    11       -17593.783             0.091            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  16.3 seconds.
[[1]]
[[1]]$w
      [,1]
 [1,]    1
 [2,]    1
 [3,]    1
 [4,]    1
 [5,]    1
 [6,]    1
 [7,]    1
 [8,]    1
 [9,]    1
[10,]    1
[11,]    1
[12,]    1
[13,]    1
[14,]    1
[15,]    1
[16,]    1
[17,]    1
[18,]    1
[19,]    1
[20,]    1
[21,]    1
[22,]    1
[23,]    1
[24,]    1
[25,]    1
[26,]    1
[27,]    1
[28,]    1
[29,]    1
[30,]    1
[31,]    1
[32,]    1
[33,]    1
[34,]    1
[35,]    1
[36,]    1
[37,]    1
[38,]    1
[39,]    1
[40,]    1
[41,]    1
[42,]    1
[43,]    1
[44,]    1
[45,]    1
[46,]    1
[47,]    1
[48,]    1
[49,]    1
[50,]    1
[51,]    1
[52,]    1
[53,]    1
[54,]    1
[55,]    1
[56,]    1
[57,]    1
[58,]    1
[59,]    1
[60,]    1
[61,]    1

[[1]]$tau
[1] 0.203021

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -17602.9
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181920-1-4097c3.csv\n"
init_taus from clustering  0.0539621530155358 init_taus from clustering  0.698425015317963Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.011098 seconds 
1000 transitions using 10 leapfrog steps per transition would take 110.98 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17449.047             1.000            1.000 
     2       -17328.592             0.503            1.000 
     3       -17321.896             0.336            0.007 
     4       -17321.668             0.252            0.007 
     5       -17313.939             0.202            0.000 
     6       -17311.740             0.168            0.000 
     7       -17310.021             0.144            0.000 
     8       -17306.004             0.126            0.000 
     9       -17308.139             0.112            0.000 
    10       -17309.235             0.101            0.000 
    11       -17304.064             0.092            0.000 
    12       -17302.199             0.084            0.000 
    13       -17301.918             0.078            0.000 
    14       -17298.868             0.072            0.000 
    15       -17297.165             0.067            0.000 
    16       -17298.577             0.063            0.000 
    17       -17300.418             0.059            0.000 
    18       -17296.898             0.056            0.000 
    19       -17303.808             0.053            0.000 
    20       -17295.593             0.051            0.000 
    21       -17296.673             0.001            0.000 
    22       -17296.070             0.000            0.000 
    23       -17294.740             0.000            0.000 
    24       -17294.426             0.000            0.000 
    25       -17295.974             0.000            0.000 
    26       -17295.321             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  30.9 seconds.
[[1]]
[[1]]$w
            [,1]         [,2]
 [1,] 0.99491730 0.0050826985
 [2,] 0.99589060 0.0041094024
 [3,] 0.99983569 0.0001643084
 [4,] 0.99400739 0.0059926080
 [5,] 0.99400739 0.0059926080
 [6,] 0.99952800 0.0004720005
 [7,] 0.99982928 0.0001707241
 [8,] 0.99804003 0.0019599706
 [9,] 0.99929124 0.0007087647
[10,] 0.99973360 0.0002664030
[11,] 0.92066915 0.0793308520
[12,] 0.75484071 0.2451592935
[13,] 0.72185801 0.2781419877
[14,] 0.83289739 0.1671026095
[15,] 0.99400739 0.0059926080
[16,] 0.99905633 0.0009436705
[17,] 0.99400739 0.0059926080
[18,] 0.99878528 0.0012147155
[19,] 0.99400739 0.0059926080
[20,] 0.99400739 0.0059926080
[21,] 0.99914503 0.0008549668
[22,] 0.99400739 0.0059926080
[23,] 0.99894626 0.0010537418
[24,] 0.99400739 0.0059926080
[25,] 0.99975882 0.0002411850
[26,] 0.99916546 0.0008345374
[27,] 0.99884462 0.0011553827
[28,] 0.99966605 0.0003339458
[29,] 0.99400739 0.0059926080
[30,] 0.99400739 0.0059926080
[31,] 0.99835714 0.0016428571
[32,] 0.99400739 0.0059926080
[33,] 0.99741392 0.0025860805
[34,] 0.19129055 0.8087094450
[35,] 0.00808128 0.9919187201
[36,] 0.09232642 0.9076735765
[37,] 0.99963327 0.0003667307
[38,] 0.99959795 0.0004020470
[39,] 0.09232642 0.9076735765
[40,] 0.99931833 0.0006816741
[41,] 0.99838859 0.0016114080
[42,] 0.99400739 0.0059926080
[43,] 0.99953608 0.0004639207
[44,] 0.99400739 0.0059926080
[45,] 0.53858111 0.4614188878
[46,] 0.88871246 0.1112875447
[47,] 0.25514049 0.7448595095
[48,] 0.11716413 0.8828358714
[49,] 0.99989919 0.0001008062
[50,] 0.99973759 0.0002624086
[51,] 0.99925987 0.0007401282
[52,] 0.99400739 0.0059926080
[53,] 0.99400739 0.0059926080
[54,] 0.99400739 0.0059926080
[55,] 0.99851537 0.0014846338
[56,] 0.99977582 0.0002241781
[57,] 0.99400739 0.0059926080
[58,] 0.88871246 0.1112875447
[59,] 0.99400739 0.0059926080
[60,] 0.99837209 0.0016279116
[61,] 0.95678307 0.0432169305

[[1]]$tau
[1] 0.05396215 0.69842502

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -17321.9
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.01171 seconds 
1000 transitions using 10 leapfrog steps per transition would take 117.1 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17358.080             1.000            1.000 
     2       -17340.666             0.501            1.000 
     3       -17332.348             0.334            0.001 
     4       -17329.356             0.250            0.001 
     5       -17322.746             0.200            0.000 
     6       -17322.190             0.167            0.000 
     7       -17318.758             0.143            0.000 
     8       -17317.738             0.125            0.000 
     9       -17311.509             0.111            0.000 
    10       -17307.204             0.100            0.000 
    11       -17304.274             0.091            0.000 
    12       -17304.382             0.084            0.000 
    13       -17305.799             0.077            0.000 
    14       -17305.414             0.072            0.000 
    15       -17304.543             0.067            0.000 
    16       -17300.944             0.063            0.000 
    17       -17303.892             0.059            0.000 
    18       -17302.507             0.056            0.000 
    19       -17298.395             0.053            0.000 
    20       -17299.783             0.050            0.000 
    21       -17299.606             0.000            0.000 
    22       -17295.060             0.000            0.000 
    23       -17299.415             0.000            0.000 
    24       -17300.691             0.000            0.000 
    25       -17295.523             0.000            0.000 
    26       -17294.946             0.000            0.000 
    27       -17294.588             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  61.4 seconds.
[[1]]
[[1]]$w
            [,1]         [,2]
 [1,] 0.99491730 0.0050826985
 [2,] 0.99589060 0.0041094024
 [3,] 0.99983569 0.0001643084
 [4,] 0.99400739 0.0059926080
 [5,] 0.99400739 0.0059926080
 [6,] 0.99952800 0.0004720005
 [7,] 0.99982928 0.0001707241
 [8,] 0.99804003 0.0019599706
 [9,] 0.99929124 0.0007087647
[10,] 0.99973360 0.0002664030
[11,] 0.92066915 0.0793308520
[12,] 0.75484071 0.2451592935
[13,] 0.72185801 0.2781419877
[14,] 0.83289739 0.1671026095
[15,] 0.99400739 0.0059926080
[16,] 0.99905633 0.0009436705
[17,] 0.99400739 0.0059926080
[18,] 0.99878528 0.0012147155
[19,] 0.99400739 0.0059926080
[20,] 0.99400739 0.0059926080
[21,] 0.99914503 0.0008549668
[22,] 0.99400739 0.0059926080
[23,] 0.99894626 0.0010537418
[24,] 0.99400739 0.0059926080
[25,] 0.99975882 0.0002411850
[26,] 0.99916546 0.0008345374
[27,] 0.99884462 0.0011553827
[28,] 0.99966605 0.0003339458
[29,] 0.99400739 0.0059926080
[30,] 0.99400739 0.0059926080
[31,] 0.99835714 0.0016428571
[32,] 0.99400739 0.0059926080
[33,] 0.99741392 0.0025860805
[34,] 0.19129055 0.8087094450
[35,] 0.00808128 0.9919187201
[36,] 0.09232642 0.9076735765
[37,] 0.99963327 0.0003667307
[38,] 0.99959795 0.0004020470
[39,] 0.09232642 0.9076735765
[40,] 0.99931833 0.0006816741
[41,] 0.99838859 0.0016114080
[42,] 0.99400739 0.0059926080
[43,] 0.99953608 0.0004639207
[44,] 0.99400739 0.0059926080
[45,] 0.53858111 0.4614188878
[46,] 0.88871246 0.1112875447
[47,] 0.25514049 0.7448595095
[48,] 0.11716413 0.8828358714
[49,] 0.99989919 0.0001008062
[50,] 0.99973759 0.0002624086
[51,] 0.99925987 0.0007401282
[52,] 0.99400739 0.0059926080
[53,] 0.99400739 0.0059926080
[54,] 0.99400739 0.0059926080
[55,] 0.99851537 0.0014846338
[56,] 0.99977582 0.0002241781
[57,] 0.99400739 0.0059926080
[58,] 0.88871246 0.1112875447
[59,] 0.99400739 0.0059926080
[60,] 0.99837209 0.0016279116
[61,] 0.95678307 0.0432169305

[[1]]$tau
[1] 0.0700000 0.6374898

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -17332.3
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181921-1-76e29b.csv\n"
init_taus from clustering  0.0336287995231195 init_taus from clustering  0.335393141790927 init_taus from clustering  0.9313640457244Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.015371 seconds 
1000 transitions using 10 leapfrog steps per transition would take 153.71 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17579.376             1.000            1.000 
     2       -17474.524             0.503            1.000 
     3       -17416.500             0.336            0.006 
     4       -17399.844             0.253            0.006 
     5       -17390.522             0.202            0.003 
     6       -17378.503             0.169            0.003 
     7       -17372.297             0.145            0.001 
     8       -17361.914             0.127            0.001 
     9       -17356.139             0.113            0.001 
    10       -17350.391             0.101            0.001 
    11       -17351.719             0.092            0.001 
    12       -17340.855             0.084            0.001 
    13       -17337.098             0.078            0.001 
    14       -17335.848             0.072            0.001 
    15       -17336.144             0.068            0.001 
    16       -17333.624             0.063            0.001 
    17       -17328.146             0.060            0.000 
    18       -17328.942             0.056            0.000 
    19       -17326.557             0.053            0.000 
    20       -17327.661             0.051            0.000 
    21       -17323.036             0.001            0.000 
    22       -17325.402             0.000            0.000 
    23       -17322.066             0.000            0.000 
    24       -17319.750             0.000            0.000 
    25       -17319.979             0.000            0.000 
    26       -17318.062             0.000            0.000 
    27       -17321.184             0.000            0.000 
    28       -17318.094             0.000            0.000 
    29       -17320.331             0.000            0.000 
    30       -17314.800             0.000            0.000 
    31       -17314.050             0.000            0.000 
    32       -17317.097             0.000            0.000 
    33       -17316.096             0.000            0.000 
    34       -17314.363             0.000            0.000 
    35       -17313.506             0.000            0.000 
    36       -17314.978             0.000            0.000 
    37       -17311.042             0.000            0.000 
    38       -17314.291             0.000            0.000 
    39       -17310.738             0.000            0.000 
    40       -17312.572             0.000            0.000 
    41       -17310.532             0.000            0.000 
    42       -17309.948             0.000            0.000 
    43       -17310.896             0.000            0.000 
    44       -17310.261             0.000            0.000 
    45       -17309.646             0.000            0.000 
    46       -17309.306             0.000            0.000 
    47       -17309.646             0.000            0.000 
    48       -17308.504             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  58.2 seconds.
[[1]]
[[1]]$w
             [,1]         [,2]         [,3]
 [1,] 0.929962951 0.0646532939 0.0053837549
 [2,] 0.994043130 0.0052191634 0.0007377062
 [3,] 0.996733733 0.0028737402 0.0003925269
 [4,] 0.988693312 0.0099326053 0.0013740827
 [5,] 0.988693312 0.0099326053 0.0013740827
 [6,] 0.999049462 0.0007766822 0.0001738562
 [7,] 0.996841246 0.0027761774 0.0003825770
 [8,] 0.998914899 0.0008921767 0.0001929246
 [9,] 0.980279080 0.0179243430 0.0017965772
[10,] 0.997935228 0.0017844463 0.0002803257
[11,] 0.389445048 0.5902645268 0.0202904254
[12,] 0.033637961 0.9610255428 0.0053364967
[13,] 0.016563897 0.9803813433 0.0030547601
[14,] 0.121069420 0.8661349780 0.0127956017
[15,] 0.988693312 0.0099326053 0.0013740827
[16,] 0.999786664 0.0001120116 0.0001013243
[17,] 0.988693312 0.0099326053 0.0013740827
[18,] 0.999754523 0.0001408486 0.0001046283
[19,] 0.988693312 0.0099326053 0.0013740827
[20,] 0.988693312 0.0099326053 0.0013740827
[21,] 0.999744622 0.0001498271 0.0001055509
[22,] 0.988693312 0.0099326053 0.0013740827
[23,] 0.999799490 0.0001004820 0.0001000279
[24,] 0.988693312 0.0099326053 0.0013740827
[25,] 0.988522249 0.0103606709 0.0011170798
[26,] 0.978439472 0.0196172009 0.0019433267
[27,] 0.974043264 0.0236689288 0.0022878069
[28,] 0.986556768 0.0121605456 0.0012826864
[29,] 0.988693312 0.0099326053 0.0013740827
[30,] 0.988693312 0.0099326053 0.0013740827
[31,] 0.999370692 0.0004847108 0.0001445969
[32,] 0.988693312 0.0099326053 0.0013740827
[33,] 0.997741763 0.0019382017 0.0003200349
[34,] 0.091447380 0.8128738558 0.0956787639
[35,] 0.044743132 0.1302548001 0.8250020681
[36,] 0.005064927 0.0105971783 0.9843378947
[37,] 0.985926432 0.0127382842 0.0013352842
[38,] 0.998770177 0.0010290062 0.0002008164
[39,] 0.005064927 0.0105971783 0.9843378947
[40,] 0.980687106 0.0175490873 0.0017638071
[41,] 0.968248403 0.0290218563 0.0027297405
[42,] 0.988693312 0.0099326053 0.0013740827
[43,] 0.999020843 0.0008025282 0.0001766289
[44,] 0.988693312 0.0099326053 0.0013740827
[45,] 0.007399718 0.9900313816 0.0025689003
[46,] 0.259171059 0.7223715504 0.0184573908
[47,] 0.074360056 0.8644998836 0.0611400609
[48,] 0.109514948 0.7283988314 0.1620862209
[49,] 0.994422056 0.0049749938 0.0006029504
[50,] 0.997901621 0.0018148827 0.0002834967
[51,] 0.999638398 0.0002454541 0.0001161481
[52,] 0.988693312 0.0099326053 0.0013740827
[53,] 0.988693312 0.0099326053 0.0013740827
[54,] 0.988693312 0.0099326053 0.0013740827
[55,] 0.969820253 0.0275686010 0.0026111463
[56,] 0.997538315 0.0021440366 0.0003176485
[57,] 0.988693312 0.0099326053 0.0013740827
[58,] 0.259171059 0.7223715504 0.0184573908
[59,] 0.988693312 0.0099326053 0.0013740827
[60,] 0.968045615 0.0292094108 0.0027449740
[61,] 0.604290134 0.3772734474 0.0184364187

[[1]]$tau
[1] 0.0336288 0.3353931 0.8800000

[[1]]$phi
[1] 0.3333333 0.3333333 0.3333333

[[1]]$kappa
[1] 5


ELBO for this run: -17416.5
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.016682 seconds 
1000 transitions using 10 leapfrog steps per transition would take 166.82 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -19542.549             1.000            1.000 
     2       -18965.603             0.515            1.000 
     3       -18324.094             0.355            0.035 
     4       -18132.736             0.269            0.035 
     5       -17980.990             0.217            0.030 
     6       -17867.540             0.182            0.030 
     7       -17833.755             0.156            0.011 
     8       -17776.410             0.137            0.011 
     9       -17772.926             0.122            0.008 
    10       -17731.181             0.110            0.008 
    11       -17714.224             0.100            0.006 
    12       -17688.878             0.092            0.006 
    13       -17670.041             0.085            0.003 
    14       -17648.576             0.079            0.003 
    15       -17638.436             0.074            0.002 
    16       -17611.984             0.069            0.002 
    17       -17591.168             0.065            0.002 
    18       -17564.869             0.062            0.002 
    19       -17551.345             0.058            0.002 
    20       -17519.981             0.056            0.002 
    21       -17502.458             0.006            0.002 
    22       -17480.421             0.004            0.001 
    23       -17469.365             0.002            0.001 
    24       -17457.947             0.002            0.001 
    25       -17448.161             0.002            0.001 
    26       -17429.523             0.001            0.001 
    27       -17418.792             0.001            0.001 
    28       -17411.755             0.001            0.001 
    29       -17409.315             0.001            0.001 
    30       -17406.423             0.001            0.001 
    31       -17398.138             0.001            0.001 
    32       -17397.050             0.001            0.001 
    33       -17392.253             0.001            0.001 
    34       -17384.519             0.001            0.001 
    35       -17380.929             0.001            0.001 
    36       -17377.709             0.001            0.001 
    37       -17373.833             0.001            0.001 
    38       -17370.259             0.001            0.000 
    39       -17368.166             0.001            0.000 
    40       -17362.027             0.000            0.000 
    41       -17360.334             0.000            0.000 
    42       -17357.230             0.000            0.000 
    43       -17356.763             0.000            0.000 
    44       -17355.008             0.000            0.000 
    45       -17350.822             0.000            0.000 
    46       -17347.429             0.000            0.000 
    47       -17345.676             0.000            0.000 
    48       -17346.390             0.000            0.000 
    49       -17340.510             0.000            0.000 
    50       -17339.384             0.000            0.000 
    51       -17337.076             0.000            0.000 
    52       -17336.322             0.000            0.000 
    53       -17333.145             0.000            0.000 
    54       -17332.814             0.000            0.000 
    55       -17330.999             0.000            0.000 
    56       -17329.035             0.000            0.000 
    57       -17328.645             0.000            0.000 
    58       -17328.065             0.000            0.000 
    59       -17324.795             0.000            0.000 
    60       -17322.784             0.000            0.000 
    61       -17324.240             0.000            0.000 
    62       -17321.818             0.000            0.000 
    63       -17322.931             0.000            0.000 
    64       -17319.163             0.000            0.000 
    65       -17319.513             0.000            0.000 
    66       -17319.072             0.000            0.000 
    67       -17319.932             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  73.6 seconds.
[[1]]
[[1]]$w
             [,1]         [,2]         [,3]
 [1,] 0.929962951 0.0646532939 0.0053837549
 [2,] 0.994043130 0.0052191634 0.0007377062
 [3,] 0.996733733 0.0028737402 0.0003925269
 [4,] 0.988693312 0.0099326053 0.0013740827
 [5,] 0.988693312 0.0099326053 0.0013740827
 [6,] 0.999049462 0.0007766822 0.0001738562
 [7,] 0.996841246 0.0027761774 0.0003825770
 [8,] 0.998914899 0.0008921767 0.0001929246
 [9,] 0.980279080 0.0179243430 0.0017965772
[10,] 0.997935228 0.0017844463 0.0002803257
[11,] 0.389445048 0.5902645268 0.0202904254
[12,] 0.033637961 0.9610255428 0.0053364967
[13,] 0.016563897 0.9803813433 0.0030547601
[14,] 0.121069420 0.8661349780 0.0127956017
[15,] 0.988693312 0.0099326053 0.0013740827
[16,] 0.999786664 0.0001120116 0.0001013243
[17,] 0.988693312 0.0099326053 0.0013740827
[18,] 0.999754523 0.0001408486 0.0001046283
[19,] 0.988693312 0.0099326053 0.0013740827
[20,] 0.988693312 0.0099326053 0.0013740827
[21,] 0.999744622 0.0001498271 0.0001055509
[22,] 0.988693312 0.0099326053 0.0013740827
[23,] 0.999799490 0.0001004820 0.0001000279
[24,] 0.988693312 0.0099326053 0.0013740827
[25,] 0.988522249 0.0103606709 0.0011170798
[26,] 0.978439472 0.0196172009 0.0019433267
[27,] 0.974043264 0.0236689288 0.0022878069
[28,] 0.986556768 0.0121605456 0.0012826864
[29,] 0.988693312 0.0099326053 0.0013740827
[30,] 0.988693312 0.0099326053 0.0013740827
[31,] 0.999370692 0.0004847108 0.0001445969
[32,] 0.988693312 0.0099326053 0.0013740827
[33,] 0.997741763 0.0019382017 0.0003200349
[34,] 0.091447380 0.8128738558 0.0956787639
[35,] 0.044743132 0.1302548001 0.8250020681
[36,] 0.005064927 0.0105971783 0.9843378947
[37,] 0.985926432 0.0127382842 0.0013352842
[38,] 0.998770177 0.0010290062 0.0002008164
[39,] 0.005064927 0.0105971783 0.9843378947
[40,] 0.980687106 0.0175490873 0.0017638071
[41,] 0.968248403 0.0290218563 0.0027297405
[42,] 0.988693312 0.0099326053 0.0013740827
[43,] 0.999020843 0.0008025282 0.0001766289
[44,] 0.988693312 0.0099326053 0.0013740827
[45,] 0.007399718 0.9900313816 0.0025689003
[46,] 0.259171059 0.7223715504 0.0184573908
[47,] 0.074360056 0.8644998836 0.0611400609
[48,] 0.109514948 0.7283988314 0.1620862209
[49,] 0.994422056 0.0049749938 0.0006029504
[50,] 0.997901621 0.0018148827 0.0002834967
[51,] 0.999638398 0.0002454541 0.0001161481
[52,] 0.988693312 0.0099326053 0.0013740827
[53,] 0.988693312 0.0099326053 0.0013740827
[54,] 0.988693312 0.0099326053 0.0013740827
[55,] 0.969820253 0.0275686010 0.0026111463
[56,] 0.997538315 0.0021440366 0.0003176485
[57,] 0.988693312 0.0099326053 0.0013740827
[58,] 0.259171059 0.7223715504 0.0184573908
[59,] 0.988693312 0.0099326053 0.0013740827
[60,] 0.968045615 0.0292094108 0.0027449740
[61,] 0.604290134 0.3772734474 0.0184364187

[[1]]$tau
[1] 0.8800000 0.1385073 0.2940615

[[1]]$phi
[1] 0.3333333 0.3333333 0.3333333

[[1]]$kappa
[1] 5


ELBO for this run: -18324.1
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181923-1-94aa15.csv\n"
init_taus from clustering  0.242615198952303 init_taus from clustering  0.968249932241451 init_taus from clustering  0.0304682639875565 init_taus from clustering  0.491756507488192Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.020797 seconds 
1000 transitions using 10 leapfrog steps per transition would take 207.97 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17566.822             1.000            1.000 
     2       -17498.818             0.502            1.000 
     3       -17461.923             0.335            0.004 
     4       -17448.281             0.252            0.004 
     5       -17419.283             0.202            0.002 
     6       -17422.396             0.168            0.002 
     7       -17418.648             0.144            0.002 
     8       -17408.656             0.126            0.002 
     9       -17401.941             0.112            0.001 
    10       -17398.767             0.101            0.001 
    11       -17392.865             0.092            0.001 
    12       -17392.827             0.084            0.001 
    13       -17389.247             0.078            0.000 
    14       -17393.110             0.072            0.000 
    15       -17387.159             0.067            0.000 
    16       -17380.706             0.063            0.000 
    17       -17379.733             0.060            0.000 
    18       -17373.077             0.056            0.000 
    19       -17370.717             0.053            0.000 
    20       -17370.292             0.051            0.000 
    21       -17373.144             0.001            0.000 
    22       -17367.309             0.000            0.000 
    23       -17366.980             0.000            0.000 
    24       -17367.387             0.000            0.000 
    25       -17368.278             0.000            0.000 
    26       -17363.286             0.000            0.000 
    27       -17356.169             0.000            0.000 
    28       -17358.516             0.000            0.000 
    29       -17360.364             0.000            0.000 
    30       -17360.350             0.000            0.000 
    31       -17356.330             0.000            0.000 
    32       -17355.764             0.000            0.000 
    33       -17357.490             0.000            0.000 
    34       -17358.681             0.000            0.000 
    35       -17357.359             0.000            0.000 
    36       -17353.164             0.000            0.000 
    37       -17358.231             0.000            0.000 
    38       -17356.596             0.000            0.000 
    39       -17352.888             0.000            0.000 
    40       -17352.792             0.000            0.000 
    41       -17352.134             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  122.1 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]
 [1,] 0.1653561158 0.0047395531 0.8072321250 0.0226722062
 [2,] 0.0075623958 0.0005388504 0.9900612903 0.0018374635
 [3,] 0.0088932789 0.0004908427 0.9888319636 0.0017839148
 [4,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
 [5,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
 [6,] 0.0029742492 0.0002355495 0.9961161026 0.0006740986
 [7,] 0.0086291374 0.0004798910 0.9891552166 0.0017357549
 [8,] 0.0007569489 0.0001349577 0.9988652431 0.0002428503
 [9,] 0.0479433872 0.0018752499 0.9420391136 0.0081422493
[10,] 0.0059026319 0.0003646688 0.9925008459 0.0012318534
[11,] 0.9197601709 0.0029116970 0.0577205383 0.0196075937
[12,] 0.9216554433 0.0041812006 0.0286082558 0.0455551004
[13,] 0.8718861529 0.0067182222 0.0404563036 0.0809393213
[14,] 0.9951962116 0.0003220012 0.0023858556 0.0020959316
[15,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[16,] 0.0005083632 0.0001202217 0.9991869302 0.0001844849
[17,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[18,] 0.0001333123 0.0001016517 0.9996580655 0.0001069705
[19,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[20,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[21,] 0.0007497949 0.0001319414 0.9988845680 0.0002336957
[22,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[23,] 0.0002979248 0.0001098740 0.9994509993 0.0001412019
[24,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[25,] 0.0284976950 0.0012326134 0.9651387729 0.0051309187
[26,] 0.0522789248 0.0020092838 0.9369298644 0.0087819269
[27,] 0.0626359948 0.0023179017 0.9247766058 0.0102694978
[28,] 0.0331391368 0.0013928520 0.9595951161 0.0058728952
[29,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[30,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[31,] 0.0002791380 0.0001093227 0.9994731274 0.0001384119
[32,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[33,] 0.0022664249 0.0002192855 0.9969321257 0.0005821638
[34,] 0.0003907489 0.0001754828 0.0001834696 0.9992502988
[35,] 0.0867616468 0.5491742268 0.0437824484 0.3202816779
[36,] 0.0018448517 0.9930155273 0.0011647834 0.0039748376
[37,] 0.0346266746 0.0014432223 0.9578227194 0.0061073838
[38,] 0.0037353980 0.0002697548 0.9951738081 0.0008210391
[39,] 0.0018448517 0.9930155273 0.0011647834 0.0039748376
[40,] 0.0469816439 0.0018451034 0.9431743398 0.0079989129
[41,] 0.0762761212 0.0027019639 0.9088728795 0.0121490354
[42,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[43,] 0.0030536291 0.0002391412 0.9960177326 0.0006894971
[44,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[45,] 0.4835868773 0.0195109695 0.0639639577 0.4329381954
[46,] 0.9824774210 0.0008243665 0.0110449814 0.0056532311
[47,] 0.0200575663 0.0037757136 0.0052237373 0.9709429828
[48,] 0.0146098756 0.0060843668 0.0048509102 0.9744548475
[49,] 0.0144881680 0.0007155722 0.9820151134 0.0027811465
[50,] 0.0059877905 0.0003683328 0.9923960825 0.0012477942
[51,] 0.0011806183 0.0001525523 0.9983462125 0.0003206169
[52,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[53,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[54,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[55,] 0.0725780382 0.0026001815 0.9131739020 0.0116478782
[56,] 0.0069016808 0.0004073748 0.9912729398 0.0014180045
[57,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[58,] 0.9824774210 0.0008243665 0.0110449814 0.0056532311
[59,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[60,] 0.0767531041 0.0027149704 0.9083186896 0.0122132359
[61,] 0.7284771530 0.0066149637 0.2251757542 0.0397321291

[[1]]$tau
[1] 0.24261520 0.88000000 0.03046826 0.49175651

[[1]]$phi
[1] 0.25 0.25 0.25 0.25

[[1]]$kappa
[1] 5


ELBO for this run: -17461.9
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.021064 seconds 
1000 transitions using 10 leapfrog steps per transition would take 210.64 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -18170.282             1.000            1.000 
     2       -17898.181             0.508            1.000 
     3       -17738.950             0.341            0.015 
     4       -17701.517             0.257            0.015 
     5       -17666.955             0.206            0.009 
     6       -17638.704             0.172            0.009 
     7       -17620.389             0.147            0.002 
     8       -17604.930             0.129            0.002 
     9       -17579.979             0.115            0.002 
    10       -17582.489             0.103            0.002 
    11       -17557.874             0.094            0.002 
    12       -17544.145             0.086            0.002 
    13       -17536.501             0.080            0.001 
    14       -17511.559             0.074            0.001 
    15       -17523.177             0.069            0.001 
    16       -17500.494             0.065            0.001 
    17       -17500.625             0.061            0.001 
    18       -17494.879             0.058            0.001 
    19       -17488.878             0.055            0.001 
    20       -17476.964             0.052            0.001 
    21       -17467.183             0.002            0.001 
    22       -17465.690             0.001            0.001 
    23       -17454.907             0.001            0.001 
    24       -17460.804             0.001            0.001 
    25       -17448.585             0.001            0.001 
    26       -17442.521             0.001            0.001 
    27       -17442.825             0.001            0.001 
    28       -17438.018             0.001            0.001 
    29       -17436.375             0.001            0.000 
    30       -17430.231             0.001            0.000 
    31       -17425.734             0.000            0.000 
    32       -17427.116             0.000            0.000 
    33       -17423.207             0.000            0.000 
    34       -17424.270             0.000            0.000 
    35       -17417.330             0.000            0.000 
    36       -17416.608             0.000            0.000 
    37       -17411.954             0.000            0.000 
    38       -17405.153             0.000            0.000 
    39       -17405.345             0.000            0.000 
    40       -17404.342             0.000            0.000 
    41       -17398.001             0.000            0.000 
    42       -17397.225             0.000            0.000 
    43       -17397.482             0.000            0.000 
    44       -17395.256             0.000            0.000 
    45       -17389.169             0.000            0.000 
    46       -17393.560             0.000            0.000 
    47       -17389.117             0.000            0.000 
    48       -17390.422             0.000            0.000 
    49       -17386.610             0.000            0.000 
    50       -17388.122             0.000            0.000 
    51       -17381.617             0.000            0.000 
    52       -17381.526             0.000            0.000 
    53       -17383.720             0.000            0.000 
    54       -17379.886             0.000            0.000 
    55       -17378.838             0.000            0.000 
    56       -17379.375             0.000            0.000 
    57       -17376.188             0.000            0.000 
    58       -17376.317             0.000            0.000 
    59       -17376.112             0.000            0.000 
    60       -17376.776             0.000            0.000 
    61       -17373.506             0.000            0.000 
    62       -17374.756             0.000            0.000 
    63       -17377.223             0.000            0.000 
    64       -17373.718             0.000            0.000 
    65       -17370.684             0.000            0.000 
    66       -17369.686             0.000            0.000 
    67       -17369.275             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  96.6 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]
 [1,] 0.1653561158 0.0047395531 0.8072321250 0.0226722062
 [2,] 0.0075623958 0.0005388504 0.9900612903 0.0018374635
 [3,] 0.0088932789 0.0004908427 0.9888319636 0.0017839148
 [4,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
 [5,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
 [6,] 0.0029742492 0.0002355495 0.9961161026 0.0006740986
 [7,] 0.0086291374 0.0004798910 0.9891552166 0.0017357549
 [8,] 0.0007569489 0.0001349577 0.9988652431 0.0002428503
 [9,] 0.0479433872 0.0018752499 0.9420391136 0.0081422493
[10,] 0.0059026319 0.0003646688 0.9925008459 0.0012318534
[11,] 0.9197601709 0.0029116970 0.0577205383 0.0196075937
[12,] 0.9216554433 0.0041812006 0.0286082558 0.0455551004
[13,] 0.8718861529 0.0067182222 0.0404563036 0.0809393213
[14,] 0.9951962116 0.0003220012 0.0023858556 0.0020959316
[15,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[16,] 0.0005083632 0.0001202217 0.9991869302 0.0001844849
[17,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[18,] 0.0001333123 0.0001016517 0.9996580655 0.0001069705
[19,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[20,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[21,] 0.0007497949 0.0001319414 0.9988845680 0.0002336957
[22,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[23,] 0.0002979248 0.0001098740 0.9994509993 0.0001412019
[24,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[25,] 0.0284976950 0.0012326134 0.9651387729 0.0051309187
[26,] 0.0522789248 0.0020092838 0.9369298644 0.0087819269
[27,] 0.0626359948 0.0023179017 0.9247766058 0.0102694978
[28,] 0.0331391368 0.0013928520 0.9595951161 0.0058728952
[29,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[30,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[31,] 0.0002791380 0.0001093227 0.9994731274 0.0001384119
[32,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[33,] 0.0022664249 0.0002192855 0.9969321257 0.0005821638
[34,] 0.0003907489 0.0001754828 0.0001834696 0.9992502988
[35,] 0.0867616468 0.5491742268 0.0437824484 0.3202816779
[36,] 0.0018448517 0.9930155273 0.0011647834 0.0039748376
[37,] 0.0346266746 0.0014432223 0.9578227194 0.0061073838
[38,] 0.0037353980 0.0002697548 0.9951738081 0.0008210391
[39,] 0.0018448517 0.9930155273 0.0011647834 0.0039748376
[40,] 0.0469816439 0.0018451034 0.9431743398 0.0079989129
[41,] 0.0762761212 0.0027019639 0.9088728795 0.0121490354
[42,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[43,] 0.0030536291 0.0002391412 0.9960177326 0.0006894971
[44,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[45,] 0.4835868773 0.0195109695 0.0639639577 0.4329381954
[46,] 0.9824774210 0.0008243665 0.0110449814 0.0056532311
[47,] 0.0200575663 0.0037757136 0.0052237373 0.9709429828
[48,] 0.0146098756 0.0060843668 0.0048509102 0.9744548475
[49,] 0.0144881680 0.0007155722 0.9820151134 0.0027811465
[50,] 0.0059877905 0.0003683328 0.9923960825 0.0012477942
[51,] 0.0011806183 0.0001525523 0.9983462125 0.0003206169
[52,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[53,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[54,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[55,] 0.0725780382 0.0026001815 0.9131739020 0.0116478782
[56,] 0.0069016808 0.0004073748 0.9912729398 0.0014180045
[57,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[58,] 0.9824774210 0.0008243665 0.0110449814 0.0056532311
[59,] 0.0153731366 0.0010577133 0.9797546741 0.0038144760
[60,] 0.0767531041 0.0027149704 0.9083186896 0.0122132359
[61,] 0.7284771530 0.0066149637 0.2251757542 0.0397321291

[[1]]$tau
[1] 0.880000000 0.257798432 0.503923538 0.009425806

[[1]]$phi
[1] 0.25 0.25 0.25 0.25

[[1]]$kappa
[1] 5


ELBO for this run: -17738.9
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181925-1-943eda.csv\n"
init_taus from clustering  0.0303100683679589 init_taus from clustering  0.760575552501161 init_taus from clustering  0.999833865601526 init_taus from clustering  0.479294725718386 init_taus from clustering  0.239365441224809Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.027547 seconds 
1000 transitions using 10 leapfrog steps per transition would take 275.47 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17781.247             1.000            1.000 
     2       -17542.318             0.507            1.000 
     3       -17501.642             0.339            0.014 
     4       -17479.155             0.254            0.014 
     5       -17450.432             0.204            0.002 
     6       -17438.553             0.170            0.002 
     7       -17426.535             0.146            0.002 
     8       -17422.665             0.128            0.002 
     9       -17414.142             0.113            0.001 
    10       -17406.650             0.102            0.001 
    11       -17397.943             0.093            0.001 
    12       -17392.240             0.085            0.001 
    13       -17390.584             0.079            0.001 
    14       -17387.254             0.073            0.001 
    15       -17386.410             0.068            0.001 
    16       -17379.857             0.064            0.001 
    17       -17381.923             0.060            0.000 
    18       -17375.994             0.057            0.000 
    19       -17372.736             0.054            0.000 
    20       -17372.883             0.051            0.000 
    21       -17367.092             0.001            0.000 
    22       -17371.856             0.001            0.000 
    23       -17365.747             0.000            0.000 
    24       -17367.847             0.000            0.000 
    25       -17365.559             0.000            0.000 
    26       -17362.844             0.000            0.000 
    27       -17360.783             0.000            0.000 
    28       -17359.657             0.000            0.000 
    29       -17362.396             0.000            0.000 
    30       -17360.517             0.000            0.000 
    31       -17359.010             0.000            0.000 
    32       -17356.789             0.000            0.000 
    33       -17353.167             0.000            0.000 
    34       -17353.706             0.000            0.000 
    35       -17353.445             0.000            0.000 
    36       -17352.794             0.000            0.000 
    37       -17350.403             0.000            0.000 
    38       -17353.313             0.000            0.000 
    39       -17350.748             0.000            0.000 
    40       -17350.243             0.000            0.000 
    41       -17353.178             0.000            0.000 
    42       -17348.075             0.000            0.000 
    43       -17351.427             0.000            0.000 
    44       -17346.889             0.000            0.000 
    45       -17350.186             0.000            0.000 
    46       -17347.518             0.000            0.000 
    47       -17347.228             0.000            0.000 
    48       -17348.698             0.000            0.000 
    49       -17343.961             0.000            0.000 
    50       -17345.058             0.000            0.000 
    51       -17346.877             0.000            0.000 
    52       -17343.311             0.000            0.000 
    53       -17345.465             0.000            0.000 
    54       -17343.986             0.000            0.000 
    55       -17342.845             0.000            0.000 
    56       -17345.068             0.000            0.000 
    57       -17341.727             0.000            0.000 
    58       -17343.593             0.000            0.000 
    59       -17341.994             0.000            0.000 
    60       -17341.138             0.000            0.000 
    61       -17342.591             0.000            0.000 
    62       -17338.597             0.000            0.000 
    63       -17341.650             0.000            0.000 
    64       -17339.919             0.000            0.000 
    65       -17339.315             0.000            0.000 
    66       -17338.830             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  194.7 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]         [,5]
 [1,] 7.930470e-01 0.0079926000 0.0043651688 0.0238563828 1.707388e-01
 [2,] 9.891425e-01 0.0008036007 0.0005044681 0.0019007329 7.648685e-03
 [3,] 9.875134e-01 0.0007626346 0.0004711570 0.0019113654 9.341405e-03
 [4,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
 [5,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
 [6,] 9.955581e-01 0.0003316431 0.0002304149 0.0007247675 3.155113e-03
 [7,] 9.878691e-01 0.0007441413 0.0004608631 0.0018599885 9.065880e-03
 [8,] 9.987334e-01 0.0001542737 0.0001308826 0.0002423414 7.390979e-04
 [9,] 9.365679e-01 0.0031093270 0.0017605091 0.0086581683 4.990414e-02
[10,] 9.915564e-01 0.0005496263 0.0003524095 0.0013219333 6.219610e-03
[11,] 4.944075e-02 0.0046311138 0.0023253688 0.0183631701 9.252396e-01
[12,] 3.191628e-02 0.0095479181 0.0042647151 0.0577211625 8.965499e-01
[13,] 4.320067e-02 0.0150125823 0.0065515504 0.0990265722 8.362086e-01
[14,] 3.966287e-03 0.0008470080 0.0004448919 0.0038638225 9.908780e-01
[15,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[16,] 9.989939e-01 0.0001360260 0.0001203569 0.0001961098 5.536513e-04
[17,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[18,] 9.995412e-01 0.0001035150 0.0001019707 0.0001094033 1.438631e-04
[19,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[20,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[21,] 9.986510e-01 0.0001560913 0.0001316837 0.0002498737 8.113472e-04
[22,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[23,] 9.992966e-01 0.0001181406 0.0001102486 0.0001483306 3.267148e-04
[24,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[25,] 9.616102e-01 0.0020179749 0.0011645284 0.0054703052 2.973697e-02
[26,] 9.310509e-01 0.0033372820 0.0018843111 0.0093337893 5.439375e-02
[27,] 9.179564e-01 0.0038625059 0.0021687141 0.0109028266 6.510953e-02
[28,] 9.555844e-01 0.0022898203 0.0013135105 0.0062569101 3.455539e-02
[29,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[30,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[31,] 9.993774e-01 0.0001137205 0.0001077769 0.0001362101 2.649124e-04
[32,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[33,] 9.966460e-01 0.0002896172 0.0002082925 0.0005931419 2.262957e-03
[34,] 4.270319e-04 0.0010176020 0.0003605788 0.9969847649 1.210022e-03
[35,] 1.033968e-04 0.9995343025 0.0001325490 0.0001230454 1.067063e-04
[36,] 9.997936e-05 0.0001004313 0.9995995399 0.0001000518 9.999771e-05
[37,] 9.536601e-01 0.0023753150 0.0013602897 0.0065053468 3.609898e-02
[38,] 9.945126e-01 0.0003894102 0.0002627986 0.0008823365 3.952811e-03
[39,] 9.997936e-05 0.0001004313 0.9995995399 0.0001000518 9.999771e-05
[40,] 9.377947e-01 0.0030580700 0.0017326402 0.0085067032 4.890790e-02
[41,] 9.008784e-01 0.0045166967 0.0025213461 0.0128809727 7.920261e-02
[42,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[43,] 9.954488e-01 0.0003377104 0.0002338182 0.0007412912 3.238359e-03
[44,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[45,] 5.723473e-02 0.0404357684 0.0157988496 0.4758065226 4.107241e-01
[46,] 7.830246e-03 0.0010842213 0.0005716387 0.0044189431 9.860950e-01
[47,] 1.977886e-03 0.0039601732 0.0012948715 0.9855605491 7.206520e-03
[48,] 8.391363e-03 0.0373037740 0.0092028352 0.9202335950 2.486843e-02
[49,] 9.800305e-01 0.0011423749 0.0006819544 0.0029738726 1.517127e-02
[50,] 9.914408e-01 0.0005558107 0.0003558630 0.0013389707 6.308585e-03
[51,] 9.980450e-01 0.0001911752 0.0001514625 0.0003441984 1.268129e-03
[52,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[53,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[54,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[55,] 9.054908e-01 0.0043432724 0.0024280353 0.0123540028 7.538387e-02
[56,] 9.902017e-01 0.0006217124 0.0003926419 0.0015208178 7.263084e-03
[57,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[58,] 7.830246e-03 0.0010842213 0.0005716387 0.0044189431 9.860950e-01
[59,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[60,] 9.002844e-01 0.0045388607 0.0025332626 0.0129484544 7.969504e-02
[61,] 2.078388e-01 0.0110805529 0.0056787056 0.0397470105 7.356550e-01

[[1]]$tau
[1] 0.03031007 0.76057555 0.88000000 0.47929473 0.23936544

[[1]]$phi
[1] 0.2 0.2 0.2 0.2 0.2

[[1]]$kappa
[1] 5


ELBO for this run: -17501.6
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.026319 seconds 
1000 transitions using 10 leapfrog steps per transition would take 263.19 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17645.219             1.000            1.000 
     2       -17553.413             0.503            1.000 
     3       -17494.409             0.336            0.005 
     4       -17477.364             0.252            0.005 
     5       -17455.297             0.202            0.003 
     6       -17443.551             0.169            0.003 
     7       -17430.127             0.145            0.001 
     8       -17421.453             0.127            0.001 
     9       -17413.446             0.113            0.001 
    10       -17408.260             0.101            0.001 
    11       -17403.595             0.092            0.001 
    12       -17400.957             0.084            0.001 
    13       -17394.724             0.078            0.001 
    14       -17390.617             0.072            0.001 
    15       -17393.429             0.068            0.000 
    16       -17385.563             0.063            0.000 
    17       -17385.009             0.060            0.000 
    18       -17384.264             0.056            0.000 
    19       -17378.604             0.053            0.000 
    20       -17377.084             0.051            0.000 
    21       -17375.117             0.001            0.000 
    22       -17375.361             0.001            0.000 
    23       -17373.363             0.000            0.000 
    24       -17370.523             0.000            0.000 
    25       -17369.012             0.000            0.000 
    26       -17368.938             0.000            0.000 
    27       -17366.455             0.000            0.000 
    28       -17363.645             0.000            0.000 
    29       -17363.000             0.000            0.000 
    30       -17364.211             0.000            0.000 
    31       -17362.146             0.000            0.000 
    32       -17357.930             0.000            0.000 
    33       -17364.030             0.000            0.000 
    34       -17360.605             0.000            0.000 
    35       -17356.805             0.000            0.000 
    36       -17356.288             0.000            0.000 
    37       -17354.816             0.000            0.000 
    38       -17354.715             0.000            0.000 
    39       -17353.890             0.000            0.000 
    40       -17351.427             0.000            0.000 
    41       -17353.798             0.000            0.000 
    42       -17350.411             0.000            0.000 
    43       -17352.104             0.000            0.000 
    44       -17352.576             0.000            0.000 
    45       -17349.203             0.000            0.000 
    46       -17348.410             0.000            0.000 
    47       -17347.994             0.000            0.000 
    48       -17349.164             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  95.0 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]         [,5]
 [1,] 7.930470e-01 0.0079926000 0.0043651688 0.0238563828 1.707388e-01
 [2,] 9.891425e-01 0.0008036007 0.0005044681 0.0019007329 7.648685e-03
 [3,] 9.875134e-01 0.0007626346 0.0004711570 0.0019113654 9.341405e-03
 [4,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
 [5,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
 [6,] 9.955581e-01 0.0003316431 0.0002304149 0.0007247675 3.155113e-03
 [7,] 9.878691e-01 0.0007441413 0.0004608631 0.0018599885 9.065880e-03
 [8,] 9.987334e-01 0.0001542737 0.0001308826 0.0002423414 7.390979e-04
 [9,] 9.365679e-01 0.0031093270 0.0017605091 0.0086581683 4.990414e-02
[10,] 9.915564e-01 0.0005496263 0.0003524095 0.0013219333 6.219610e-03
[11,] 4.944075e-02 0.0046311138 0.0023253688 0.0183631701 9.252396e-01
[12,] 3.191628e-02 0.0095479181 0.0042647151 0.0577211625 8.965499e-01
[13,] 4.320067e-02 0.0150125823 0.0065515504 0.0990265722 8.362086e-01
[14,] 3.966287e-03 0.0008470080 0.0004448919 0.0038638225 9.908780e-01
[15,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[16,] 9.989939e-01 0.0001360260 0.0001203569 0.0001961098 5.536513e-04
[17,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[18,] 9.995412e-01 0.0001035150 0.0001019707 0.0001094033 1.438631e-04
[19,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[20,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[21,] 9.986510e-01 0.0001560913 0.0001316837 0.0002498737 8.113472e-04
[22,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[23,] 9.992966e-01 0.0001181406 0.0001102486 0.0001483306 3.267148e-04
[24,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[25,] 9.616102e-01 0.0020179749 0.0011645284 0.0054703052 2.973697e-02
[26,] 9.310509e-01 0.0033372820 0.0018843111 0.0093337893 5.439375e-02
[27,] 9.179564e-01 0.0038625059 0.0021687141 0.0109028266 6.510953e-02
[28,] 9.555844e-01 0.0022898203 0.0013135105 0.0062569101 3.455539e-02
[29,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[30,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[31,] 9.993774e-01 0.0001137205 0.0001077769 0.0001362101 2.649124e-04
[32,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[33,] 9.966460e-01 0.0002896172 0.0002082925 0.0005931419 2.262957e-03
[34,] 4.270319e-04 0.0010176020 0.0003605788 0.9969847649 1.210022e-03
[35,] 1.033968e-04 0.9995343025 0.0001325490 0.0001230454 1.067063e-04
[36,] 9.997936e-05 0.0001004313 0.9995995399 0.0001000518 9.999771e-05
[37,] 9.536601e-01 0.0023753150 0.0013602897 0.0065053468 3.609898e-02
[38,] 9.945126e-01 0.0003894102 0.0002627986 0.0008823365 3.952811e-03
[39,] 9.997936e-05 0.0001004313 0.9995995399 0.0001000518 9.999771e-05
[40,] 9.377947e-01 0.0030580700 0.0017326402 0.0085067032 4.890790e-02
[41,] 9.008784e-01 0.0045166967 0.0025213461 0.0128809727 7.920261e-02
[42,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[43,] 9.954488e-01 0.0003377104 0.0002338182 0.0007412912 3.238359e-03
[44,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[45,] 5.723473e-02 0.0404357684 0.0157988496 0.4758065226 4.107241e-01
[46,] 7.830246e-03 0.0010842213 0.0005716387 0.0044189431 9.860950e-01
[47,] 1.977886e-03 0.0039601732 0.0012948715 0.9855605491 7.206520e-03
[48,] 8.391363e-03 0.0373037740 0.0092028352 0.9202335950 2.486843e-02
[49,] 9.800305e-01 0.0011423749 0.0006819544 0.0029738726 1.517127e-02
[50,] 9.914408e-01 0.0005558107 0.0003558630 0.0013389707 6.308585e-03
[51,] 9.980450e-01 0.0001911752 0.0001514625 0.0003441984 1.268129e-03
[52,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[53,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[54,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[55,] 9.054908e-01 0.0043432724 0.0024280353 0.0123540028 7.538387e-02
[56,] 9.902017e-01 0.0006217124 0.0003926419 0.0015208178 7.263084e-03
[57,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[58,] 7.830246e-03 0.0010842213 0.0005716387 0.0044189431 9.860950e-01
[59,] 9.778213e-01 0.0016330956 0.0009870198 0.0039618132 1.559678e-02
[60,] 9.002844e-01 0.0045388607 0.0025332626 0.0129484544 7.969504e-02
[61,] 2.078388e-01 0.0110805529 0.0056787056 0.0397470105 7.356550e-01

[[1]]$tau
[1] 0.02431825 0.75847480 0.40692940 0.78055202 0.21937872

[[1]]$phi
[1] 0.2 0.2 0.2 0.2 0.2

[[1]]$kappa
[1] 5


ELBO for this run: -17494.4
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181932-1-cad1f1.csv\n"
init_taus from clustering  0.0288360476798489 init_taus from clustering  0.999945779002995 init_taus from clustering  0.489402094629471 init_taus from clustering  0.7615196853591 init_taus from clustering  0.300343992519167 init_taus from clustering  0.20036992217394Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.031174 seconds 
1000 transitions using 10 leapfrog steps per transition would take 311.74 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17741.172             1.000            1.000 
     2       -17638.543             0.503            1.000 
     3       -17579.323             0.336            0.006 
     4       -17552.534             0.253            0.006 
     5       -17529.077             0.202            0.003 
     6       -17514.182             0.169            0.003 
     7       -17502.858             0.145            0.002 
     8       -17483.268             0.127            0.002 
     9       -17475.941             0.113            0.001 
    10       -17473.159             0.102            0.001 
    11       -17462.623             0.092            0.001 
    12       -17460.719             0.085            0.001 
    13       -17448.122             0.078            0.001 
    14       -17457.255             0.073            0.001 
    15       -17444.312             0.068            0.001 
    16       -17435.162             0.064            0.001 
    17       -17432.997             0.060            0.001 
    18       -17434.257             0.057            0.001 
    19       -17426.147             0.054            0.001 
    20       -17422.814             0.051            0.001 
    21       -17430.233             0.001            0.001 
    22       -17415.171             0.001            0.001 
    23       -17420.564             0.001            0.001 
    24       -17416.123             0.001            0.001 
    25       -17409.782             0.000            0.000 
    26       -17412.020             0.000            0.000 
    27       -17407.537             0.000            0.000 
    28       -17407.152             0.000            0.000 
    29       -17409.244             0.000            0.000 
    30       -17402.154             0.000            0.000 
    31       -17405.190             0.000            0.000 
    32       -17402.364             0.000            0.000 
    33       -17402.446             0.000            0.000 
    34       -17397.244             0.000            0.000 
    35       -17397.486             0.000            0.000 
    36       -17401.462             0.000            0.000 
    37       -17395.481             0.000            0.000 
    38       -17392.885             0.000            0.000 
    39       -17396.585             0.000            0.000 
    40       -17390.072             0.000            0.000 
    41       -17389.058             0.000            0.000 
    42       -17383.861             0.000            0.000 
    43       -17386.241             0.000            0.000 
    44       -17381.620             0.000            0.000 
    45       -17388.094             0.000            0.000 
    46       -17382.509             0.000            0.000 
    47       -17386.793             0.000            0.000 
    48       -17382.660             0.000            0.000 
    49       -17381.868             0.000            0.000 
    50       -17383.453             0.000            0.000 
    51       -17376.990             0.000            0.000 
    52       -17379.893             0.000            0.000 
    53       -17378.957             0.000            0.000 
    54       -17375.714             0.000            0.000 
    55       -17378.797             0.000            0.000 
    56       -17375.740             0.000            0.000 
    57       -17375.463             0.000            0.000 
    58       -17376.675             0.000            0.000 
    59       -17371.973             0.000            0.000 
    60       -17373.964             0.000            0.000 
    61       -17373.273             0.000            0.000 
    62       -17365.151             0.000            0.000 
    63       -17372.444             0.000            0.000 
    64       -17367.363             0.000            0.000 
    65       -17367.829             0.000            0.000 
    66       -17366.734             0.000            0.000 
    67       -17367.687             0.000            0.000 
    68       -17367.757             0.000            0.000 
    69       -17363.695             0.000            0.000 
    70       -17367.193             0.000            0.000 
    71       -17371.331             0.000            0.000 
    72       -17364.520             0.000            0.000 
Chain 1 stan::variational::advi::calc_ELBO: The number of dropped evaluations has reached its maximum amount (100). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  134.1 seconds.
An error occurred during inference: Fitting failed. Unable to retrieve the metadata.
Error processing 0040b1b6-b07a-4b6e-90ef-133523eaf412: object 'tol_rel_obj' not found
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
Error processing 00493087-9d9d-40ca-86d5-936f1b951c93: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
[1] 98
[1] 99
[1] 100
[1] 101
[1] 102
[1] 103
[1] 104
[1] 105
[1] 106
[1] 107
[1] 108
[1] 109
[1] 110
[1] 111
[1] 112
[1] 113
[1] 114
[1] 115
[1] 116
[1] 117
[1] 118
[1] 119
[1] 120
[1] 121
[1] 122
[1] 123
[1] 124
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
[1] 130
[1] 131
[1] 132
[1] 133
[1] 134
[1] 135
[1] 136
[1] 137
[1] 138
[1] 139
[1] 140
[1] 141
[1] 142
[1] 143
[1] 144
[1] 145
[1] 146
[1] 147
[1] 148
[1] 149
[1] 150
[1] 151
[1] 152
[1] 153
[1] 154
[1] 155
[1] 156
[1] 157
[1] 158
[1] 159
[1] 160
[1] 161
[1] 162
[1] 163
[1] 164
[1] 165
[1] 166
[1] 167
[1] 168
[1] 169
[1] 170
[1] 171
[1] 172
[1] 173
[1] 174
[1] 175
[1] 176
[1] 177
[1] 178
[1] 179
[1] 180
[1] 181
[1] 182
[1] 183
[1] 184
[1] 185
[1] 186
[1] 187
[1] 188
[1] 189
[1] 190
[1] 191
[1] 192
[1] 193
[1] 194
[1] 195
[1] 196
[1] 197
[1] 198
[1] 199
[1] 200
[1] 201
[1] 202
[1] 203
[1] 204
[1] 205
[1] 206
[1] 207
[1] 208
[1] 209
[1] 210
[1] 211
[1] 212
[1] 213
[1] 214
[1] 215
[1] 216
[1] 217
[1] 218
[1] 219
[1] 220
[1] 221
[1] 222
[1] 223
[1] 224
[1] 225
[1] 226
[1] 227
[1] 228
[1] 229
[1] 230
[1] 231
[1] 232
[1] 233
[1] 234
[1] 235
[1] 236
[1] 237
[1] 238
[1] 239
[1] 240
[1] 241
[1] 242
[1] 243
[1] 244
[1] 245
[1] 246
[1] 247
[1] 248
[1] 249
[1] 250
[1] 251
[1] 252
[1] 253
[1] 254
[1] 255
[1] 256
[1] 257
[1] 258
[1] 259
[1] 260
[1] 261
[1] 262
[1] 263
[1] 264
[1] 265
[1] 266
[1] 267
[1] 268
[1] 269
[1] 270
[1] 271
[1] 272
[1] 273
Error processing 00508f2b-36bf-44fc-b66b-97e1f3e40bfa: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
Error processing 005794f1-5a87-45b5-9811-83ddf6924568: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
[1] 98
[1] 99
[1] 100
[1] 101
[1] 102
[1] 103
[1] 104
[1] 105
Error processing 005e85a3-3571-462d-8dc9-2babfc7ace21: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
Error processing 007aab66-2f07-459d-8952-3041d6ea24a8: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
[1] 98
[1] 99
[1] 100
[1] 101
[1] 102
[1] 103
[1] 104
[1] 105
[1] 106
[1] 107
[1] 108
[1] 109
[1] 110
[1] 111
[1] 112
[1] 113
[1] 114
[1] 115
[1] 116
[1] 117
[1] 118
[1] 119
[1] 120
[1] 121
[1] 122
[1] 123
[1] 124
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
[1] 130
[1] 131
[1] 132
[1] 133
[1] 134
[1] 135
[1] 136
[1] 137
[1] 138
[1] 139
[1] 140
[1] 141
[1] 142
[1] 143
[1] 144
[1] 145
[1] 146
[1] 147
[1] 148
[1] 149
[1] 150
[1] 151
[1] 152
[1] 153
[1] 154
[1] 155
[1] 156
[1] 157
[1] 158
[1] 159
[1] 160
[1] 161
[1] 162
[1] 163
[1] 164
[1] 165
[1] 166
[1] 167
[1] 168
[1] 169
[1] 170
[1] 171
[1] 172
[1] 173
[1] 174
[1] 175
[1] 176
[1] 177
[1] 178
[1] 179
[1] 180
[1] 181
[1] 182
[1] 183
[1] 184
[1] 185
[1] 186
[1] 187
[1] 188
[1] 189
[1] 190
[1] 191
[1] 192
[1] 193
[1] 194
[1] 195
Error processing 008aef39-0c97-48ce-9dfd-f12d67116c59: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
[1] 98
[1] 99
[1] 100
[1] 101
[1] 102
[1] 103
[1] 104
[1] 105
[1] 106
[1] 107
[1] 108
[1] 109
[1] 110
[1] 111
[1] 112
[1] 113
[1] 114
[1] 115
[1] 116
[1] 117
[1] 118
[1] 119
[1] 120
[1] 121
[1] 122
[1] 123
[1] 124
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
[1] 130
[1] 131
[1] 132
[1] 133
[1] 134
[1] 135
[1] 136
[1] 137
[1] 138
[1] 139
[1] 140
[1] 141
[1] 142
[1] 143
[1] 144
[1] 145
[1] 146
[1] 147
[1] 148
[1] 149
[1] 150
[1] 151
[1] 152
[1] 153
[1] 154
[1] 155
[1] 156
[1] 157
[1] 158
Error processing 008bad10-d41b-4bbb-86fa-9976ecea46b1: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
Error processing 00aa769d-622c-433e-8a8a-63fb5c41ea42: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
[1] 4
ℹ Adding segment with index 4 to segments included in the inference.
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
ℹ Adding segment with index 23 to segments included in the inference.
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
ℹ Adding segment with index 72 to segments included in the inference.
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
[1] 98
[1] 99
[1] 100
init_taus from clustering  0.554178009247988Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000142 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1.42 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -319.330             1.000            1.000 
     2         -318.329             0.502            1.000 
     3         -317.917             0.335            0.003 
     4         -317.554             0.251            0.003 
     5         -318.268             0.202            0.002 
     6         -317.673             0.168            0.002 
     7         -318.044             0.144            0.002 
     8         -317.803             0.126            0.002 
     9         -317.817             0.112            0.001 
    10         -317.513             0.101            0.001 
    11         -317.775             0.092            0.001 
    12         -317.649             0.084            0.001 
    13         -317.636             0.078            0.001 
    14         -317.447             0.072            0.001 
    15         -317.707             0.068            0.001 
    16         -317.763             0.063            0.001 
    17         -317.432             0.060            0.001 
    18         -317.621             0.057            0.001 
    19         -317.556             0.054            0.001 
    20         -317.564             0.051            0.001 
    21         -317.576             0.001            0.001 
    22         -317.428             0.001            0.001 
    23         -317.349             0.001            0.001 
    24         -317.492             0.001            0.001 
    25         -317.496             0.001            0.000 
    26         -317.366             0.000            0.000 
    27         -317.513             0.000            0.000 
    28         -317.484             0.000            0.000 
    29         -317.678             0.000            0.000 
    30         -317.600             0.000            0.000 
    31         -317.588             0.000            0.000 
    32         -317.710             0.000            0.000 
    33         -317.506             0.000            0.000 
    34         -317.550             0.000            0.000 
    35         -317.887             0.000            0.000 
    36         -317.332             0.000            0.000 
    37         -317.495             0.000            0.000 
    38         -317.518             0.000            0.000 
    39         -317.508             0.000            0.000 
    40         -317.587             0.000            0.000 
    41         -317.274             0.000            0.000 
    42         -317.296             0.000            0.000 
    43         -317.421             0.000            0.000 
    44         -317.448             0.000            0.000 
    45         -317.624             0.000            0.000 
    46         -317.806             0.000            0.000 
    47         -317.370             0.000            0.000 
    48         -317.585             0.001            0.001 
    49         -317.485             0.001            0.000 
    50         -317.435             0.001            0.000 
    51         -317.319             0.001            0.000 
    52         -317.314             0.001            0.000 
    53         -317.424             0.000            0.000 
    54         -317.467             0.000            0.000 
    55         -317.419             0.000            0.000 
    56         -317.620             0.000            0.000 
    57         -317.353             0.000            0.000 
    58         -317.616             0.000            0.000 
    59         -317.426             0.000            0.000 
    60         -317.479             0.000            0.000 
    61         -317.521             0.000            0.000 
    62         -317.234             0.000            0.000 
    63         -317.435             0.000            0.001 
    64         -317.514             0.000            0.001 
    65         -317.395             0.000            0.000 
    66         -317.706             0.000            0.000 
    67         -317.447             0.000            0.000 
    68         -317.349             0.000            0.000 
    69         -317.513             0.000            0.000 
    70         -317.626             0.000            0.000 
    71         -317.493             0.000            0.000 
    72         -317.432             0.000            0.000 
    73         -317.482             0.000            0.000 
    74         -317.589             0.000            0.000 
    75         -317.464             0.000            0.000 
    76         -317.359             0.000            0.000 
    77         -317.694             0.000            0.000 
    78         -317.409             0.000            0.000 
    79         -317.320             0.000            0.000 
    80         -317.376             0.000            0.000 
    81         -317.448             0.000            0.000 
    82         -317.339             0.000            0.000 
    83         -317.505             0.000            0.000 
    84         -317.492             0.000            0.000 
    85         -317.468             0.000            0.000 
    86         -317.326             0.000            0.000 
    87         -317.381             0.000            0.000 
    88         -317.415             0.000            0.000 
    89         -317.656             0.000            0.000 
    90         -317.376             0.000            0.000 
    91         -317.494             0.000            0.000 
    92         -317.718             0.000            0.000 
    93         -317.380             0.000            0.000 
    94         -317.535             0.000            0.000 
    95         -317.646             0.000            0.000 
    96         -317.354             0.000            0.000 
    97         -317.527             0.000            0.000 
    98         -317.563             0.000            0.000 
    99         -317.608             0.000            0.000 
   100         -317.323             0.000            0.000 
   101         -317.648             0.000            0.000 
   102         -317.398             0.001            0.001 
   103         -317.605             0.001            0.001 
   104         -317.643             0.001            0.001 
   105         -317.410             0.001            0.001 
   106         -317.426             0.001            0.001 
   107         -317.365             0.001            0.001 
   108         -317.567             0.001            0.001 
   109         -317.569             0.001            0.001 
   110         -317.452             0.001            0.001 
   111         -317.300             0.001            0.001 
   112         -317.402             0.000            0.000 
   113         -317.455             0.000            0.000 
   114         -317.203             0.000            0.000 
   115         -317.467             0.000            0.001 
   116         -317.570             0.000            0.000 
   117         -317.640             0.000            0.000 
   118         -317.384             0.000            0.000 
   119         -317.405             0.000            0.000 
   120         -317.526             0.000            0.000 
   121         -317.444             0.000            0.000 
   122         -317.380             0.000            0.000 
   123         -317.677             0.000            0.000 
   124         -317.415             0.000            0.000 
   125         -317.599             0.000            0.000 
   126         -317.625             0.000            0.000 
   127         -317.340             0.000            0.000 
   128         -317.773             0.000            0.000 
   129         -317.458             0.001            0.000 
   130         -317.693             0.001            0.001 
   131         -317.567             0.001            0.001 
   132         -317.442             0.001            0.001 
   133         -317.317             0.001            0.001 
   134         -317.325             0.001            0.000 
   135         -317.645             0.001            0.000 
   136         -317.612             0.001            0.000 
   137         -317.454             0.001            0.000 
   138         -317.421             0.001            0.000 
   139         -317.434             0.001            0.000 
   140         -317.465             0.000            0.000 
   141         -317.541             0.000            0.000 
   142         -317.635             0.001            0.000 
   143         -317.411             0.000            0.000 
   144         -317.421             0.000            0.000 
   145         -317.522             0.000            0.000 
   146         -317.443             0.000            0.000 
   147         -317.379             0.000            0.000 
   148         -317.529             0.000            0.000 
   149         -317.539             0.000            0.000 
   150         -317.504             0.000            0.000 
   151         -317.360             0.000            0.000 
   152         -317.446             0.000            0.000 
   153         -317.508             0.000            0.000 
   154         -317.586             0.000            0.000 
   155         -317.366             0.000            0.000 
   156         -317.715             0.000            0.000 
   157         -317.405             0.000            0.000 
   158         -317.342             0.000            0.000 
   159         -317.704             0.000            0.000 
   160         -317.510             0.000            0.000 
   161         -317.707             0.000            0.000 
   162         -317.642             0.000            0.000 
   163         -317.501             0.000            0.000 
   164         -317.448             0.000            0.000 
   165         -317.393             0.000            0.000 
   166         -317.463             0.000            0.000 
   167         -317.688             0.000            0.000 
   168         -317.488             0.000            0.000 
   169         -317.346             0.000            0.000 
   170         -317.492             0.000            0.000 
   171         -317.398             0.000            0.000 
   172         -317.684             0.001            0.000 
   173         -317.524             0.001            0.001 
   174         -317.464             0.001            0.001 
   175         -317.386             0.001            0.000 
   176         -317.556             0.000            0.000 
   177         -317.347             0.000            0.000 
   178         -317.393             0.000            0.000 
   179         -317.388             0.000            0.000 
   180         -317.739             0.000            0.000 
   181         -317.304             0.000            0.000 
   182         -317.326             0.000            0.000 
   183         -317.550             0.000            0.000 
   184         -317.369             0.000            0.001 
   185         -317.586             0.001            0.001 
   186         -317.513             0.001            0.001 
   187         -317.619             0.001            0.001 
   188         -317.465             0.000            0.000 
   189         -317.421             0.000            0.000 
   190         -317.454             0.000            0.000 
   191         -317.360             0.000            0.000 
   192         -317.555             0.000            0.000 
   193         -317.496             0.000            0.000 
   194         -317.387             0.000            0.000 
   195         -317.621             0.000            0.000 
   196         -317.483             0.000            0.000 
   197         -317.370             0.000            0.000 
   198         -317.464             0.000            0.000 
   199         -317.526             0.000            0.000 
   200         -317.445             0.000            0.000 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  1.1 seconds.
[[1]]
[[1]]$w
     [,1]
[1,]    1
[2,]    1
[3,]    1

[[1]]$tau
[1] 0.554178

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -317.917
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.00014 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1.4 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -318.534             1.000            1.000 
     2         -317.454             0.502            1.000 
     3         -317.587             0.335            0.003 
     4         -317.482             0.251            0.003 
     5         -317.843             0.201            0.001 
     6         -317.709             0.168            0.001 
     7         -317.505             0.144            0.001 
     8         -317.654             0.126            0.001 
     9         -317.477             0.112            0.001 
    10         -317.295             0.101            0.001 
    11         -317.641             0.092            0.001 
    12         -317.410             0.084            0.001 
    13         -317.435             0.078            0.001 
    14         -317.537             0.072            0.001 
    15         -317.463             0.067            0.001 
    16         -317.256             0.063            0.001 
    17         -317.375             0.059            0.001 
    18         -317.346             0.056            0.001 
    19         -317.377             0.053            0.000 
    20         -317.447             0.051            0.000 
    21         -317.436             0.001            0.000 
    22         -317.481             0.000            0.000 
    23         -317.234             0.000            0.000 
    24         -317.404             0.000            0.000 
    25         -317.360             0.000            0.000 
    26         -317.385             0.000            0.000 
    27         -317.439             0.000            0.000 
    28         -317.550             0.000            0.000 
    29         -317.673             0.000            0.000 
    30         -317.435             0.000            0.000 
    31         -317.339             0.000            0.000 
    32         -317.508             0.000            0.000 
    33         -317.473             0.000            0.000 
    34         -317.541             0.000            0.000 
    35         -317.481             0.000            0.000 
    36         -317.311             0.000            0.000 
    37         -317.381             0.000            0.000 
    38         -317.594             0.000            0.000 
    39         -317.790             0.000            0.000 
    40         -317.802             0.000            0.000 
    41         -317.561             0.000            0.000 
    42         -317.429             0.000            0.000 
    43         -317.494             0.000            0.000 
    44         -317.492             0.000            0.000 
    45         -317.757             0.000            0.000 
    46         -317.559             0.000            0.000 
    47         -317.299             0.000            0.000 
    48         -317.462             0.000            0.001 
    49         -317.222             0.000            0.001 
    50         -317.523             0.000            0.001 
    51         -317.721             0.000            0.001 
    52         -317.478             0.000            0.001 
    53         -317.474             0.000            0.001 
    54         -317.473             0.000            0.001 
    55         -317.309             0.000            0.001 
    56         -317.609             0.001            0.001 
    57         -317.804             0.001            0.001 
    58         -317.391             0.001            0.001 
    59         -317.442             0.001            0.001 
    60         -317.470             0.001            0.001 
    61         -317.409             0.001            0.001 
    62         -317.461             0.001            0.001 
    63         -317.470             0.000            0.001 
    64         -317.494             0.000            0.001 
    65         -317.506             0.000            0.001 
    66         -317.366             0.000            0.001 
    67         -317.631             0.000            0.001 
    68         -317.723             0.000            0.000 
    69         -317.506             0.000            0.000 
    70         -317.468             0.000            0.000 
    71         -317.451             0.000            0.000 
    72         -317.537             0.000            0.000 
    73         -317.513             0.000            0.000 
    74         -317.394             0.000            0.000 
    75         -317.607             0.000            0.000 
    76         -317.516             0.000            0.000 
    77         -317.431             0.000            0.000 
    78         -317.389             0.000            0.000 
    79         -317.464             0.000            0.000 
    80         -317.550             0.000            0.000 
    81         -317.356             0.000            0.000 
    82         -317.609             0.000            0.000 
    83         -317.551             0.000            0.000 
    84         -317.417             0.000            0.000 
    85         -317.665             0.000            0.000 
    86         -317.437             0.000            0.000 
    87         -317.479             0.000            0.000 
    88         -317.459             0.000            0.000 
    89         -317.411             0.000            0.000 
    90         -317.484             0.000            0.000 
    91         -317.404             0.000            0.000 
    92         -317.405             0.000            0.000 
    93         -317.456             0.000            0.000 
    94         -317.438             0.000            0.000 
    95         -317.428             0.000            0.000 
    96         -317.305             0.000            0.000 
    97         -317.446             0.000            0.000 
    98         -317.610             0.000            0.000 
    99         -317.465             0.000            0.000 
   100         -317.425             0.000            0.000 
   101         -317.601             0.000            0.000 
   102         -317.403             0.000            0.000 
   103         -317.463             0.000            0.000 
   104         -317.473             0.000            0.000 
   105         -317.623             0.000            0.000 
   106         -317.487             0.000            0.000 
   107         -317.493             0.000            0.000 
   108         -317.599             0.000            0.000 
   109         -317.453             0.000            0.000 
   110         -317.400             0.000            0.000 
   111         -317.498             0.000            0.000 
   112         -317.544             0.000            0.000 
   113         -317.370             0.000            0.000 
   114         -317.416             0.000            0.000 
   115         -317.709             0.000            0.000 
   116         -317.584             0.000            0.000 
   117         -317.646             0.000            0.000 
   118         -317.366             0.000            0.000 
   119         -317.509             0.000            0.000 
   120         -317.537             0.000            0.000 
   121         -317.539             0.000            0.000 
   122         -317.461             0.000            0.000 
   123         -317.339             0.000            0.000 
   124         -317.252             0.000            0.000 
   125         -317.576             0.000            0.000 
   126         -317.364             0.000            0.000 
   127         -317.622             0.000            0.000 
   128         -317.488             0.000            0.000 
   129         -317.617             0.000            0.000 
   130         -317.529             0.000            0.000 
   131         -317.628             0.000            0.000 
   132         -317.552             0.000            0.000 
   133         -317.429             0.000            0.000 
   134         -317.512             0.000            0.000 
   135         -317.242             0.000            0.000 
   136         -317.573             0.000            0.000 
   137         -317.358             0.000            0.000 
   138         -317.544             0.000            0.000 
   139         -317.650             0.000            0.000 
   140         -317.631             0.000            0.000 
   141         -317.532             0.000            0.000 
   142         -317.464             0.000            0.000 
   143         -317.614             0.000            0.000 
   144         -317.785             0.000            0.000 
   145         -317.368             0.001            0.000 
   146         -317.699             0.001            0.000 
   147         -317.382             0.001            0.000 
   148         -317.523             0.001            0.000 
   149         -317.477             0.001            0.000 
   150         -317.661             0.001            0.000 
   151         -317.459             0.001            0.001 
   152         -317.653             0.001            0.001 
   153         -317.609             0.001            0.001 
   154         -317.527             0.001            0.001 
   155         -317.581             0.001            0.001 
   156         -317.511             0.000            0.000 
   157         -317.507             0.000            0.000 
   158         -317.545             0.000            0.000 
   159         -317.568             0.000            0.000 
   160         -317.338             0.000            0.000 
   161         -317.487             0.000            0.000 
   162         -317.335             0.000            0.000 
   163         -317.612             0.000            0.000 
   164         -317.505             0.000            0.000 
   165         -317.530             0.000            0.000 
   166         -317.403             0.000            0.000 
   167         -317.442             0.000            0.000 
   168         -317.481             0.000            0.000 
   169         -317.453             0.000            0.000 
   170         -317.349             0.000            0.000 
   171         -317.554             0.000            0.000 
   172         -317.564             0.000            0.000 
   173         -317.429             0.000            0.000 
   174         -317.650             0.000            0.000 
   175         -317.671             0.000            0.000 
   176         -317.462             0.000            0.000 
   177         -317.469             0.000            0.000 
   178         -317.438             0.000            0.000 
   179         -317.399             0.000            0.000 
   180         -317.491             0.000            0.000 
   181         -317.485             0.000            0.000 
   182         -317.352             0.000            0.000 
   183         -317.701             0.000            0.000 
   184         -317.515             0.000            0.000 
   185         -317.448             0.000            0.000 
   186         -317.286             0.000            0.000 
   187         -317.320             0.000            0.000 
   188         -317.361             0.000            0.000 
   189         -317.242             0.000            0.000 
   190         -317.472             0.000            0.000 
   191         -317.703             0.000            0.000 
   192         -317.444             0.000            0.000 
   193         -317.564             0.000            0.000 
   194         -317.473             0.000            0.000 
   195         -317.559             0.000            0.000 
   196         -317.631             0.000            0.000 
   197         -317.440             0.000            0.000 
   198         -317.515             0.000            0.000 
   199         -317.552             0.000            0.000 
   200         -317.368             0.000            0.000 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  1.2 seconds.
[[1]]
[[1]]$w
     [,1]
[1,]    1
[2,]    1
[3,]    1

[[1]]$tau
[1] 0.5330535

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -317.587
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181936-1-a4acb9.csv\n"
init_taus from clustering  0.623267550634139 init_taus from clustering  0.426426809819453Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000235 seconds 
1000 transitions using 10 leapfrog steps per transition would take 2.35 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -325.382             1.000            1.000 
     2         -321.639             0.506            1.000 
     3         -320.491             0.338            0.012 
     4         -320.207             0.254            0.012 
     5         -319.046             0.204            0.004 
     6         -318.804             0.170            0.004 
     7         -318.487             0.146            0.004 
     8         -318.165             0.128            0.004 
     9         -318.417             0.114            0.001 
    10         -318.172             0.102            0.001 
    11         -318.505             0.093            0.001 
    12         -317.760             0.086            0.001 
    13         -317.995             0.079            0.001 
    14         -318.146             0.073            0.001 
    15         -317.835             0.069            0.001 
    16         -317.289             0.064            0.001 
    17         -317.662             0.061            0.001 
    18         -317.419             0.057            0.001 
    19         -318.009             0.054            0.001 
    20         -318.213             0.052            0.001 
    21         -317.462             0.002            0.001 
    22         -317.644             0.001            0.001 
    23         -317.407             0.001            0.001 
    24         -317.559             0.001            0.001 
    25         -316.964             0.001            0.001 
    26         -317.387             0.001            0.001 
    27         -317.447             0.001            0.001 
    28         -317.405             0.001            0.001 
    29         -317.231             0.001            0.001 
    30         -317.268             0.001            0.001 
    31         -316.965             0.001            0.001 
    32         -317.420             0.001            0.001 
    33         -317.130             0.001            0.001 
    34         -317.635             0.001            0.001 
    35         -316.706             0.001            0.001 
    36         -316.664             0.001            0.001 
    37         -316.593             0.001            0.001 
    38         -316.856             0.001            0.001 
    39         -316.937             0.001            0.001 
    40         -316.896             0.001            0.001 
    41         -316.693             0.001            0.001 
    42         -317.184             0.001            0.001 
    43         -317.588             0.001            0.001 
    44         -316.689             0.001            0.001 
    45         -317.474             0.001            0.001 
    46         -316.963             0.001            0.001 
    47         -317.352             0.001            0.001 
    48         -317.161             0.001            0.001 
    49         -316.785             0.001            0.001 
    50         -316.989             0.001            0.001 
    51         -317.117             0.001            0.001 
    52         -316.667             0.001            0.001 
    53         -317.260             0.001            0.001 
    54         -316.685             0.001            0.001 
    55         -317.071             0.001            0.001 
    56         -317.501             0.001            0.001 
    57         -316.651             0.001            0.001 
    58         -316.648             0.001            0.001 
    59         -316.748             0.001            0.001 
    60         -317.141             0.001            0.001 
    61         -317.567             0.001            0.001 
    62         -317.303             0.001            0.001 
    63         -316.364             0.001            0.001 
    64         -316.767             0.001            0.001 
    65         -317.268             0.001            0.001 
    66         -316.857             0.001            0.001 
    67         -317.182             0.001            0.001 
    68         -316.637             0.001            0.001 
    69         -316.855             0.001            0.001 
    70         -316.987             0.001            0.001 
    71         -317.100             0.001            0.001 
    72         -316.405             0.001            0.001 
    73         -317.682             0.001            0.001 
    74         -316.844             0.001            0.001 
    75         -316.537             0.001            0.001 
    76         -317.293             0.001            0.001 
    77         -316.980             0.001            0.001 
    78         -316.684             0.001            0.001 
    79         -316.914             0.001            0.001 
    80         -316.759             0.001            0.001 
    81         -316.939             0.001            0.001 
    82         -316.867             0.001            0.001 
    83         -316.517             0.001            0.001 
    84         -316.903             0.001            0.001 
    85         -317.357             0.001            0.001 
    86         -316.809             0.001            0.001 
    87         -316.640             0.001            0.001 
    88         -316.761             0.001            0.001 
    89         -316.908             0.001            0.001 
    90         -316.962             0.001            0.001 
    91         -316.593             0.001            0.001 
    92         -316.863             0.001            0.001 
    93         -316.892             0.001            0.001 
    94         -316.699             0.001            0.001 
    95         -316.742             0.001            0.001 
    96         -316.960             0.001            0.001 
    97         -316.415             0.001            0.001 
    98         -316.839             0.001            0.001 
    99         -316.587             0.001            0.001 
   100         -316.589             0.001            0.001 
   101         -316.972             0.001            0.001 
   102         -316.659             0.001            0.001 
   103         -316.823             0.001            0.001 
   104         -316.622             0.001            0.001 
   105         -316.609             0.001            0.001 
   106         -316.733             0.001            0.001 
   107         -316.665             0.001            0.001 
   108         -316.311             0.001            0.001 
   109         -316.899             0.001            0.001 
   110         -316.535             0.001            0.001 
   111         -316.440             0.001            0.001 
   112         -316.663             0.001            0.001 
   113         -316.788             0.001            0.001 
   114         -316.106             0.001            0.001 
   115         -316.581             0.001            0.001 
   116         -317.069             0.001            0.001 
   117         -316.938             0.001            0.001 
   118         -316.208             0.001            0.001 
   119         -316.314             0.001            0.001 
   120         -316.574             0.001            0.001 
   121         -316.749             0.001            0.001 
   122         -316.274             0.001            0.001 
   123         -316.471             0.001            0.001 
   124         -316.603             0.001            0.001 
   125         -316.407             0.001            0.001 
   126         -316.280             0.001            0.001 
   127         -316.730             0.001            0.001 
   128         -316.517             0.001            0.001 
   129         -316.485             0.001            0.001 
   130         -316.723             0.001            0.001 
   131         -316.250             0.001            0.001 
   132         -316.435             0.001            0.001 
   133         -316.242             0.001            0.001 
   134         -316.468             0.001            0.001 
   135         -316.736             0.001            0.001 
   136         -316.722             0.001            0.001 
   137         -316.135             0.001            0.001 
   138         -316.371             0.001            0.001 
   139         -316.556             0.001            0.001 
   140         -316.364             0.001            0.001 
   141         -316.607             0.001            0.001 
   142         -316.636             0.001            0.001 
   143         -316.073             0.001            0.001 
   144         -316.734             0.001            0.001 
   145         -316.589             0.001            0.001 
   146         -316.548             0.001            0.001 
   147         -316.360             0.001            0.001 
   148         -316.299             0.001            0.001 
   149         -316.470             0.001            0.001 
   150         -316.549             0.001            0.001 
   151         -316.813             0.001            0.001 
   152         -316.790             0.001            0.001 
   153         -316.143             0.001            0.001 
   154         -316.760             0.001            0.001 
   155         -316.721             0.001            0.001 
   156         -316.518             0.001            0.001 
   157         -316.508             0.001            0.001 
   158         -316.440             0.001            0.001 
   159         -315.918             0.001            0.001 
   160         -316.551             0.001            0.001 
   161         -316.679             0.001            0.001 
   162         -316.458             0.001            0.001 
   163         -316.606             0.001            0.001 
   164         -316.492             0.001            0.000 
   165         -316.532             0.001            0.000 
   166         -316.613             0.001            0.000 
   167         -316.536             0.001            0.000 
   168         -316.606             0.001            0.000 
   169         -316.322             0.001            0.000 
   170         -316.166             0.001            0.000 
   171         -316.121             0.001            0.000 
   172         -316.288             0.001            0.000 
   173         -316.615             0.001            0.000 
   174         -316.421             0.001            0.000 
   175         -316.392             0.001            0.000 
   176         -316.212             0.001            0.000 
   177         -316.271             0.001            0.000 
   178         -316.571             0.001            0.000 
   179         -316.489             0.001            0.000 
   180         -316.152             0.000            0.000 
   181         -316.620             0.001            0.000 
   182         -316.077             0.001            0.000 
   183         -316.149             0.001            0.000 
   184         -316.600             0.001            0.001 
   185         -316.551             0.001            0.001 
   186         -316.438             0.001            0.001 
   187         -316.555             0.001            0.001 
   188         -316.108             0.001            0.001 
   189         -316.128             0.001            0.001 
   190         -316.828             0.001            0.001 
   191         -316.438             0.001            0.001 
   192         -316.371             0.001            0.001 
   193         -316.252             0.001            0.001 
   194         -316.496             0.001            0.001 
   195         -316.561             0.001            0.001 
   196         -316.261             0.001            0.001 
   197         -316.558             0.001            0.001 
   198         -316.443             0.001            0.001 
   199         -316.339             0.001            0.001 
   200         -316.705             0.001            0.001 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  2.6 seconds.
[[1]]
[[1]]$w
             [,1]       [,2]
[1,] 0.9682522150 0.03174779
[2,] 0.0002107095 0.99978929
[3,] 0.8869183317 0.11308167

[[1]]$tau
[1] 0.6232676 0.4264268

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -320.491
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000227 seconds 
1000 transitions using 10 leapfrog steps per transition would take 2.27 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -325.834             1.000            1.000 
     2         -322.390             0.505            1.000 
     3         -320.985             0.338            0.011 
     4         -320.317             0.254            0.011 
     5         -319.588             0.204            0.004 
     6         -318.967             0.170            0.004 
     7         -318.061             0.146            0.003 
     8         -318.224             0.128            0.003 
     9         -317.941             0.114            0.002 
    10         -318.222             0.103            0.002 
    11         -317.445             0.094            0.002 
    12         -318.210             0.086            0.002 
    13         -317.889             0.079            0.002 
    14         -317.772             0.074            0.002 
    15         -317.406             0.069            0.002 
    16         -317.726             0.065            0.002 
    17         -317.690             0.061            0.002 
    18         -317.372             0.058            0.002 
    19         -317.231             0.055            0.001 
    20         -317.242             0.052            0.001 
    21         -317.365             0.002            0.001 
    22         -317.179             0.001            0.001 
    23         -317.344             0.001            0.001 
    24         -317.115             0.001            0.001 
    25         -317.043             0.001            0.001 
    26         -317.217             0.001            0.001 
    27         -317.655             0.001            0.001 
    28         -317.443             0.001            0.001 
    29         -317.106             0.001            0.001 
    30         -316.975             0.001            0.001 
    31         -317.166             0.001            0.001 
    32         -317.257             0.001            0.001 
    33         -316.621             0.001            0.001 
    34         -316.957             0.001            0.001 
    35         -316.967             0.001            0.001 
    36         -316.968             0.001            0.001 
    37         -316.983             0.001            0.001 
    38         -316.621             0.001            0.001 
    39         -317.176             0.001            0.001 
    40         -317.293             0.001            0.001 
    41         -316.748             0.001            0.001 
    42         -317.645             0.001            0.001 
    43         -317.404             0.001            0.001 
    44         -316.771             0.001            0.001 
    45         -316.446             0.001            0.001 
    46         -316.617             0.001            0.001 
    47         -316.633             0.001            0.001 
    48         -317.063             0.001            0.001 
    49         -316.811             0.001            0.001 
    50         -317.130             0.001            0.001 
    51         -316.644             0.001            0.001 
    52         -316.790             0.001            0.001 
    53         -316.794             0.001            0.001 
    54         -317.288             0.001            0.001 
    55         -316.267             0.001            0.001 
    56         -317.352             0.001            0.001 
    57         -316.900             0.001            0.001 
    58         -317.040             0.001            0.001 
    59         -316.541             0.001            0.001 
    60         -316.815             0.001            0.001 
    61         -317.301             0.001            0.001 
    62         -317.026             0.001            0.001 
    63         -316.557             0.001            0.001 
    64         -316.387             0.001            0.001 
    65         -316.557             0.001            0.001 
    66         -316.495             0.001            0.001 
    67         -317.343             0.001            0.001 
    68         -317.191             0.001            0.001 
    69         -316.935             0.001            0.001 
    70         -317.144             0.001            0.001 
    71         -317.224             0.001            0.001 
    72         -316.580             0.001            0.001 
    73         -316.833             0.001            0.001 
    74         -316.894             0.001            0.001 
    75         -317.209             0.001            0.001 
    76         -316.451             0.001            0.001 
    77         -316.848             0.001            0.001 
    78         -316.821             0.001            0.001 
    79         -316.580             0.001            0.001 
    80         -316.858             0.001            0.001 
    81         -316.580             0.001            0.001 
    82         -316.536             0.001            0.001 
    83         -316.465             0.001            0.001 
    84         -316.908             0.001            0.001 
    85         -316.598             0.001            0.001 
    86         -316.935             0.001            0.001 
    87         -316.715             0.001            0.001 
    88         -317.215             0.001            0.001 
    89         -317.087             0.001            0.001 
    90         -316.433             0.001            0.001 
    91         -316.587             0.001            0.001 
    92         -316.246             0.001            0.001 
    93         -316.655             0.001            0.001 
    94         -316.155             0.001            0.001 
    95         -316.602             0.001            0.001 
    96         -317.136             0.001            0.001 
    97         -316.574             0.001            0.001 
    98         -316.657             0.001            0.001 
    99         -316.976             0.001            0.001 
   100         -317.005             0.001            0.001 
   101         -316.535             0.001            0.001 
   102         -317.038             0.001            0.001 
   103         -317.148             0.001            0.001 
   104         -316.396             0.001            0.001 
   105         -316.722             0.001            0.001 
   106         -317.032             0.001            0.001 
   107         -316.588             0.001            0.001 
   108         -316.758             0.001            0.001 
   109         -316.576             0.001            0.001 
   110         -316.149             0.001            0.001 
   111         -316.236             0.001            0.001 
   112         -316.975             0.001            0.001 
   113         -316.282             0.001            0.001 
   114         -316.620             0.001            0.001 
   115         -316.385             0.001            0.001 
   116         -316.502             0.001            0.001 
   117         -316.591             0.001            0.001 
   118         -316.690             0.001            0.001 
   119         -316.589             0.001            0.001 
   120         -316.804             0.001            0.001 
   121         -316.377             0.001            0.001 
   122         -316.638             0.001            0.001 
   123         -316.396             0.001            0.001 
   124         -316.937             0.001            0.001 
   125         -316.685             0.001            0.001 
   126         -316.505             0.001            0.001 
   127         -316.375             0.001            0.001 
   128         -316.622             0.001            0.001 
   129         -316.373             0.001            0.001 
   130         -316.054             0.001            0.001 
   131         -316.401             0.001            0.001 
   132         -316.624             0.001            0.001 
   133         -316.748             0.001            0.001 
   134         -316.751             0.001            0.001 
   135         -316.786             0.001            0.001 
   136         -316.913             0.001            0.001 
   137         -316.230             0.001            0.001 
   138         -316.784             0.001            0.001 
   139         -316.484             0.001            0.001 
   140         -316.218             0.001            0.001 
   141         -316.337             0.001            0.001 
   142         -316.730             0.001            0.001 
   143         -316.720             0.001            0.001 
   144         -316.358             0.001            0.001 
   145         -316.697             0.001            0.001 
   146         -316.582             0.001            0.001 
   147         -315.834             0.001            0.001 
   148         -316.501             0.001            0.001 
   149         -316.402             0.001            0.001 
   150         -316.508             0.001            0.001 
   151         -316.439             0.001            0.001 
   152         -316.788             0.001            0.001 
   153         -316.493             0.001            0.001 
   154         -316.819             0.001            0.001 
   155         -316.298             0.001            0.001 
   156         -316.056             0.001            0.001 
   157         -316.267             0.001            0.001 
   158         -316.822             0.001            0.001 
   159         -316.104             0.001            0.001 
   160         -316.152             0.001            0.001 
   161         -316.409             0.001            0.001 
   162         -316.528             0.001            0.001 
   163         -316.207             0.001            0.001 
   164         -316.372             0.001            0.001 
   165         -316.405             0.001            0.001 
   166         -316.656             0.001            0.001 
   167         -316.644             0.001            0.001 
   168         -316.145             0.001            0.001 
   169         -316.698             0.001            0.001 
   170         -316.318             0.001            0.001 
   171         -316.166             0.001            0.001 
   172         -316.403             0.001            0.001 
   173         -316.668             0.001            0.001 
   174         -316.460             0.001            0.001 
   175         -316.747             0.001            0.001 
   176         -316.739             0.001            0.001 
   177         -316.511             0.001            0.001 
   178         -316.411             0.001            0.001 
   179         -317.282             0.001            0.001 
   180         -316.381             0.001            0.001 
   181         -316.384             0.001            0.001 
   182         -316.466             0.001            0.001 
   183         -316.503             0.001            0.001 
   184         -316.534             0.001            0.001 
   185         -316.411             0.001            0.001 
   186         -316.460             0.001            0.001 
   187         -316.294             0.001            0.001 
   188         -316.258             0.001            0.001 
   189         -316.128             0.001            0.000 
   190         -316.272             0.001            0.000 
   191         -316.285             0.001            0.000 
   192         -316.289             0.001            0.000 
   193         -316.238             0.001            0.000 
   194         -316.575             0.001            0.000 
   195         -316.336             0.001            0.000 
   196         -316.162             0.001            0.000 
   197         -316.273             0.001            0.000 
   198         -316.691             0.001            0.000 
   199         -316.194             0.001            0.000 
   200         -316.132             0.000            0.000 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  2.5 seconds.
[[1]]
[[1]]$w
             [,1]       [,2]
[1,] 0.9682522150 0.03174779
[2,] 0.0002107095 0.99978929
[3,] 0.8869183317 0.11308167

[[1]]$tau
[1] 0.4895331 0.6772158

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -320.985
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181936-1-86c0b8.csv\n"
[1] "entropy per segment: "
[1] -9.899995e-05
[1] "entropy per segment normalized: "
[1] -9.999995e-07
[1] "entropy per segment: "
[1] 4.297812
[1] "entropy per segment normalized: "
[1] 0.04341224
ℹ The algorithm should be run with more Components 
ℹ The algorithm should be run with more Components 
# A tibble: 3 × 8
  segment_original_indx segment_name       segment_id karyotype chr   clock_mean
                  <int> <chr>                   <dbl> <chr>     <chr>      <dbl>
1                     4 chr1_144835904_19…          1 2:1       chr1       0.899
2                    23 chr6_212500_43417…          2 2:0       chr6       0.429
3                    72 chr17_1389_119824…          3 2:0       chr17      0.429
# ℹ 2 more variables: clock_low <dbl>, clock_high <dbl>
# A tibble: 2 × 4
      K   BIC Log_lik   ICL
  <int> <dbl>   <dbl> <dbl>
1     1  646.   -316.  646.
2     2  639.   -308.  657.
ℹ Fitting segment with index 4
Running MCMC with 8 parallel chains...

Chain 1 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 1 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 1 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 1 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 2 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 2 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 2 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 2 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 3 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 3 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 3 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 3 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 4 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 4 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 4 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 4 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 5 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 5 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 5 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 5 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 5 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 5 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 5 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 5 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 5 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 5 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 5 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 5 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 5 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 5 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 5 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 5 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 5 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 5 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 5 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 5 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 5 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 5 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 5 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 5 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 5 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 5 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 5 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 5 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 5 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 5 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 5 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 5 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 5 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 5 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 6 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 6 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 6 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 6 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 6 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 6 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 6 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 6 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 6 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 6 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 6 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 6 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 6 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 6 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 6 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 6 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 6 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 6 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 6 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 6 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 6 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 6 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 6 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 6 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 6 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 6 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 6 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 6 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 6 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 6 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 6 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 6 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 6 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 6 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 6 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 6 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 7 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 7 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 7 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 7 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 7 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 7 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 7 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 7 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 7 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 7 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 7 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 7 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 7 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 7 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 7 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 7 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 7 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 7 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 7 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 7 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 7 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 7 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 7 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 7 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 7 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 7 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 7 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 7 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 7 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 7 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 7 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 7 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 7 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 7 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 7 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 8 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 8 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 8 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 8 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 8 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 8 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 8 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 8 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 8 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 8 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 8 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 8 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 8 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 8 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 8 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 8 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 8 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 8 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 8 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 8 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 8 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 8 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 8 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 8 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 8 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 8 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 8 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 8 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 8 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 8 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 8 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 8 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 1 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 1 finished in 0.5 seconds.
Chain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 3 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 3 finished in 0.5 seconds.
Chain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 4 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 4 finished in 0.5 seconds.
Chain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 2 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 5 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 5 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 5 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 5 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 5 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 5 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 5 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 5 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 6 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 6 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 6 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 6 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 6 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 6 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 7 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 7 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 7 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 7 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 7 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 7 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 7 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 8 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 8 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 8 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 8 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 8 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 8 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 8 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 8 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 2 finished in 0.6 seconds.
Chain 5 finished in 0.5 seconds.
Chain 6 finished in 0.5 seconds.
Chain 7 finished in 0.5 seconds.
Chain 8 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 8 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 8 finished in 0.5 seconds.

All 8 chains finished successfully.
Mean chain execution time: 0.5 seconds.
Total execution time: 0.9 seconds.

ℹ Fitting segment with index 23
Running MCMC with 8 parallel chains...

Chain 1 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 1 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 1 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 1 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 1 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 2 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 2 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 2 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 2 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 2 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 3 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 3 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 3 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 3 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 3 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 4 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 4 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 4 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 4 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 4 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 5 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 5 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 5 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 5 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 5 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 5 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 5 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 5 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 5 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 5 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 5 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 5 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 5 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 5 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 5 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 5 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 5 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 5 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 5 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 5 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 5 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 5 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 5 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 5 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 5 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 5 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 5 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 5 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 5 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 5 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 5 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 5 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 5 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 5 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 5 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 5 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 5 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 5 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 5 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 5 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 5 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 5 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 6 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 6 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 6 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 6 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 6 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 6 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 6 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 6 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 6 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 6 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 6 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 6 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 6 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 6 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 6 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 6 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 6 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 6 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 6 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 6 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 6 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 6 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 6 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 6 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 6 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 6 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 6 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 6 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 6 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 6 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 6 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 6 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 6 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 6 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 6 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 6 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 6 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 6 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 6 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 6 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 7 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 7 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 7 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 7 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 7 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 7 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 7 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 7 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 7 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 7 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 7 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 7 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 7 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 7 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 7 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 7 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 7 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 7 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 7 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 7 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 7 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 7 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 7 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 7 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 7 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 7 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 7 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 7 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 7 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 7 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 7 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 7 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 7 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 7 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 7 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 7 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 7 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 8 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 8 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 8 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 8 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 8 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 8 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 8 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 8 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 8 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 8 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 8 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 8 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 8 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 8 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 8 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 8 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 8 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 8 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 8 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 8 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 8 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 8 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 8 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 8 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 8 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 8 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 8 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 8 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 8 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 8 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 8 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 8 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 8 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 8 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 8 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 8 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 1 finished in 0.2 seconds.
Chain 2 finished in 0.2 seconds.
Chain 3 finished in 0.2 seconds.
Chain 4 finished in 0.2 seconds.
Chain 5 finished in 0.2 seconds.
Chain 6 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 6 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 6 finished in 0.2 seconds.
Chain 7 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 7 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 7 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 7 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 7 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 7 finished in 0.2 seconds.
Chain 8 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 8 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 8 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 8 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 8 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 8 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 8 finished in 0.2 seconds.

All 8 chains finished successfully.
Mean chain execution time: 0.2 seconds.
Total execution time: 0.5 seconds.

ℹ Fitting segment with index 72
Running MCMC with 8 parallel chains...

Chain 1 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 1 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 1 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 1 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 1 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 2 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 2 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 2 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 2 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 2 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 3 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 3 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 3 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 3 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 3 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 4 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 4 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 4 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 4 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 4 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 5 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 5 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 5 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 5 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 5 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 5 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 5 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 5 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 5 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 5 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 5 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 5 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 5 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 5 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 5 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 5 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 5 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 5 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 5 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 5 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 5 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 5 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 5 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 5 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 5 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 5 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 5 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 5 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 5 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 5 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 5 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 5 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 5 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 5 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 5 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 5 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 5 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 5 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 5 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 5 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 5 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 5 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 6 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 6 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 6 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 6 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 6 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 6 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 6 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 6 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 6 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 6 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 6 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 6 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 6 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 6 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 6 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 6 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 6 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 6 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 6 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 6 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 6 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 6 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 6 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 6 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 6 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 6 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 6 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 6 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 6 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 6 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 6 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 6 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 6 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 6 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 6 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 6 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 6 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 6 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 6 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 6 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 6 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 6 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 7 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 7 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 7 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 7 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 7 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 7 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 7 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 7 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 7 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 7 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 7 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 7 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 7 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 7 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 7 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 7 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 7 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 7 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 7 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 7 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 7 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 7 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 7 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 7 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 7 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 7 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 7 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 7 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 7 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 7 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 7 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 7 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 7 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 7 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 7 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 7 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 7 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 7 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 7 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 7 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 7 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 7 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 8 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 8 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 8 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 8 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 8 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 8 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 8 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 8 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 8 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 8 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 8 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 8 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 8 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 8 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 8 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 8 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 8 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 8 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 8 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 8 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 8 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 8 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 8 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 8 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 8 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 8 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 8 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 8 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 8 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 8 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 8 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 8 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 8 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 8 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 8 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 8 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 8 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 8 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 8 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 8 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 8 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 8 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 1 finished in 0.1 seconds.
Chain 2 finished in 0.1 seconds.
Chain 3 finished in 0.1 seconds.
Chain 4 finished in 0.1 seconds.
Chain 5 finished in 0.1 seconds.
Chain 6 finished in 0.1 seconds.
Chain 7 finished in 0.1 seconds.
Chain 8 finished in 0.1 seconds.

All 8 chains finished successfully.
Mean chain execution time: 0.1 seconds.
Total execution time: 0.4 seconds.

# A tibble: 3 × 7
  tau_low tau_mean tau_high segment karyotype chr   segment_id              
    <dbl>    <dbl>    <dbl>   <int> <chr>     <chr> <chr>                   
1   0.855    1.03     1.19        4 2:1       chr1  chr1_144835904_193673916
2   0.255    0.441    0.628      23 2:0       chr6  chr6_212500_43417499    
3   0.278    0.599    0.864      72 2:0       chr17 chr17_1389_11982499     
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
Error processing 00bf0350-8c7c-4b9e-8143-13ea2dc1122f: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
ℹ Adding segment with index 11 to segments included in the inference.
[1] 12
ℹ Adding segment with index 12 to segments included in the inference.
[1] 13
[1] 14
ℹ Adding segment with index 14 to segments included in the inference.
[1] 15
[1] 16
ℹ Adding segment with index 16 to segments included in the inference.
[1] 17
[1] 18
ℹ Adding segment with index 18 to segments included in the inference.
[1] 19
ℹ Adding segment with index 19 to segments included in the inference.
[1] 20
[1] 21
ℹ Adding segment with index 21 to segments included in the inference.
[1] 22
[1] 23
[1] 24
[1] 25
ℹ Adding segment with index 25 to segments included in the inference.
[1] 26
[1] 27
ℹ Adding segment with index 27 to segments included in the inference.
[1] 28
ℹ Adding segment with index 28 to segments included in the inference.
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
[1] 98
[1] 99
[1] 100
[1] 101
[1] 102
[1] 103
[1] 104
[1] 105
[1] 106
[1] 107
[1] 108
ℹ Adding segment with index 108 to segments included in the inference.
[1] 109
ℹ Adding segment with index 109 to segments included in the inference.
[1] 110
ℹ Adding segment with index 110 to segments included in the inference.
[1] 111
[1] 112
ℹ Adding segment with index 112 to segments included in the inference.
[1] 113
ℹ Adding segment with index 113 to segments included in the inference.
[1] 114
ℹ Adding segment with index 114 to segments included in the inference.
[1] 115
ℹ Adding segment with index 115 to segments included in the inference.
[1] 116
[1] 117
ℹ Adding segment with index 117 to segments included in the inference.
[1] 118
[1] 119
[1] 120
[1] 121
[1] 122
[1] 123
[1] 124
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
[1] 130
[1] 131
[1] 132
[1] 133
ℹ Adding segment with index 133 to segments included in the inference.
[1] 134
[1] 135
ℹ Adding segment with index 135 to segments included in the inference.
[1] 136
[1] 137
ℹ Adding segment with index 137 to segments included in the inference.
[1] 138
ℹ Adding segment with index 138 to segments included in the inference.
[1] 139
ℹ Adding segment with index 139 to segments included in the inference.
[1] 140
[1] 141
[1] 142
ℹ Adding segment with index 142 to segments included in the inference.
[1] 143
ℹ Adding segment with index 143 to segments included in the inference.
[1] 144
ℹ Adding segment with index 144 to segments included in the inference.
[1] 145
ℹ Adding segment with index 145 to segments included in the inference.
[1] 146
[1] 147
[1] 148
[1] 149
[1] 150
[1] 151
[1] 152
[1] 153
[1] 154
[1] 155
[1] 156
[1] 157
[1] 158
[1] 159
[1] 160
[1] 161
[1] 162
[1] 163
[1] 164
[1] 165
[1] 166
[1] 167
[1] 168
[1] 169
[1] 170
[1] 171
[1] 172
[1] 173
[1] 174
[1] 175
[1] 176
[1] 177
[1] 178
[1] 179
[1] 180
[1] 181
[1] 182
[1] 183
[1] 184
[1] 185
[1] 186
[1] 187
[1] 188
[1] 189
[1] 190
[1] 191
[1] 192
[1] 193
[1] 194
[1] 195
[1] 196
[1] 197
[1] 198
[1] 199
[1] 200
[1] 201
[1] 202
[1] 203
[1] 204
[1] 205
[1] 206
[1] 207
[1] 208
[1] 209
[1] 210
[1] 211
[1] 212
[1] 213
[1] 214
[1] 215
[1] 216
[1] 217
[1] 218
[1] 219
ℹ Adding segment with index 219 to segments included in the inference.
[1] 220
[1] 221
ℹ Adding segment with index 221 to segments included in the inference.
[1] 222
ℹ Adding segment with index 222 to segments included in the inference.
[1] 223
ℹ Adding segment with index 223 to segments included in the inference.
[1] 224
[1] 225
[1] 226
[1] 227
[1] 228
[1] 229
[1] 230
[1] 231
[1] 232
[1] 233
[1] 234
[1] 235
[1] 236
[1] 237
[1] 238
[1] 239
[1] 240
[1] 241
[1] 242
[1] 243
[1] 244
[1] 245
[1] 246
[1] 247
[1] 248
[1] 249
[1] 250
[1] 251
init_taus from clustering  0.650643091938555Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.002113 seconds 
1000 transitions using 10 leapfrog steps per transition would take 21.13 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -6770.298             1.000            1.000 
     2        -6764.270             0.500            1.000 
     3        -6754.111             0.334            0.002 
     4        -6753.627             0.251            0.002 
     5        -6750.682             0.201            0.001 
     6        -6752.131             0.167            0.001 
     7        -6750.952             0.143            0.000 
     8        -6750.533             0.125            0.000 
     9        -6749.646             0.111            0.000 
    10        -6750.537             0.100            0.000 
    11        -6749.368             0.091            0.000 
    12        -6749.508             0.084            0.000 
    13        -6748.838             0.077            0.000 
    14        -6748.501             0.072            0.000 
    15        -6748.283             0.067            0.000 
    16        -6748.557             0.063            0.000 
    17        -6748.027             0.059            0.000 
    18        -6748.087             0.056            0.000 
    19        -6748.594             0.053            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  5.6 seconds.
[[1]]
[[1]]$w
      [,1]
 [1,]    1
 [2,]    1
 [3,]    1
 [4,]    1
 [5,]    1
 [6,]    1
 [7,]    1
 [8,]    1
 [9,]    1
[10,]    1
[11,]    1
[12,]    1
[13,]    1
[14,]    1
[15,]    1
[16,]    1
[17,]    1
[18,]    1
[19,]    1
[20,]    1
[21,]    1
[22,]    1
[23,]    1
[24,]    1
[25,]    1
[26,]    1
[27,]    1
[28,]    1
[29,]    1
[30,]    1
[31,]    1

[[1]]$tau
[1] 0.6506431

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -6754.11
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.002069 seconds 
1000 transitions using 10 leapfrog steps per transition would take 20.69 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -7145.926             1.000            1.000 
     2        -6748.413             0.529            1.000 
     3        -6747.860             0.353            0.059 
     4        -6748.464             0.265            0.059 
     5        -6748.042             0.212            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  4.3 seconds.
[[1]]
[[1]]$w
      [,1]
 [1,]    1
 [2,]    1
 [3,]    1
 [4,]    1
 [5,]    1
 [6,]    1
 [7,]    1
 [8,]    1
 [9,]    1
[10,]    1
[11,]    1
[12,]    1
[13,]    1
[14,]    1
[15,]    1
[16,]    1
[17,]    1
[18,]    1
[19,]    1
[20,]    1
[21,]    1
[22,]    1
[23,]    1
[24,]    1
[25,]    1
[26,]    1
[27,]    1
[28,]    1
[29,]    1
[30,]    1
[31,]    1

[[1]]$tau
[1] 0.6272483

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -6747.86
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181937-1-b73772.csv\n"
init_taus from clustering  0.545765592456904 init_taus from clustering  0.910080829488407Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.00372 seconds 
1000 transitions using 10 leapfrog steps per transition would take 37.2 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -6817.521             1.000            1.000 
     2        -6799.745             0.501            1.000 
     3        -6780.879             0.335            0.003 
     4        -6776.051             0.252            0.003 
     5        -6773.974             0.201            0.003 
     6        -6769.362             0.168            0.003 
     7        -6768.259             0.144            0.001 
     8        -6766.381             0.126            0.001 
     9        -6765.424             0.112            0.001 
    10        -6765.523             0.101            0.001 
    11        -6764.228             0.092            0.000 
    12        -6763.380             0.084            0.000 
    13        -6762.674             0.078            0.000 
    14        -6763.135             0.072            0.000 
    15        -6762.271             0.067            0.000 
    16        -6761.282             0.063            0.000 
    17        -6761.672             0.059            0.000 
    18        -6761.043             0.056            0.000 
    19        -6759.964             0.053            0.000 
    20        -6760.189             0.050            0.000 
    21        -6760.963             0.000            0.000 
    22        -6761.139             0.000            0.000 
    23        -6759.815             0.000            0.000 
    24        -6759.800             0.000            0.000 
    25        -6760.609             0.000            0.000 
    26        -6759.742             0.000            0.000 
    27        -6759.176             0.000            0.000 
    28        -6759.428             0.000            0.000   MEAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  17.5 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]
 [1,] 0.9075507972 0.0924492028
 [2,] 0.9842664858 0.0157335142
 [3,] 0.9440470383 0.0559529617
 [4,] 0.8018827260 0.1981172740
 [5,] 0.8580696177 0.1419303823
 [6,] 0.9469566018 0.0530433982
 [7,] 0.8018827260 0.1981172740
 [8,] 0.7637073874 0.2362926126
 [9,] 0.7593886617 0.2406113383
[10,] 0.9244820440 0.0755179560
[11,] 0.9973558761 0.0026441239
[12,] 0.9915481489 0.0084518511
[13,] 0.9115455008 0.0884544992
[14,] 0.9969442089 0.0030557911
[15,] 0.9971616978 0.0028383022
[16,] 0.9998369278 0.0001630722
[17,] 0.9952063136 0.0047936864
[18,] 0.9624424849 0.0375575151
[19,] 0.0378019352 0.9621980648
[20,] 0.8018827260 0.1981172740
[21,] 0.0044242967 0.9955757033
[22,] 0.0061393215 0.9938606785
[23,] 0.0172417791 0.9827582209
[24,] 0.0001072536 0.9998927464
[25,] 0.1578658643 0.8421341357
[26,] 0.0009072119 0.9990927881
[27,] 0.0144138334 0.9855861666
[28,] 0.9997574348 0.0002425652
[29,] 0.8018827260 0.1981172740
[30,] 0.9280943080 0.0719056920
[31,] 0.8018827260 0.1981172740

[[1]]$tau
[1] 0.5457656 0.8800000

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -6780.88
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.003689 seconds 
1000 transitions using 10 leapfrog steps per transition would take 36.89 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -6842.266             1.000            1.000 
     2        -6824.320             0.501            1.000 
     3        -6810.248             0.335            0.003 
     4        -6801.795             0.251            0.003 
     5        -6796.408             0.201            0.002 
     6        -6789.680             0.168            0.002 
     7        -6787.540             0.144            0.001 
     8        -6784.339             0.126            0.001 
     9        -6781.650             0.112            0.001 
    10        -6777.830             0.101            0.001 
    11        -6779.357             0.092            0.001 
    12        -6777.068             0.084            0.001 
    13        -6776.246             0.078            0.001 
    14        -6774.242             0.072            0.001 
    15        -6775.247             0.067            0.000 
    16        -6772.679             0.063            0.000 
    17        -6772.115             0.059            0.000 
    18        -6770.098             0.056            0.000 
    19        -6769.192             0.053            0.000 
    20        -6769.386             0.051            0.000 
    21        -6766.569             0.001            0.000 
    22        -6767.908             0.000            0.000 
    23        -6766.375             0.000            0.000 
    24        -6766.192             0.000            0.000 
    25        -6766.021             0.000            0.000 
    26        -6765.209             0.000            0.000 
    27        -6764.097             0.000            0.000 
    28        -6763.429             0.000            0.000 
    29        -6764.644             0.000            0.000 
    30        -6764.031             0.000            0.000 
    31        -6762.506             0.000            0.000 
    32        -6763.890             0.000            0.000 
    33        -6763.622             0.000            0.000 
    34        -6761.185             0.000            0.000 
    35        -6763.078             0.000            0.000 
    36        -6762.561             0.000            0.000 
    37        -6761.330             0.000            0.000 
    38        -6761.356             0.000            0.000 
    39        -6761.797             0.000            0.000 
    40        -6762.477             0.000            0.000 
    41        -6761.169             0.000            0.000 
    42        -6761.980             0.000            0.000 
    43        -6761.143             0.000            0.000 
    44        -6760.633             0.000            0.000 
    45        -6760.008             0.000            0.000 
    46        -6760.609             0.000            0.000 
    47        -6760.586             0.000            0.000 
    48        -6759.557             0.000            0.000 
    49        -6759.102             0.000            0.000 
    50        -6760.647             0.000            0.000 
    51        -6760.438             0.000            0.000 
    52        -6760.082             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  20.8 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]
 [1,] 0.9075507972 0.0924492028
 [2,] 0.9842664858 0.0157335142
 [3,] 0.9440470383 0.0559529617
 [4,] 0.8018827260 0.1981172740
 [5,] 0.8580696177 0.1419303823
 [6,] 0.9469566018 0.0530433982
 [7,] 0.8018827260 0.1981172740
 [8,] 0.7637073874 0.2362926126
 [9,] 0.7593886617 0.2406113383
[10,] 0.9244820440 0.0755179560
[11,] 0.9973558761 0.0026441239
[12,] 0.9915481489 0.0084518511
[13,] 0.9115455008 0.0884544992
[14,] 0.9969442089 0.0030557911
[15,] 0.9971616978 0.0028383022
[16,] 0.9998369278 0.0001630722
[17,] 0.9952063136 0.0047936864
[18,] 0.9624424849 0.0375575151
[19,] 0.0378019352 0.9621980648
[20,] 0.8018827260 0.1981172740
[21,] 0.0044242967 0.9955757033
[22,] 0.0061393215 0.9938606785
[23,] 0.0172417791 0.9827582209
[24,] 0.0001072536 0.9998927464
[25,] 0.1578658643 0.8421341357
[26,] 0.0009072119 0.9990927881
[27,] 0.0144138334 0.9855861666
[28,] 0.9997574348 0.0002425652
[29,] 0.8018827260 0.1981172740
[30,] 0.9280943080 0.0719056920
[31,] 0.8018827260 0.1981172740

[[1]]$tau
[1] 0.8572375 0.5181757

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -6810.25
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181937-1-3dfed7.csv\n"
init_taus from clustering  0.474401771506138 init_taus from clustering  0.931043043845439 init_taus from clustering  0.657687008889511Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.005066 seconds 
1000 transitions using 10 leapfrog steps per transition would take 50.66 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -6887.952             1.000            1.000 
     2        -6833.533             0.504            1.000 
     3        -6821.104             0.337            0.008 
     4        -6812.180             0.253            0.008 
     5        -6807.939             0.202            0.002 
     6        -6805.337             0.169            0.002 
     7        -6802.186             0.145            0.001 
     8        -6794.911             0.127            0.001 
     9        -6792.462             0.113            0.001 
    10        -6790.067             0.101            0.001 
    11        -6789.384             0.092            0.001 
    12        -6786.182             0.085            0.001 
    13        -6785.946             0.078            0.000 
    14        -6785.125             0.073            0.000 
    15        -6783.221             0.068            0.000 
    16        -6781.439             0.063            0.000 
    17        -6780.048             0.060            0.000 
    18        -6779.699             0.056            0.000 
    19        -6778.824             0.053            0.000 
    20        -6779.052             0.051            0.000 
    21        -6776.215             0.001            0.000 
    22        -6778.043             0.000            0.000 
    23        -6776.852             0.000            0.000 
    24        -6776.265             0.000            0.000 
    25        -6776.125             0.000            0.000 
    26        -6775.388             0.000            0.000 
    27        -6774.037             0.000            0.000 
    28        -6773.062             0.000            0.000 
    29        -6771.829             0.000            0.000 
    30        -6772.922             0.000            0.000 
    31        -6772.660             0.000            0.000 
    32        -6770.796             0.000            0.000 
    33        -6772.437             0.000            0.000 
    34        -6771.480             0.000            0.000 
    35        -6771.317             0.000            0.000 
    36        -6769.170             0.000            0.000 
    37        -6770.490             0.000            0.000 
    38        -6769.886             0.000            0.000 
    39        -6769.425             0.000            0.000 
    40        -6768.808             0.000            0.000 
    41        -6768.852             0.000            0.000 
    42        -6771.356             0.000            0.000 
    43        -6767.917             0.000            0.000 
    44        -6768.647             0.000            0.000 
    45        -6766.597             0.000            0.000 
    46        -6768.557             0.000            0.000 
    47        -6768.956             0.000            0.000 
    48        -6768.983             0.000            0.000 
    49        -6768.528             0.000            0.000 
    50        -6769.020             0.000            0.000 
    51        -6767.730             0.000            0.000 
    52        -6766.634             0.000            0.000 
    53        -6766.659             0.000            0.000 
    54        -6765.835             0.000            0.000 
    55        -6767.194             0.000            0.000 
    56        -6766.728             0.000            0.000 
    57        -6767.212             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  30.8 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]
 [1,] 0.8653527651 0.0277048136 0.1069424213
 [2,] 0.9850731463 0.0019210285 0.0130058252
 [3,] 0.9538512923 0.0080062150 0.0381424927
 [4,] 0.0022938682 0.0012611991 0.9964449327
 [5,] 0.0014981224 0.0006567284 0.9978451492
 [6,] 0.0810914469 0.0162737525 0.9026348006
 [7,] 0.0022938682 0.0012611991 0.9964449327
 [8,] 0.0082152670 0.0051676645 0.9866170685
 [9,] 0.0090231217 0.0057716474 0.9852052309
[10,] 0.9066128413 0.0178548117 0.0755323470
[11,] 0.8521781338 0.0141617604 0.1336601057
[12,] 0.9426373414 0.0064139837 0.0509486749
[13,] 0.8749749543 0.0253032294 0.0997218163
[14,] 0.8625816968 0.0133652592 0.1240530439
[15,] 0.8572248447 0.0137780933 0.1289970620
[16,] 0.6660794748 0.0251974805 0.3087230446
[17,] 0.8971313318 0.0105565794 0.0923120889
[18,] 0.9902877416 0.0015511747 0.0081610837
[19,] 0.0163673517 0.9451815028 0.0384511455
[20,] 0.0022938682 0.0012611991 0.9964449327
[21,] 0.0002056002 0.9994036837 0.0003907161
[22,] 0.0127318334 0.9457470616 0.0415211051
[23,] 0.0049422694 0.9826326004 0.0124251302
[24,] 0.0026214826 0.9897404760 0.0076380415
[25,] 0.0806544086 0.4976636681 0.4216819233
[26,] 0.0053015879 0.9785524088 0.0161460034
[27,] 0.0036110709 0.9872299779 0.0091589513
[28,] 0.6519128974 0.0258096178 0.3222774848
[29,] 0.0022938682 0.0012611991 0.9964449327
[30,] 0.0444303467 0.0108453000 0.9447243533
[31,] 0.0022938682 0.0012611991 0.9964449327

[[1]]$tau
[1] 0.4744018 0.8800000 0.6576870

[[1]]$phi
[1] 0.3333333 0.3333333 0.3333333

[[1]]$kappa
[1] 5


ELBO for this run: -6821.1
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.005577 seconds 
1000 transitions using 10 leapfrog steps per transition would take 55.77 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -6898.936             1.000            1.000 
     2        -6845.176             0.504            1.000 
     3        -6816.579             0.337            0.008 
     4        -6806.803             0.253            0.008 
     5        -6797.997             0.203            0.004 
     6        -6793.794             0.169            0.004 
     7        -6788.915             0.145            0.001 
     8        -6788.368             0.127            0.001 
     9        -6782.437             0.113            0.001 
    10        -6781.653             0.102            0.001 
    11        -6779.390             0.093            0.001 
    12        -6777.306             0.085            0.001 
    13        -6776.895             0.078            0.001 
    14        -6774.484             0.073            0.001 
    15        -6774.401             0.068            0.001 
    16        -6774.201             0.064            0.001 
    17        -6774.411             0.060            0.000 
    18        -6773.160             0.057            0.000 
    19        -6773.102             0.054            0.000 
    20        -6771.672             0.051            0.000 
    21        -6771.849             0.001            0.000 
    22        -6771.052             0.001            0.000 
    23        -6770.498             0.000            0.000 
    24        -6768.218             0.000            0.000 
    25        -6770.137             0.000            0.000 
    26        -6769.106             0.000            0.000 
    27        -6769.527             0.000            0.000 
    28        -6770.631             0.000            0.000 
    29        -6769.291             0.000            0.000 
    30        -6769.764             0.000            0.000 
    31        -6767.220             0.000            0.000 
    32        -6767.632             0.000            0.000 
    33        -6768.363             0.000            0.000 
    34        -6767.446             0.000            0.000 
    35        -6767.927             0.000            0.000 
    36        -6766.232             0.000            0.000 
    37        -6766.643             0.000            0.000 
    38        -6768.666             0.000            0.000 
    39        -6767.046             0.000            0.000 
    40        -6765.660             0.000            0.000 
    41        -6765.683             0.000            0.000 
    42        -6766.923             0.000            0.000 
    43        -6766.567             0.000            0.000 
    44        -6766.185             0.000            0.000 
    45        -6766.682             0.000            0.000 
    46        -6766.421             0.000            0.000 
    47        -6767.214             0.000            0.000 
    48        -6765.596             0.000            0.000 
    49        -6766.544             0.000            0.000 
    50        -6764.607             0.000            0.000 
    51        -6765.389             0.000            0.000 
    52        -6764.938             0.000            0.000 
    53        -6765.423             0.000            0.000 
    54        -6765.313             0.000            0.000 
    55        -6764.863             0.000            0.000 
    56        -6765.113             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  30.7 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]
 [1,] 0.8653527651 0.0277048136 0.1069424213
 [2,] 0.9850731463 0.0019210285 0.0130058252
 [3,] 0.9538512923 0.0080062150 0.0381424927
 [4,] 0.0022938682 0.0012611991 0.9964449327
 [5,] 0.0014981224 0.0006567284 0.9978451492
 [6,] 0.0810914469 0.0162737525 0.9026348006
 [7,] 0.0022938682 0.0012611991 0.9964449327
 [8,] 0.0082152670 0.0051676645 0.9866170685
 [9,] 0.0090231217 0.0057716474 0.9852052309
[10,] 0.9066128413 0.0178548117 0.0755323470
[11,] 0.8521781338 0.0141617604 0.1336601057
[12,] 0.9426373414 0.0064139837 0.0509486749
[13,] 0.8749749543 0.0253032294 0.0997218163
[14,] 0.8625816968 0.0133652592 0.1240530439
[15,] 0.8572248447 0.0137780933 0.1289970620
[16,] 0.6660794748 0.0251974805 0.3087230446
[17,] 0.8971313318 0.0105565794 0.0923120889
[18,] 0.9902877416 0.0015511747 0.0081610837
[19,] 0.0163673517 0.9451815028 0.0384511455
[20,] 0.0022938682 0.0012611991 0.9964449327
[21,] 0.0002056002 0.9994036837 0.0003907161
[22,] 0.0127318334 0.9457470616 0.0415211051
[23,] 0.0049422694 0.9826326004 0.0124251302
[24,] 0.0026214826 0.9897404760 0.0076380415
[25,] 0.0806544086 0.4976636681 0.4216819233
[26,] 0.0053015879 0.9785524088 0.0161460034
[27,] 0.0036110709 0.9872299779 0.0091589513
[28,] 0.6519128974 0.0258096178 0.3222774848
[29,] 0.0022938682 0.0012611991 0.9964449327
[30,] 0.0444303467 0.0108453000 0.9447243533
[31,] 0.0022938682 0.0012611991 0.9964449327

[[1]]$tau
[1] 0.8054217 0.6045606 0.6794275

[[1]]$phi
[1] 0.3333333 0.3333333 0.3333333

[[1]]$kappa
[1] 5


ELBO for this run: -6816.58
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181938-1-63475d.csv\n"
init_taus from clustering  0.663395073654293 init_taus from clustering  0.932378748613254 init_taus from clustering  0.524566614656251 init_taus from clustering  0.4010095807282Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.006565 seconds 
1000 transitions using 10 leapfrog steps per transition would take 65.65 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -6932.906             1.000            1.000 
     2        -6889.356             0.503            1.000 
     3        -6846.336             0.338            0.006 
     4        -6830.542             0.254            0.006 
     5        -6819.051             0.203            0.006 
     6        -6811.757             0.170            0.006 
     7        -6805.610             0.146            0.002 
     8        -6802.363             0.127            0.002 
     9        -6800.254             0.113            0.002 
    10        -6797.898             0.102            0.002 
    11        -6795.904             0.093            0.001 
    12        -6795.674             0.085            0.001 
    13        -6795.541             0.078            0.001 
    14        -6793.137             0.073            0.001 
    15        -6790.958             0.068            0.000 
    16        -6788.595             0.064            0.000 
    17        -6789.125             0.060            0.000 
    18        -6787.970             0.057            0.000 
    19        -6787.946             0.054            0.000 
    20        -6784.831             0.051            0.000 
    21        -6785.775             0.001            0.000 
    22        -6783.746             0.001            0.000 
    23        -6783.122             0.000            0.000 
    24        -6784.183             0.000            0.000 
    25        -6781.508             0.000            0.000 
    26        -6781.365             0.000            0.000 
    27        -6782.278             0.000            0.000 
    28        -6780.810             0.000            0.000 
    29        -6781.101             0.000            0.000 
    30        -6779.773             0.000            0.000 
    31        -6779.552             0.000            0.000 
    32        -6779.504             0.000            0.000 
    33        -6779.960             0.000            0.000 
    34        -6777.990             0.000            0.000 
    35        -6777.682             0.000            0.000 
    36        -6778.222             0.000            0.000 
    37        -6778.997             0.000            0.000 
    38        -6778.731             0.000            0.000 
    39        -6780.368             0.000            0.000 
    40        -6780.272             0.000            0.000 
    41        -6777.626             0.000            0.000 
    42        -6778.440             0.000            0.000 
    43        -6778.572             0.000            0.000 
    44        -6776.951             0.000            0.000 
    45        -6776.607             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  36.7 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]
 [1,] 0.0078601746 0.0021767901 0.0289711113 0.9609919240
 [2,] 0.0294670301 0.0045094403 0.8659258343 0.1000976953
 [3,] 0.0127099797 0.0028383362 0.0756406758 0.9088110082
 [4,] 0.9988454153 0.0002555619 0.0006435007 0.0002555222
 [5,] 0.9860613063 0.0019916028 0.0094533027 0.0024937882
 [6,] 0.7397585201 0.0170348583 0.2061089383 0.0370976833
 [7,] 0.9988454153 0.0002555619 0.0006435007 0.0002555222
 [8,] 0.9884399890 0.0024766187 0.0069166259 0.0021667664
 [9,] 0.9867056450 0.0028852160 0.0079231790 0.0024859601
[10,] 0.0001119939 0.0001029046 0.0001538083 0.9996312933
[11,] 0.0002760764 0.0001200169 0.9992936308 0.0003102759
[12,] 0.0099992753 0.0014169920 0.9682163149 0.0203674178
[13,] 0.0049692683 0.0013769942 0.0189464746 0.9747072629
[14,] 0.0001024399 0.0001002468 0.9996942434 0.0001030699
[15,] 0.0001580939 0.0001066297 0.9995642446 0.0001710318
[16,] 0.0410271058 0.0037601209 0.9303816410 0.0248311323
[17,] 0.0016312613 0.0002869686 0.9956813561 0.0024004140
[18,] 0.0409721932 0.0078372637 0.3756830164 0.5755075267
[19,] 0.0376852396 0.9314057743 0.0189398938 0.0119690923
[20,] 0.9988454153 0.0002555619 0.0006435007 0.0002555222
[21,] 0.0002563819 0.9994344819 0.0001685936 0.0001405426
[22,] 0.0453277871 0.9280279274 0.0171213200 0.0095229656
[23,] 0.0118795244 0.9790165379 0.0056298656 0.0034740721
[24,] 0.0089415382 0.9851810308 0.0037098210 0.0021676100
[25,] 0.4116440739 0.4386534919 0.1013494525 0.0483529816
[26,] 0.0182541756 0.9702533625 0.0073106065 0.0041818554
[27,] 0.0086417356 0.9847900412 0.0040633364 0.0025048868
[28,] 0.0467667384 0.0042006509 0.9219552949 0.0270773158
[29,] 0.9988454153 0.0002555619 0.0006435007 0.0002555222
[30,] 0.8397730688 0.0131704595 0.1223621598 0.0246943119
[31,] 0.9988454153 0.0002555619 0.0006435007 0.0002555222

[[1]]$tau
[1] 0.6633951 0.8800000 0.5245666 0.4010096

[[1]]$phi
[1] 0.25 0.25 0.25 0.25

[[1]]$kappa
[1] 5


ELBO for this run: -6846.34
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.007431 seconds 
1000 transitions using 10 leapfrog steps per transition would take 74.31 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -7039.762             1.000            1.000 
     2        -6909.358             0.509            1.000 
     3        -6887.336             0.341            0.019 
     4        -6865.143             0.256            0.019 
     5        -6854.206             0.205            0.003 
     6        -6847.895             0.171            0.003 
     7        -6842.652             0.147            0.003 
     8        -6835.219             0.129            0.003 
     9        -6832.861             0.114            0.002 
    10        -6829.396             0.103            0.002 
    11        -6823.619             0.094            0.001 
    12        -6822.717             0.086            0.001 
    13        -6815.760             0.079            0.001 
    14        -6815.305             0.074            0.001 
    15        -6815.658             0.069            0.001 
    16        -6806.264             0.065            0.001 
    17        -6807.406             0.061            0.001 
    18        -6808.427             0.057            0.001 
    19        -6804.370             0.054            0.001 
    20        -6807.792             0.052            0.001 
    21        -6801.943             0.002            0.001 
    22        -6799.454             0.001            0.001 
    23        -6801.925             0.001            0.001 
    24        -6795.901             0.001            0.001 
    25        -6797.086             0.001            0.001 
    26        -6793.271             0.001            0.001 
    27        -6796.894             0.001            0.001 
    28        -6795.089             0.000            0.001 
    29        -6793.398             0.000            0.001 
    30        -6792.806             0.000            0.000 
    31        -6790.509             0.000            0.000 
    32        -6792.384             0.000            0.000 
    33        -6788.802             0.000            0.000 
    34        -6790.033             0.000            0.000 
    35        -6788.603             0.000            0.000 
    36        -6788.156             0.000            0.000 
    37        -6789.041             0.000            0.000 
    38        -6787.407             0.000            0.000 
    39        -6785.687             0.000            0.000 
    40        -6785.052             0.000            0.000 
    41        -6785.017             0.000            0.000 
    42        -6786.424             0.000            0.000 
    43        -6784.173             0.000            0.000 
    44        -6782.646             0.000            0.000 
    45        -6783.521             0.000            0.000 
    46        -6783.360             0.000            0.000 
    47        -6782.690             0.000            0.000 
    48        -6786.891             0.000            0.000 
    49        -6783.247             0.000            0.000 
    50        -6782.515             0.000            0.000 
    51        -6783.469             0.000            0.000 
    52        -6781.126             0.000            0.000 
    53        -6781.438             0.000            0.000 
    54        -6780.393             0.000            0.000 
    55        -6780.034             0.000            0.000 
    56        -6780.102             0.000            0.000 
    57        -6780.967             0.000            0.000 
    58        -6779.861             0.000            0.000 
    59        -6780.524             0.000            0.000 
    60        -6778.756             0.000            0.000 
    61        -6779.072             0.000            0.000 
    62        -6779.646             0.000            0.000 
    63        -6780.516             0.000            0.000 
    64        -6779.135             0.000            0.000 
    65        -6779.732             0.000            0.000 
    66        -6778.348             0.000            0.000 
    67        -6777.760             0.000            0.000 
    68        -6776.651             0.000            0.000 
    69        -6778.117             0.000            0.000 
    70        -6778.755             0.000            0.000 
    71        -6776.819             0.000            0.000 
    72        -6778.514             0.000            0.000 
    73        -6776.476             0.000            0.000 
    74        -6777.966             0.000            0.000 
    75        -6776.925             0.000            0.000 
    76        -6776.206             0.000            0.000 
    77        -6777.391             0.000            0.000 
    78        -6777.044             0.000            0.000 
    79        -6776.284             0.000            0.000 
    80        -6777.096             0.000            0.000 
    81        -6776.923             0.000            0.000 
    82        -6776.228             0.000            0.000 
    83        -6776.856             0.000            0.000 
    84        -6777.450             0.000            0.000 
    85        -6775.739             0.000            0.000 
    86        -6774.520             0.000            0.000 
    87        -6775.785             0.000            0.000 
    88        -6777.640             0.000            0.000 
    89        -6774.923             0.000            0.000 
    90        -6777.633             0.000            0.000 
    91        -6776.471             0.000            0.000 
    92        -6775.399             0.000            0.000 
    93        -6775.112             0.000            0.000 
    94        -6775.096             0.000            0.000 
    95        -6775.401             0.000            0.000 
    96        -6774.354             0.000            0.000 
    97        -6774.211             0.000            0.000 
    98        -6776.394             0.000            0.000 
    99        -6773.952             0.000            0.000 
   100        -6774.957             0.000            0.000 
   101        -6775.347             0.000            0.000 
   102        -6775.266             0.000            0.000 
   103        -6774.784             0.000            0.000 
   104        -6772.180             0.000            0.000 
   105        -6773.935             0.000            0.000 
   106        -6774.938             0.000            0.000 
   107        -6775.471             0.000            0.000 
   108        -6773.542             0.000            0.000 
   109        -6773.894             0.000            0.000 
   110        -6774.395             0.000            0.000 
   111        -6774.313             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  55.5 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]
 [1,] 0.0078601746 0.0021767901 0.0289711113 0.9609919240
 [2,] 0.0294670301 0.0045094403 0.8659258343 0.1000976953
 [3,] 0.0127099797 0.0028383362 0.0756406758 0.9088110082
 [4,] 0.9988454153 0.0002555619 0.0006435007 0.0002555222
 [5,] 0.9860613063 0.0019916028 0.0094533027 0.0024937882
 [6,] 0.7397585201 0.0170348583 0.2061089383 0.0370976833
 [7,] 0.9988454153 0.0002555619 0.0006435007 0.0002555222
 [8,] 0.9884399890 0.0024766187 0.0069166259 0.0021667664
 [9,] 0.9867056450 0.0028852160 0.0079231790 0.0024859601
[10,] 0.0001119939 0.0001029046 0.0001538083 0.9996312933
[11,] 0.0002760764 0.0001200169 0.9992936308 0.0003102759
[12,] 0.0099992753 0.0014169920 0.9682163149 0.0203674178
[13,] 0.0049692683 0.0013769942 0.0189464746 0.9747072629
[14,] 0.0001024399 0.0001002468 0.9996942434 0.0001030699
[15,] 0.0001580939 0.0001066297 0.9995642446 0.0001710318
[16,] 0.0410271058 0.0037601209 0.9303816410 0.0248311323
[17,] 0.0016312613 0.0002869686 0.9956813561 0.0024004140
[18,] 0.0409721932 0.0078372637 0.3756830164 0.5755075267
[19,] 0.0376852396 0.9314057743 0.0189398938 0.0119690923
[20,] 0.9988454153 0.0002555619 0.0006435007 0.0002555222
[21,] 0.0002563819 0.9994344819 0.0001685936 0.0001405426
[22,] 0.0453277871 0.9280279274 0.0171213200 0.0095229656
[23,] 0.0118795244 0.9790165379 0.0056298656 0.0034740721
[24,] 0.0089415382 0.9851810308 0.0037098210 0.0021676100
[25,] 0.4116440739 0.4386534919 0.1013494525 0.0483529816
[26,] 0.0182541756 0.9702533625 0.0073106065 0.0041818554
[27,] 0.0086417356 0.9847900412 0.0040633364 0.0025048868
[28,] 0.0467667384 0.0042006509 0.9219552949 0.0270773158
[29,] 0.9988454153 0.0002555619 0.0006435007 0.0002555222
[30,] 0.8397730688 0.0131704595 0.1223621598 0.0246943119
[31,] 0.9988454153 0.0002555619 0.0006435007 0.0002555222

[[1]]$tau
[1] 0.5018120 0.8800000 0.6780763 0.4534866

[[1]]$phi
[1] 0.25 0.25 0.25 0.25

[[1]]$kappa
[1] 5


ELBO for this run: -6887.34
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181938-1-7cafcc.csv\n"
init_taus from clustering  0.661368899652086 init_taus from clustering  0.966679938209816 init_taus from clustering  0.400494424906071 init_taus from clustering  0.888706015010119 init_taus from clustering  0.523992530325112Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.008428 seconds 
1000 transitions using 10 leapfrog steps per transition would take 84.28 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -6987.526             1.000            1.000 
     2        -6937.720             0.504            1.000 
     3        -6896.465             0.338            0.007 
     4        -6874.207             0.254            0.007 
     5        -6864.482             0.204            0.006 
     6        -6855.658             0.170            0.006 
     7        -6850.034             0.146            0.003 
     8        -6840.846             0.128            0.003 
     9        -6841.048             0.113            0.001 
    10        -6834.784             0.102            0.001 
    11        -6827.526             0.093            0.001 
    12        -6833.890             0.085            0.001 
    13        -6828.737             0.079            0.001 
    14        -6826.421             0.073            0.001 
    15        -6822.384             0.068            0.001 
    16        -6818.044             0.064            0.001 
    17        -6816.593             0.060            0.001 
    18        -6816.175             0.057            0.001 
    19        -6812.664             0.054            0.001 
    20        -6812.593             0.051            0.001 
    21        -6809.278             0.001            0.001 
    22        -6809.938             0.001            0.001 
    23        -6807.562             0.001            0.001 
    24        -6806.253             0.001            0.001 
    25        -6807.938             0.001            0.001 
    26        -6804.645             0.001            0.000 
    27        -6802.340             0.000            0.000 
    28        -6802.535             0.000            0.000 
    29        -6804.776             0.000            0.000 
    30        -6803.039             0.000            0.000 
    31        -6801.097             0.000            0.000 
    32        -6799.906             0.000            0.000 
    33        -6799.576             0.000            0.000 
    34        -6798.901             0.000            0.000 
    35        -6797.327             0.000            0.000 
    36        -6795.311             0.000            0.000 
    37        -6795.217             0.000            0.000 
    38        -6796.824             0.000            0.000 
    39        -6798.467             0.000            0.000 
    40        -6792.846             0.000            0.000 
    41        -6795.527             0.000            0.000 
    42        -6795.218             0.000            0.000 
    43        -6794.131             0.000            0.000 
    44        -6792.989             0.000            0.000 
    45        -6790.363             0.000            0.000 
    46        -6793.016             0.000            0.000 
    47        -6790.463             0.000            0.000 
    48        -6789.722             0.000            0.000 
    49        -6791.158             0.000            0.000 
    50        -6792.854             0.000            0.000 
    51        -6789.405             0.000            0.000 
    52        -6789.719             0.000            0.000 
    53        -6787.767             0.000            0.000 
    54        -6789.261             0.000            0.000 
    55        -6787.635             0.000            0.000 
    56        -6788.646             0.000            0.000 
    57        -6788.352             0.000            0.000 
    58        -6789.118             0.000            0.000 
    59        -6789.098             0.000            0.000 
    60        -6787.747             0.000            0.000 
    61        -6786.872             0.000            0.000 
    62        -6786.188             0.000            0.000 
    63        -6787.288             0.000            0.000 
    64        -6787.201             0.000            0.000 
    65        -6787.125             0.000            0.000 
    66        -6784.209             0.000            0.000 
    67        -6785.928             0.000            0.000 
    68        -6785.491             0.000            0.000 
    69        -6787.843             0.000            0.000 
    70        -6787.238             0.000            0.000 
    71        -6787.733             0.000            0.000 
    72        -6783.859             0.000            0.000 
    73        -6784.163             0.000            0.000 
    74        -6785.927             0.000            0.000 
    75        -6785.094             0.000            0.000 
    76        -6785.437             0.000            0.000 
    77        -6786.339             0.000            0.000 
    78        -6784.007             0.000            0.000 
    79        -6786.297             0.000            0.000 
    80        -6785.956             0.000            0.000 
    81        -6785.480             0.000            0.000 
    82        -6784.264             0.000            0.000 
    83        -6783.322             0.000            0.000 
    84        -6783.898             0.000            0.000 
    85        -6782.527             0.000            0.000 
    86        -6782.647             0.000            0.000 
    87        -6783.277             0.000            0.000 
    88        -6782.149             0.000            0.000 
    89        -6782.267             0.000            0.000 
    90        -6781.347             0.000            0.000 
    91        -6782.814             0.000            0.000 
    92        -6782.929             0.000            0.000 
    93        -6783.099             0.000            0.000 
    94        -6783.848             0.000            0.000 
    95        -6781.410             0.000            0.000 
    96        -6783.209             0.000            0.000 
    97        -6784.507             0.000            0.000 
    98        -6782.405             0.000            0.000 
    99        -6784.868             0.000            0.000 
   100        -6780.378             0.000            0.000 
   101        -6781.282             0.000            0.000 
   102        -6781.930             0.000            0.000 
   103        -6782.608             0.000            0.000 
   104        -6781.399             0.000            0.000 
   105        -6781.610             0.000            0.000 
   106        -6781.501             0.000            0.000 
   107        -6780.927             0.000            0.000 
   108        -6780.283             0.000            0.000 
   109        -6781.757             0.000            0.000 
   110        -6779.972             0.000            0.000 
   111        -6778.954             0.000            0.000 
Chain 1 stan::variational::advi::calc_ELBO: The number of dropped evaluations has reached its maximum amount (100). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  69.0 seconds.
An error occurred during inference: Fitting failed. Unable to retrieve the metadata.
Error processing 00c27940-c623-11e3-bf01-24c6515278c0: object 'tol_rel_obj' not found
[1] 1
[1] 2
ℹ Adding segment with index 2 to segments included in the inference.
[1] 3
ℹ Adding segment with index 3 to segments included in the inference.
[1] 4
ℹ Adding segment with index 4 to segments included in the inference.
[1] 5
ℹ Adding segment with index 5 to segments included in the inference.
[1] 6
[1] 7
[1] 8
[1] 9
ℹ Adding segment with index 9 to segments included in the inference.
[1] 10
ℹ Adding segment with index 10 to segments included in the inference.
[1] 11
ℹ Adding segment with index 11 to segments included in the inference.
[1] 12
ℹ Adding segment with index 12 to segments included in the inference.
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
ℹ Adding segment with index 27 to segments included in the inference.
[1] 28
ℹ Adding segment with index 28 to segments included in the inference.
[1] 29
ℹ Adding segment with index 29 to segments included in the inference.
[1] 30
[1] 31
ℹ Adding segment with index 31 to segments included in the inference.
[1] 32
ℹ Adding segment with index 32 to segments included in the inference.
[1] 33
ℹ Adding segment with index 33 to segments included in the inference.
[1] 34
ℹ Adding segment with index 34 to segments included in the inference.
[1] 35
ℹ Adding segment with index 35 to segments included in the inference.
[1] 36
[1] 37
ℹ Adding segment with index 37 to segments included in the inference.
[1] 38
ℹ Adding segment with index 38 to segments included in the inference.
[1] 39
[1] 40
ℹ Adding segment with index 40 to segments included in the inference.
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
ℹ Adding segment with index 48 to segments included in the inference.
[1] 49
ℹ Adding segment with index 49 to segments included in the inference.
[1] 50
ℹ Adding segment with index 50 to segments included in the inference.
[1] 51
[1] 52
[1] 53
ℹ Adding segment with index 53 to segments included in the inference.
[1] 54
ℹ Adding segment with index 54 to segments included in the inference.
[1] 55
ℹ Adding segment with index 55 to segments included in the inference.
[1] 56
[1] 57
[1] 58
[1] 59
ℹ Adding segment with index 59 to segments included in the inference.
[1] 60
ℹ Adding segment with index 60 to segments included in the inference.
[1] 61
ℹ Adding segment with index 61 to segments included in the inference.
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
ℹ Adding segment with index 68 to segments included in the inference.
[1] 69
[1] 70
[1] 71
[1] 72
ℹ Adding segment with index 72 to segments included in the inference.
[1] 73
[1] 74
ℹ Adding segment with index 74 to segments included in the inference.
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
ℹ Adding segment with index 80 to segments included in the inference.
[1] 81
[1] 82
ℹ Adding segment with index 82 to segments included in the inference.
[1] 83
[1] 84
ℹ Adding segment with index 84 to segments included in the inference.
[1] 85
[1] 86
ℹ Adding segment with index 86 to segments included in the inference.
[1] 87
[1] 88
[1] 89
[1] 90
ℹ Adding segment with index 90 to segments included in the inference.
[1] 91
[1] 92
[1] 93
ℹ Adding segment with index 93 to segments included in the inference.
[1] 94
[1] 95
[1] 96
[1] 97
ℹ Adding segment with index 97 to segments included in the inference.
[1] 98
ℹ Adding segment with index 98 to segments included in the inference.
[1] 99
ℹ Adding segment with index 99 to segments included in the inference.
[1] 100
ℹ Adding segment with index 100 to segments included in the inference.
[1] 101
ℹ Adding segment with index 101 to segments included in the inference.
[1] 102
[1] 103
ℹ Adding segment with index 103 to segments included in the inference.
[1] 104
ℹ Adding segment with index 104 to segments included in the inference.
[1] 105
ℹ Adding segment with index 105 to segments included in the inference.
[1] 106
[1] 107
[1] 108
[1] 109
[1] 110
[1] 111
[1] 112
[1] 113
ℹ Adding segment with index 113 to segments included in the inference.
[1] 114
ℹ Adding segment with index 114 to segments included in the inference.
[1] 115
ℹ Adding segment with index 115 to segments included in the inference.
[1] 116
[1] 117
[1] 118
ℹ Adding segment with index 118 to segments included in the inference.
[1] 119
ℹ Adding segment with index 119 to segments included in the inference.
[1] 120
[1] 121
[1] 122
[1] 123
[1] 124
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
ℹ Adding segment with index 129 to segments included in the inference.
[1] 130
[1] 131
[1] 132
ℹ Adding segment with index 132 to segments included in the inference.
[1] 133
ℹ Adding segment with index 133 to segments included in the inference.
[1] 134
[1] 135
[1] 136
ℹ Adding segment with index 136 to segments included in the inference.
[1] 137
ℹ Adding segment with index 137 to segments included in the inference.
[1] 138
ℹ Adding segment with index 138 to segments included in the inference.
[1] 139
ℹ Adding segment with index 139 to segments included in the inference.
[1] 140
ℹ Adding segment with index 140 to segments included in the inference.
[1] 141
ℹ Adding segment with index 141 to segments included in the inference.
[1] 142
[1] 143
[1] 144
[1] 145
ℹ Adding segment with index 145 to segments included in the inference.
[1] 146
[1] 147
ℹ Adding segment with index 147 to segments included in the inference.
[1] 148
ℹ Adding segment with index 148 to segments included in the inference.
[1] 149
[1] 150
ℹ Adding segment with index 150 to segments included in the inference.
[1] 151
ℹ Adding segment with index 151 to segments included in the inference.
[1] 152
[1] 153
[1] 154
[1] 155
[1] 156
[1] 157
[1] 158
[1] 159
init_taus from clustering  0.723827335689196Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.005364 seconds 
1000 transitions using 10 leapfrog steps per transition would take 53.64 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17975.479             1.000            1.000 
     2       -17951.496             0.501            1.000 
     3       -17951.039             0.334            0.001 
     4       -17941.944             0.250            0.001 
     5       -17940.189             0.200            0.001 
     6       -17940.771             0.167            0.001 
     7       -17939.535             0.143            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  12.0 seconds.
[[1]]
[[1]]$w
      [,1]
 [1,]    1
 [2,]    1
 [3,]    1
 [4,]    1
 [5,]    1
 [6,]    1
 [7,]    1
 [8,]    1
 [9,]    1
[10,]    1
[11,]    1
[12,]    1
[13,]    1
[14,]    1
[15,]    1
[16,]    1
[17,]    1
[18,]    1
[19,]    1
[20,]    1
[21,]    1
[22,]    1
[23,]    1
[24,]    1
[25,]    1
[26,]    1
[27,]    1
[28,]    1
[29,]    1
[30,]    1
[31,]    1
[32,]    1
[33,]    1
[34,]    1
[35,]    1
[36,]    1
[37,]    1
[38,]    1
[39,]    1
[40,]    1
[41,]    1
[42,]    1
[43,]    1
[44,]    1
[45,]    1
[46,]    1
[47,]    1
[48,]    1
[49,]    1
[50,]    1
[51,]    1
[52,]    1
[53,]    1
[54,]    1
[55,]    1
[56,]    1
[57,]    1
[58,]    1
[59,]    1
[60,]    1
[61,]    1
[62,]    1
[63,]    1
[64,]    1

[[1]]$tau
[1] 0.7238273

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -17951
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.005288 seconds 
1000 transitions using 10 leapfrog steps per transition would take 52.88 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -17963.366             1.000            1.000 
     2       -17969.211             0.500            1.000 
     3       -17961.686             0.334            0.000 
     4       -17956.942             0.250            0.000 
     5       -17953.287             0.200            0.000 
     6       -17949.657             0.167            0.000 
     7       -17947.564             0.143            0.000 
     8       -17951.958             0.125            0.000 
     9       -17950.405             0.111            0.000 
    10       -17947.678             0.100            0.000 
    11       -17945.195             0.091            0.000 
    12       -17947.961             0.084            0.000 
    13       -17941.795             0.077            0.000 
    14       -17944.559             0.072            0.000 
    15       -17944.012             0.067            0.000 
    16       -17943.229             0.063            0.000 
    17       -17943.479             0.059            0.000 
    18       -17942.797             0.056            0.000 
    19       -17942.801             0.053            0.000 
    20       -17941.993             0.050            0.000 
    21       -17941.456             0.000            0.000 
    22       -17940.247             0.000            0.000 
    23       -17940.184             0.000            0.000 
    24       -17940.511             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  15.3 seconds.
[[1]]
[[1]]$w
      [,1]
 [1,]    1
 [2,]    1
 [3,]    1
 [4,]    1
 [5,]    1
 [6,]    1
 [7,]    1
 [8,]    1
 [9,]    1
[10,]    1
[11,]    1
[12,]    1
[13,]    1
[14,]    1
[15,]    1
[16,]    1
[17,]    1
[18,]    1
[19,]    1
[20,]    1
[21,]    1
[22,]    1
[23,]    1
[24,]    1
[25,]    1
[26,]    1
[27,]    1
[28,]    1
[29,]    1
[30,]    1
[31,]    1
[32,]    1
[33,]    1
[34,]    1
[35,]    1
[36,]    1
[37,]    1
[38,]    1
[39,]    1
[40,]    1
[41,]    1
[42,]    1
[43,]    1
[44,]    1
[45,]    1
[46,]    1
[47,]    1
[48,]    1
[49,]    1
[50,]    1
[51,]    1
[52,]    1
[53,]    1
[54,]    1
[55,]    1
[56,]    1
[57,]    1
[58,]    1
[59,]    1
[60,]    1
[61,]    1
[62,]    1
[63,]    1
[64,]    1

[[1]]$tau
[1] 0.7077025

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -17961.7
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181941-1-506814.csv\n"
init_taus from clustering  0.511233335657284 init_taus from clustering  0.786417663842766Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.009311 seconds 
1000 transitions using 10 leapfrog steps per transition would take 93.11 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -18113.456             1.000            1.000 
     2       -18063.551             0.501            1.000 
     3       -18045.815             0.335            0.003 
     4       -18042.769             0.251            0.003 
     5       -18024.899             0.201            0.001 
     6       -18016.172             0.168            0.001 
     7       -18008.227             0.144            0.001 
     8       -18012.207             0.126            0.001 
     9       -18002.946             0.112            0.001 
    10       -18001.766             0.101            0.001 
    11       -18004.703             0.092            0.000 
    12       -17995.329             0.084            0.001 
    13       -17994.159             0.077            0.000 
    14       -17996.948             0.072            0.000 
    15       -17992.350             0.067            0.000 
    16       -17991.326             0.063            0.000 
    17       -17989.586             0.059            0.000 
    18       -17988.444             0.056            0.000 
    19       -17983.964             0.053            0.000 
    20       -17983.997             0.050            0.000 
    21       -17983.961             0.000            0.000 
    22       -17979.117             0.000            0.000 
    23       -17979.292             0.000            0.000 
    24       -17975.860             0.000            0.000 
    25       -17976.846             0.000            0.000 
    26       -17979.263             0.000            0.000 
    27       -17975.221             0.000            0.000 
    28       -17974.533             0.000            0.000 
    29       -17975.109             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  70.0 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]
 [1,] 0.0284841977 0.9715158023
 [2,] 0.0218638221 0.9781361779
 [3,] 0.0167637019 0.9832362981
 [4,] 0.0001710733 0.9998289267
 [5,] 0.1119939537 0.8880060463
 [6,] 0.0130899910 0.9869100090
 [7,] 0.0001372187 0.9998627813
 [8,] 0.0023144310 0.9976855690
 [9,] 0.0619453936 0.9380546064
[10,] 0.0686716230 0.9313283770
[11,] 0.0449418543 0.9550581457
[12,] 0.0167295234 0.9832704766
[13,] 0.2070098790 0.7929901210
[14,] 0.0854289827 0.9145710173
[15,] 0.8148258457 0.1851741543
[16,] 0.0033938743 0.9966061257
[17,] 0.0370406842 0.9629593158
[18,] 0.0035393893 0.9964606107
[19,] 0.0045017660 0.9954982340
[20,] 0.0697129535 0.9302870465
[21,] 0.0045017660 0.9954982340
[22,] 0.0038362997 0.9961637003
[23,] 0.9889097355 0.0110902645
[24,] 0.0001115283 0.9998884717
[25,] 0.0603746291 0.9396253709
[26,] 0.8756804616 0.1243195384
[27,] 0.9983840809 0.0016159191
[28,] 0.9815577188 0.0184422812
[29,] 0.0023144310 0.9976855690
[30,] 0.0402331290 0.9597668710
[31,] 0.7291170950 0.2708829050
[32,] 0.0276555701 0.9723444299
[33,] 0.0402331290 0.9597668710
[34,] 0.9270424965 0.0729575035
[35,] 0.3721955571 0.6278044429
[36,] 0.0402331290 0.9597668710
[37,] 0.0697129535 0.9302870465
[38,] 0.9995833826 0.0004166174
[39,] 0.0001065073 0.9998934927
[40,] 0.7029537515 0.2970462485
[41,] 0.0007278910 0.9992721090
[42,] 0.0227862295 0.9772137705
[43,] 0.0869080259 0.9130919741
[44,] 0.1119939537 0.8880060463
[45,] 0.0185951113 0.9814048887
[46,] 0.9986751464 0.0013248536
[47,] 0.9983840809 0.0016159191
[48,] 0.9761711398 0.0238288602
[49,] 0.0001679486 0.9998320514
[50,] 0.0992730243 0.9007269757
[51,] 0.9443979155 0.0556020845
[52,] 0.0045017660 0.9954982340
[53,] 0.0161313564 0.9838686436
[54,] 0.0060740794 0.9939259206
[55,] 0.0282225857 0.9717774143
[56,] 0.1007581525 0.8992418475
[57,] 0.0869080259 0.9130919741
[58,] 0.0112218193 0.9887781807
[59,] 0.0020379294 0.9979620706
[60,] 0.4495659014 0.5504340986
[61,] 0.0045017660 0.9954982340
[62,] 0.3721955571 0.6278044429
[63,] 0.0109572995 0.9890427005
[64,] 0.0402331290 0.9597668710

[[1]]$tau
[1] 0.5112333 0.7864177

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -18045.8
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.010212 seconds 
1000 transitions using 10 leapfrog steps per transition would take 102.12 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -18222.645             1.000            1.000 
     2       -18080.910             0.504            1.000 
     3       -18053.008             0.336            0.008 
     4       -18031.062             0.253            0.008 
     5       -18027.709             0.202            0.002 
     6       -18023.293             0.169            0.002 
     7       -18018.315             0.144            0.001 
     8       -18014.215             0.126            0.001 
     9       -18002.639             0.112            0.001 
    10       -18004.385             0.101            0.001 
    11       -18005.476             0.092            0.000 
    12       -17992.417             0.084            0.001 
    13       -17994.664             0.078            0.000 
    14       -17993.131             0.072            0.000 
    15       -17988.633             0.068            0.000 
    16       -17988.674             0.063            0.000 
    17       -17986.759             0.060            0.000 
    18       -17986.424             0.056            0.000 
    19       -17984.167             0.053            0.000 
    20       -17982.048             0.051            0.000 
    21       -17979.769             0.001            0.000 
    22       -17978.639             0.000            0.000 
    23       -17977.502             0.000            0.000 
    24       -17975.975             0.000            0.000 
    25       -17973.316             0.000            0.000 
    26       -17972.775             0.000            0.000 
    27       -17972.574             0.000            0.000 
    28       -17969.146             0.000            0.000 
    29       -17969.570             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  69.8 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]
 [1,] 0.0284841977 0.9715158023
 [2,] 0.0218638221 0.9781361779
 [3,] 0.0167637019 0.9832362981
 [4,] 0.0001710733 0.9998289267
 [5,] 0.1119939537 0.8880060463
 [6,] 0.0130899910 0.9869100090
 [7,] 0.0001372187 0.9998627813
 [8,] 0.0023144310 0.9976855690
 [9,] 0.0619453936 0.9380546064
[10,] 0.0686716230 0.9313283770
[11,] 0.0449418543 0.9550581457
[12,] 0.0167295234 0.9832704766
[13,] 0.2070098790 0.7929901210
[14,] 0.0854289827 0.9145710173
[15,] 0.8148258457 0.1851741543
[16,] 0.0033938743 0.9966061257
[17,] 0.0370406842 0.9629593158
[18,] 0.0035393893 0.9964606107
[19,] 0.0045017660 0.9954982340
[20,] 0.0697129535 0.9302870465
[21,] 0.0045017660 0.9954982340
[22,] 0.0038362997 0.9961637003
[23,] 0.9889097355 0.0110902645
[24,] 0.0001115283 0.9998884717
[25,] 0.0603746291 0.9396253709
[26,] 0.8756804616 0.1243195384
[27,] 0.9983840809 0.0016159191
[28,] 0.9815577188 0.0184422812
[29,] 0.0023144310 0.9976855690
[30,] 0.0402331290 0.9597668710
[31,] 0.7291170950 0.2708829050
[32,] 0.0276555701 0.9723444299
[33,] 0.0402331290 0.9597668710
[34,] 0.9270424965 0.0729575035
[35,] 0.3721955571 0.6278044429
[36,] 0.0402331290 0.9597668710
[37,] 0.0697129535 0.9302870465
[38,] 0.9995833826 0.0004166174
[39,] 0.0001065073 0.9998934927
[40,] 0.7029537515 0.2970462485
[41,] 0.0007278910 0.9992721090
[42,] 0.0227862295 0.9772137705
[43,] 0.0869080259 0.9130919741
[44,] 0.1119939537 0.8880060463
[45,] 0.0185951113 0.9814048887
[46,] 0.9986751464 0.0013248536
[47,] 0.9983840809 0.0016159191
[48,] 0.9761711398 0.0238288602
[49,] 0.0001679486 0.9998320514
[50,] 0.0992730243 0.9007269757
[51,] 0.9443979155 0.0556020845
[52,] 0.0045017660 0.9954982340
[53,] 0.0161313564 0.9838686436
[54,] 0.0060740794 0.9939259206
[55,] 0.0282225857 0.9717774143
[56,] 0.1007581525 0.8992418475
[57,] 0.0869080259 0.9130919741
[58,] 0.0112218193 0.9887781807
[59,] 0.0020379294 0.9979620706
[60,] 0.4495659014 0.5504340986
[61,] 0.0045017660 0.9954982340
[62,] 0.3721955571 0.6278044429
[63,] 0.0109572995 0.9890427005
[64,] 0.0402331290 0.9597668710

[[1]]$tau
[1] 0.5356596 0.8676906

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -18053
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181942-1-bb6a47.csv\n"
init_taus from clustering  0.732296744241712 init_taus from clustering  0.500354588151606 init_taus from clustering  0.834451851228285Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.013432 seconds 
1000 transitions using 10 leapfrog steps per transition would take 134.32 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -18201.932             1.000            1.000 
     2       -18115.800             0.502            1.000 
     3       -18093.533             0.335            0.005 
     4       -18063.013             0.252            0.005 
     5       -18061.167             0.202            0.002 
     6       -18044.423             0.168            0.002 
     7       -18030.904             0.144            0.001 
     8       -18029.888             0.126            0.001 
     9       -18024.112             0.112            0.001 
    10       -18026.091             0.101            0.001 
    11       -18011.956             0.092            0.001 
    12       -18012.175             0.084            0.001 
    13       -18008.406             0.078            0.001 
    14       -18006.375             0.072            0.001 
    15       -18001.502             0.067            0.000 
    16       -17997.197             0.063            0.000 
    17       -17996.885             0.060            0.000 
    18       -17998.821             0.056            0.000 
    19       -17990.160             0.053            0.000 
    20       -17993.218             0.051            0.000 
    21       -17990.974             0.001            0.000 
    22       -17990.388             0.000            0.000 
    23       -17988.251             0.000            0.000 
    24       -17986.586             0.000            0.000 
    25       -17986.277             0.000            0.000 
    26       -17983.209             0.000            0.000 
    27       -17984.504             0.000            0.000 
    28       -17981.073             0.000            0.000 
    29       -17982.361             0.000            0.000 
    30       -17979.243             0.000            0.000 
    31       -17975.902             0.000            0.000 
    32       -17980.738             0.000            0.000 
    33       -17977.510             0.000            0.000 
    34       -17976.232             0.000            0.000 
    35       -17977.711             0.000            0.000 
    36       -17977.371             0.000            0.000 
    37       -17975.225             0.000            0.000 
    38       -17973.914             0.000            0.000 
    39       -17973.352             0.000            0.000 
    40       -17974.908             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  75.8 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]
 [1,] 0.0062203217 0.0007400465 0.9930396318
 [2,] 0.0001043016 0.0001003762 0.9997953223
 [3,] 0.0052282761 0.0005349645 0.9942367594
 [4,] 0.3898258866 0.0150368311 0.5951372823
 [5,] 0.9712065369 0.0069528602 0.0218406028
 [6,] 0.8893818614 0.0090092325 0.1016089061
 [7,] 0.4655844080 0.0159336928 0.5184818992
 [8,] 0.2032479439 0.0104765586 0.7862754975
 [9,] 0.9993095090 0.0001836845 0.0005068065
[10,] 0.1060601296 0.0173132920 0.8766265784
[11,] 0.9965739520 0.0005630380 0.0028630100
[12,] 0.9196775262 0.0072620814 0.0730603924
[13,] 0.8952588809 0.0365016285 0.0682394907
[14,] 0.9894217933 0.0022232804 0.0083549263
[15,] 0.3249365515 0.5715693965 0.1034940520
[16,] 0.7104710673 0.0149218372 0.2746070955
[17,] 0.9890651283 0.0014942139 0.0094406578
[18,] 0.1564452746 0.0087430359 0.8348116895
[19,] 0.7459493076 0.0141920664 0.2398586260
[20,] 0.9971561613 0.0005818395 0.0022619993
[21,] 0.7459493076 0.0141920664 0.2398586260
[22,] 0.1471747549 0.0083661811 0.8444590640
[23,] 0.0072481703 0.9890203376 0.0037314921
[24,] 0.4160204150 0.0154074676 0.5685721174
[25,] 0.9995506200 0.0001419395 0.0003074406
[26,] 0.2377004653 0.6800608570 0.0822386777
[27,] 0.0001014192 0.9997979118 0.0001006690
[28,] 0.0508685315 0.9277207724 0.0214106961
[29,] 0.2032479439 0.0104765586 0.7862754975
[30,] 0.0319792218 0.0040039795 0.9640167987
[31,] 0.4317884048 0.4452121140 0.1229994812
[32,] 0.0049517804 0.0006009902 0.9944472294
[33,] 0.0319792218 0.0040039795 0.9640167987
[34,] 0.1542749871 0.7879699770 0.0577550358
[35,] 0.7642170655 0.1188675157 0.1169154188
[36,] 0.0319792218 0.0040039795 0.9640167987
[37,] 0.9971561613 0.0005818395 0.0022619993
[38,] 0.0007784738 0.9987996934 0.0004218328
[39,] 0.4204202217 0.0154634526 0.5641163257
[40,] 0.2556059202 0.5475310276 0.1968630522
[41,] 0.5624711682 0.0162871894 0.4212416424
[42,] 0.9529430752 0.0049072954 0.0421496294
[43,] 0.1471846449 0.0276197186 0.8251956365
[44,] 0.9712065369 0.0069528602 0.0218406028
[45,] 0.0019737664 0.0002650708 0.9977611628
[46,] 0.0001148404 0.9997780394 0.0001071201
[47,] 0.0001014192 0.9997979118 0.0001006690
[48,] 0.0621914371 0.9120418278 0.0257667351
[49,] 0.4767216258 0.0160202492 0.5072581250
[50,] 0.1713635917 0.0349852273 0.7936511810
[51,] 0.0568864217 0.9109331713 0.0321804071
[52,] 0.7459493076 0.0141920664 0.2398586260
[53,] 0.0068159309 0.0006618481 0.9925222211
[54,] 0.0936772154 0.0059412509 0.9003815336
[55,] 0.9716446443 0.0032957016 0.0250596542
[56,] 0.9793949835 0.0046948809 0.0159101356
[57,] 0.1471846449 0.0276197186 0.8251956365
[58,] 0.8692001934 0.0100129244 0.1207868822
[59,] 0.6527431557 0.0157548280 0.3315020162
[60,] 0.7012913155 0.1700174622 0.1286912223
[61,] 0.7459493076 0.0141920664 0.2398586260
[62,] 0.7642170655 0.1188675157 0.1169154188
[63,] 0.0325257353 0.0024856465 0.9649886182
[64,] 0.0319792218 0.0040039795 0.9640167987

[[1]]$tau
[1] 0.7322967 0.5003546 0.8344519

[[1]]$phi
[1] 0.3333333 0.3333333 0.3333333

[[1]]$kappa
[1] 5


ELBO for this run: -18093.5
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.014418 seconds 
1000 transitions using 10 leapfrog steps per transition would take 144.18 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -18225.109             1.000            1.000 
     2       -18168.598             0.502            1.000 
     3       -18133.289             0.335            0.003 
     4       -18107.697             0.252            0.003 
     5       -18089.176             0.201            0.002 
     6       -18090.624             0.168            0.002 
     7       -18069.537             0.144            0.001 
     8       -18055.601             0.126            0.001 
     9       -18056.215             0.112            0.001 
    10       -18051.572             0.101            0.001 
    11       -18041.278             0.092            0.001 
    12       -18039.022             0.084            0.001 
    13       -18041.483             0.078            0.001 
    14       -18039.164             0.072            0.001 
    15       -18028.864             0.067            0.001 
    16       -18029.586             0.063            0.001 
    17       -18021.807             0.060            0.001 
    18       -18019.449             0.056            0.001 
    19       -18020.883             0.053            0.000 
    20       -18015.616             0.051            0.000 
    21       -18011.311             0.001            0.000 
    22       -18010.662             0.000            0.000 
    23       -18006.117             0.000            0.000 
    24       -18008.813             0.000            0.000 
    25       -18008.433             0.000            0.000 
    26       -18003.949             0.000            0.000 
    27       -18002.793             0.000            0.000 
    28       -17996.638             0.000            0.000 
    29       -18000.297             0.000            0.000 
    30       -17997.186             0.000            0.000 
    31       -17997.942             0.000            0.000 
    32       -17994.142             0.000            0.000 
    33       -17993.400             0.000            0.000 
    34       -17992.197             0.000            0.000 
    35       -17990.940             0.000            0.000 
    36       -17988.506             0.000            0.000 
    37       -17992.541             0.000            0.000 
    38       -17988.452             0.000            0.000 
    39       -17987.073             0.000            0.000 
    40       -17986.270             0.000            0.000 
    41       -17985.800             0.000            0.000 
    42       -17986.264             0.000            0.000 
    43       -17983.806             0.000            0.000 
    44       -17979.515             0.000            0.000 
    45       -17981.061             0.000            0.000 
    46       -17983.427             0.000            0.000 
    47       -17980.795             0.000            0.000 
    48       -17980.910             0.000            0.000 
    49       -17976.745             0.000            0.000 
    50       -17974.861             0.000            0.000 
    51       -17978.577             0.000            0.000 
    52       -17978.964             0.000            0.000 
    53       -17976.848             0.000            0.000 
    54       -17975.034             0.000            0.000 
    55       -17976.691             0.000            0.000 
    56       -17973.852             0.000            0.000 
    57       -17974.790             0.000            0.000 
    58       -17976.498             0.000            0.000 
    59       -17974.606             0.000            0.000 
    60       -17970.985             0.000            0.000 
    61       -17972.230             0.000            0.000 
    62       -17972.282             0.000            0.000 
    63       -17971.970             0.000            0.000 
    64       -17970.808             0.000            0.000 
    65       -17971.720             0.000            0.000   MEAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  88.0 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]
 [1,] 0.0062203217 0.0007400465 0.9930396318
 [2,] 0.0001043016 0.0001003762 0.9997953223
 [3,] 0.0052282761 0.0005349645 0.9942367594
 [4,] 0.3898258866 0.0150368311 0.5951372823
 [5,] 0.9712065369 0.0069528602 0.0218406028
 [6,] 0.8893818614 0.0090092325 0.1016089061
 [7,] 0.4655844080 0.0159336928 0.5184818992
 [8,] 0.2032479439 0.0104765586 0.7862754975
 [9,] 0.9993095090 0.0001836845 0.0005068065
[10,] 0.1060601296 0.0173132920 0.8766265784
[11,] 0.9965739520 0.0005630380 0.0028630100
[12,] 0.9196775262 0.0072620814 0.0730603924
[13,] 0.8952588809 0.0365016285 0.0682394907
[14,] 0.9894217933 0.0022232804 0.0083549263
[15,] 0.3249365515 0.5715693965 0.1034940520
[16,] 0.7104710673 0.0149218372 0.2746070955
[17,] 0.9890651283 0.0014942139 0.0094406578
[18,] 0.1564452746 0.0087430359 0.8348116895
[19,] 0.7459493076 0.0141920664 0.2398586260
[20,] 0.9971561613 0.0005818395 0.0022619993
[21,] 0.7459493076 0.0141920664 0.2398586260
[22,] 0.1471747549 0.0083661811 0.8444590640
[23,] 0.0072481703 0.9890203376 0.0037314921
[24,] 0.4160204150 0.0154074676 0.5685721174
[25,] 0.9995506200 0.0001419395 0.0003074406
[26,] 0.2377004653 0.6800608570 0.0822386777
[27,] 0.0001014192 0.9997979118 0.0001006690
[28,] 0.0508685315 0.9277207724 0.0214106961
[29,] 0.2032479439 0.0104765586 0.7862754975
[30,] 0.0319792218 0.0040039795 0.9640167987
[31,] 0.4317884048 0.4452121140 0.1229994812
[32,] 0.0049517804 0.0006009902 0.9944472294
[33,] 0.0319792218 0.0040039795 0.9640167987
[34,] 0.1542749871 0.7879699770 0.0577550358
[35,] 0.7642170655 0.1188675157 0.1169154188
[36,] 0.0319792218 0.0040039795 0.9640167987
[37,] 0.9971561613 0.0005818395 0.0022619993
[38,] 0.0007784738 0.9987996934 0.0004218328
[39,] 0.4204202217 0.0154634526 0.5641163257
[40,] 0.2556059202 0.5475310276 0.1968630522
[41,] 0.5624711682 0.0162871894 0.4212416424
[42,] 0.9529430752 0.0049072954 0.0421496294
[43,] 0.1471846449 0.0276197186 0.8251956365
[44,] 0.9712065369 0.0069528602 0.0218406028
[45,] 0.0019737664 0.0002650708 0.9977611628
[46,] 0.0001148404 0.9997780394 0.0001071201
[47,] 0.0001014192 0.9997979118 0.0001006690
[48,] 0.0621914371 0.9120418278 0.0257667351
[49,] 0.4767216258 0.0160202492 0.5072581250
[50,] 0.1713635917 0.0349852273 0.7936511810
[51,] 0.0568864217 0.9109331713 0.0321804071
[52,] 0.7459493076 0.0141920664 0.2398586260
[53,] 0.0068159309 0.0006618481 0.9925222211
[54,] 0.0936772154 0.0059412509 0.9003815336
[55,] 0.9716446443 0.0032957016 0.0250596542
[56,] 0.9793949835 0.0046948809 0.0159101356
[57,] 0.1471846449 0.0276197186 0.8251956365
[58,] 0.8692001934 0.0100129244 0.1207868822
[59,] 0.6527431557 0.0157548280 0.3315020162
[60,] 0.7012913155 0.1700174622 0.1286912223
[61,] 0.7459493076 0.0141920664 0.2398586260
[62,] 0.7642170655 0.1188675157 0.1169154188
[63,] 0.0325257353 0.0024856465 0.9649886182
[64,] 0.0319792218 0.0040039795 0.9640167987

[[1]]$tau
[1] 0.5702737 0.7801948 0.6170965

[[1]]$phi
[1] 0.3333333 0.3333333 0.3333333

[[1]]$kappa
[1] 5


ELBO for this run: -18133.3
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181944-1-cde95f.csv\n"
init_taus from clustering  0.844673781368257 init_taus from clustering  0.00184499796532296 init_taus from clustering  0.527566005656094 init_taus from clustering  0.744307093781621Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.017302 seconds 
1000 transitions using 10 leapfrog steps per transition would take 173.02 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -18254.987             1.000            1.000 
     2       -18145.578             0.503            1.000 
     3       -18194.381             0.336            0.006 
     4       -18136.711             0.253            0.006 
     5       -18098.637             0.203            0.003 
     6       -18107.881             0.169            0.003 
     7       -18095.146             0.145            0.003 
     8       -18079.834             0.127            0.003 
     9       -18076.226             0.113            0.002 
    10       -18066.460             0.102            0.002 
    11       -18067.990             0.092            0.001 
    12       -18056.998             0.085            0.001 
    13       -18057.442             0.078            0.001 
    14       -18056.229             0.073            0.001 
    15       -18050.344             0.068            0.001 
    16       -18051.520             0.064            0.001 
    17       -18045.494             0.060            0.001 
    18       -18046.263             0.057            0.001 
    19       -18042.042             0.054            0.001 
    20       -18037.578             0.051            0.001 
    21       -18041.134             0.001            0.000 
    22       -18033.683             0.001            0.000 
    23       -18036.303             0.001            0.000 
    24       -18032.648             0.000            0.000 
    25       -18030.566             0.000            0.000 
    26       -18033.378             0.000            0.000 
    27       -18030.870             0.000            0.000 
    28       -18028.011             0.000            0.000 
    29       -18021.895             0.000            0.000 
    30       -18018.706             0.000            0.000 
    31       -18020.864             0.000            0.000 
    32       -18020.578             0.000            0.000 
    33       -18015.816             0.000            0.000 
    34       -18013.388             0.000            0.000 
    35       -18011.120             0.000            0.000 
    36       -18010.549             0.000            0.000 
    37       -18008.813             0.000            0.000 
    38       -18007.649             0.000            0.000 
    39       -18001.522             0.000            0.000 
    40       -18002.379             0.000            0.000 
    41       -18000.411             0.000            0.000 
    42       -17999.157             0.000            0.000 
    43       -17997.785             0.000            0.000 
    44       -17995.115             0.000            0.000 
    45       -17993.825             0.000            0.000 
    46       -17993.096             0.000            0.000 
    47       -17991.773             0.000            0.000 
    48       -17992.746             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  58.3 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]
 [1,] 0.9994379364 0.0001032151 0.0001230929 0.0003357556
 [2,] 0.9864082279 0.0002424152 0.0011476286 0.0122017283
 [3,] 0.9560663276 0.0005083417 0.0031932165 0.0402321142
 [4,] 0.3797070212 0.0020166415 0.0174973340 0.6007790033
 [5,] 0.0490534388 0.0017385575 0.0239485864 0.9252594172
 [6,] 0.0247285181 0.0004227619 0.0035738566 0.9712748633
 [7,] 0.3071170083 0.0018986985 0.0167686690 0.6742156242
 [8,] 0.5978836780 0.0019705655 0.0161539764 0.3839917800
 [9,] 0.0149896450 0.0004678118 0.0048528326 0.9796897105
[10,] 0.8998090287 0.0023365359 0.0135791977 0.0842752377
[11,] 0.0042144833 0.0001874609 0.0011751140 0.9944229418
[12,] 0.0133643956 0.0002891875 0.0021782964 0.9841681205
[13,] 0.0934801851 0.0045700362 0.0778547548 0.8240950239
[14,] 0.0316034970 0.0010136213 0.0126314873 0.9547513944
[15,] 0.0648822120 0.0109323262 0.7377936593 0.1863918025
[16,] 0.1194987532 0.0011806026 0.0108605250 0.8684601191
[17,] 0.0009204050 0.0001159782 0.0002916319 0.9986719850
[18,] 0.6643550436 0.0018437479 0.0148116427 0.3189895658
[19,] 0.0977001101 0.0010425045 0.0096023482 0.8916550372
[20,] 0.0204844803 0.0006334887 0.0071379942 0.9717440368
[21,] 0.0977001101 0.0010425045 0.0096023482 0.8916550372
[22,] 0.6782769444 0.0018103295 0.0144766825 0.3054360436
[23,] 0.0168206104 0.0099389299 0.9413888787 0.0318515810
[24,] 0.3537196680 0.0019827808 0.0173134307 0.6269841205
[25,] 0.0138978326 0.0004366485 0.0044313418 0.9812341772
[26,] 0.0434799385 0.0085565426 0.8317419004 0.1162216185
[27,] 0.0063243387 0.0030775423 0.9781068266 0.0124912924
[28,] 0.0031794352 0.0010439007 0.9887304365 0.0070462276
[29,] 0.5978836780 0.0019705655 0.0161539764 0.3839917800
[30,] 0.9860076398 0.0003100425 0.0015147266 0.0121675911
[31,] 0.0900779558 0.0126585548 0.6124532312 0.2848102581
[32,] 0.9989463182 0.0001091606 0.0001656138 0.0007789074
[33,] 0.9860076398 0.0003100425 0.0015147266 0.0121675911
[34,] 0.0236693194 0.0055205932 0.9118143964 0.0589956910
[35,] 0.1255622279 0.0090887783 0.2053272715 0.6600217223
[36,] 0.9860076398 0.0003100425 0.0015147266 0.0121675911
[37,] 0.0204844803 0.0006334887 0.0071379942 0.9717440368
[38,] 0.0040129124 0.0018614579 0.9861177842 0.0080078455
[39,] 0.3494492751 0.0019763454 0.0172752607 0.6312991187
[40,] 0.0001037531 0.9996817152 0.0001096863 0.0001048454
[41,] 0.2248763480 0.0016688948 0.0150336642 0.7584210930
[42,] 0.0037406066 0.0001582148 0.0007588713 0.9953423073
[43,] 0.8426462490 0.0043488027 0.0241248733 0.1288800750
[44,] 0.0490534388 0.0017385575 0.0239485864 0.9252594172
[45,] 0.9696952340 0.0003956249 0.0023150012 0.0275941399
[46,] 0.0058540321 0.0028210854 0.9797377021 0.0115871805
[47,] 0.0063243387 0.0030775423 0.9781068266 0.0124912924
[48,] 0.0049334744 0.0015209726 0.9823926658 0.0111528872
[49,] 0.2970851884 0.0018764738 0.0166128287 0.6844255091
[50,] 0.8069356708 0.0059451420 0.0318108670 0.1553083201
[51,] 0.0500178164 0.0500611912 0.8138253652 0.0860956272
[52,] 0.0977001101 0.0010425045 0.0096023482 0.8916550372
[53,] 0.9505039072 0.0005518924 0.0035364986 0.0454077017
[54,] 0.7647152344 0.0015461678 0.0119656880 0.2217729097
[55,] 0.0005568876 0.0001079187 0.0001920862 0.9991431074
[56,] 0.0419399722 0.0014229672 0.0188934601 0.9377436006
[57,] 0.8426462490 0.0043488027 0.0241248733 0.1288800750
[58,] 0.0332785698 0.0005134840 0.0044988218 0.9617091245
[59,] 0.1578219756 0.0013887445 0.0126969477 0.8280923322
[60,] 0.1281422982 0.0107830326 0.2779899032 0.5830847660
[61,] 0.0977001101 0.0010425045 0.0096023482 0.8916550372
[62,] 0.1255622279 0.0090887783 0.2053272715 0.6600217223
[63,] 0.8832436795 0.0009981307 0.0071729812 0.1085852085
[64,] 0.9860076398 0.0003100425 0.0015147266 0.0121675911

[[1]]$tau
[1] 0.844673781 0.001844998 0.527566006 0.744307094

[[1]]$phi
[1] 0.25 0.25 0.25 0.25

[[1]]$kappa
[1] 5


ELBO for this run: -18194.4
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.017197 seconds 
1000 transitions using 10 leapfrog steps per transition would take 171.97 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -18358.013             1.000            1.000 
     2       -18179.182             0.505            1.000 
     3       -18156.550             0.337            0.010 
     4       -18132.812             0.253            0.010 
     5       -18116.104             0.203            0.001 
     6       -18115.380             0.169            0.001 
     7       -18106.879             0.145            0.001 
     8       -18098.501             0.127            0.001 
     9       -18090.324             0.113            0.001 
    10       -18091.878             0.101            0.001 
    11       -18076.729             0.092            0.001 
    12       -18074.027             0.085            0.001 
    13       -18064.881             0.078            0.001 
    14       -18068.014             0.073            0.001 
    15       -18060.060             0.068            0.000 
    16       -18058.484             0.064            0.000 
    17       -18048.936             0.060            0.000 
    18       -18048.668             0.057            0.000 
    19       -18043.991             0.054            0.000 
    20       -18044.965             0.051            0.000 
    21       -18044.730             0.001            0.000 
    22       -18037.999             0.000            0.000 
    23       -18034.942             0.000            0.000 
    24       -18038.104             0.000            0.000 
    25       -18032.768             0.000            0.000 
    26       -18032.198             0.000            0.000 
    27       -18026.566             0.000            0.000 
    28       -18026.662             0.000            0.000 
    29       -18020.647             0.000            0.000 
    30       -18019.045             0.000            0.000 
    31       -18016.124             0.000            0.000 
    32       -18021.355             0.000            0.000 
    33       -18013.283             0.000            0.000 
    34       -18012.868             0.000            0.000 
    35       -18014.343             0.000            0.000 
    36       -18010.571             0.000            0.000 
    37       -18007.692             0.000            0.000 
    38       -18006.822             0.000            0.000 
    39       -18004.157             0.000            0.000 
    40       -18005.291             0.000            0.000 
    41       -18004.852             0.000            0.000 
    42       -18002.340             0.000            0.000 
    43       -18003.962             0.000            0.000 
    44       -18001.620             0.000            0.000 
    45       -17996.242             0.000            0.000 
    46       -17994.638             0.000            0.000 
    47       -17994.408             0.000            0.000 
    48       -17999.571             0.000            0.000 
    49       -17992.577             0.000            0.000 
    50       -17996.253             0.000            0.000 
    51       -17989.876             0.000            0.000 
    52       -17991.835             0.000            0.000 
    53       -17993.096             0.000            0.000 
    54       -17991.869             0.000            0.000 
    55       -17988.945             0.000            0.000 
    56       -17991.189             0.000            0.000 
    57       -17989.919             0.000            0.000 
    58       -17989.267             0.000            0.000 
    59       -17985.064             0.000            0.000 
    60       -17986.471             0.000            0.000 
    61       -17987.857             0.000            0.000 
    62       -17985.097             0.000            0.000 
    63       -17984.236             0.000            0.000 
    64       -17986.178             0.000            0.000 
    65       -17985.216             0.000            0.000 
    66       -17983.791             0.000            0.000 
    67       -17981.267             0.000            0.000 
    68       -17980.009             0.000            0.000 
    69       -17981.038             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  118.0 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]
 [1,] 0.9994379364 0.0001032151 0.0001230929 0.0003357556
 [2,] 0.9864082279 0.0002424152 0.0011476286 0.0122017283
 [3,] 0.9560663276 0.0005083417 0.0031932165 0.0402321142
 [4,] 0.3797070212 0.0020166415 0.0174973340 0.6007790033
 [5,] 0.0490534388 0.0017385575 0.0239485864 0.9252594172
 [6,] 0.0247285181 0.0004227619 0.0035738566 0.9712748633
 [7,] 0.3071170083 0.0018986985 0.0167686690 0.6742156242
 [8,] 0.5978836780 0.0019705655 0.0161539764 0.3839917800
 [9,] 0.0149896450 0.0004678118 0.0048528326 0.9796897105
[10,] 0.8998090287 0.0023365359 0.0135791977 0.0842752377
[11,] 0.0042144833 0.0001874609 0.0011751140 0.9944229418
[12,] 0.0133643956 0.0002891875 0.0021782964 0.9841681205
[13,] 0.0934801851 0.0045700362 0.0778547548 0.8240950239
[14,] 0.0316034970 0.0010136213 0.0126314873 0.9547513944
[15,] 0.0648822120 0.0109323262 0.7377936593 0.1863918025
[16,] 0.1194987532 0.0011806026 0.0108605250 0.8684601191
[17,] 0.0009204050 0.0001159782 0.0002916319 0.9986719850
[18,] 0.6643550436 0.0018437479 0.0148116427 0.3189895658
[19,] 0.0977001101 0.0010425045 0.0096023482 0.8916550372
[20,] 0.0204844803 0.0006334887 0.0071379942 0.9717440368
[21,] 0.0977001101 0.0010425045 0.0096023482 0.8916550372
[22,] 0.6782769444 0.0018103295 0.0144766825 0.3054360436
[23,] 0.0168206104 0.0099389299 0.9413888787 0.0318515810
[24,] 0.3537196680 0.0019827808 0.0173134307 0.6269841205
[25,] 0.0138978326 0.0004366485 0.0044313418 0.9812341772
[26,] 0.0434799385 0.0085565426 0.8317419004 0.1162216185
[27,] 0.0063243387 0.0030775423 0.9781068266 0.0124912924
[28,] 0.0031794352 0.0010439007 0.9887304365 0.0070462276
[29,] 0.5978836780 0.0019705655 0.0161539764 0.3839917800
[30,] 0.9860076398 0.0003100425 0.0015147266 0.0121675911
[31,] 0.0900779558 0.0126585548 0.6124532312 0.2848102581
[32,] 0.9989463182 0.0001091606 0.0001656138 0.0007789074
[33,] 0.9860076398 0.0003100425 0.0015147266 0.0121675911
[34,] 0.0236693194 0.0055205932 0.9118143964 0.0589956910
[35,] 0.1255622279 0.0090887783 0.2053272715 0.6600217223
[36,] 0.9860076398 0.0003100425 0.0015147266 0.0121675911
[37,] 0.0204844803 0.0006334887 0.0071379942 0.9717440368
[38,] 0.0040129124 0.0018614579 0.9861177842 0.0080078455
[39,] 0.3494492751 0.0019763454 0.0172752607 0.6312991187
[40,] 0.0001037531 0.9996817152 0.0001096863 0.0001048454
[41,] 0.2248763480 0.0016688948 0.0150336642 0.7584210930
[42,] 0.0037406066 0.0001582148 0.0007588713 0.9953423073
[43,] 0.8426462490 0.0043488027 0.0241248733 0.1288800750
[44,] 0.0490534388 0.0017385575 0.0239485864 0.9252594172
[45,] 0.9696952340 0.0003956249 0.0023150012 0.0275941399
[46,] 0.0058540321 0.0028210854 0.9797377021 0.0115871805
[47,] 0.0063243387 0.0030775423 0.9781068266 0.0124912924
[48,] 0.0049334744 0.0015209726 0.9823926658 0.0111528872
[49,] 0.2970851884 0.0018764738 0.0166128287 0.6844255091
[50,] 0.8069356708 0.0059451420 0.0318108670 0.1553083201
[51,] 0.0500178164 0.0500611912 0.8138253652 0.0860956272
[52,] 0.0977001101 0.0010425045 0.0096023482 0.8916550372
[53,] 0.9505039072 0.0005518924 0.0035364986 0.0454077017
[54,] 0.7647152344 0.0015461678 0.0119656880 0.2217729097
[55,] 0.0005568876 0.0001079187 0.0001920862 0.9991431074
[56,] 0.0419399722 0.0014229672 0.0188934601 0.9377436006
[57,] 0.8426462490 0.0043488027 0.0241248733 0.1288800750
[58,] 0.0332785698 0.0005134840 0.0044988218 0.9617091245
[59,] 0.1578219756 0.0013887445 0.0126969477 0.8280923322
[60,] 0.1281422982 0.0107830326 0.2779899032 0.5830847660
[61,] 0.0977001101 0.0010425045 0.0096023482 0.8916550372
[62,] 0.1255622279 0.0090887783 0.2053272715 0.6600217223
[63,] 0.8832436795 0.0009981307 0.0071729812 0.1085852085
[64,] 0.9860076398 0.0003100425 0.0015147266 0.0121675911

[[1]]$tau
[1] 0.63436799 0.01924493 0.79913711 0.67114389

[[1]]$phi
[1] 0.25 0.25 0.25 0.25

[[1]]$kappa
[1] 5


ELBO for this run: -18156.5
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181948-1-3f8bdf.csv\n"
init_taus from clustering  0.77986632779586 init_taus from clustering  0.708868328663406 init_taus from clustering  0.517858822931635 init_taus from clustering  0.00113696184147498 init_taus from clustering  0.861823349804041Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.020695 seconds 
1000 transitions using 10 leapfrog steps per transition would take 206.95 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -18399.092             1.000            1.000 
     2       -18219.448             0.505            1.000 
     3       -18179.208             0.337            0.010 
     4       -18149.445             0.253            0.010 
     5       -18136.359             0.203            0.002 
     6       -18126.028             0.169            0.002 
     7       -18119.517             0.145            0.002 
     8       -18103.178             0.127            0.002 
     9       -18101.530             0.113            0.001 
    10       -18092.838             0.102            0.001 
    11       -18090.986             0.092            0.001 
    12       -18087.104             0.085            0.001 
    13       -18076.617             0.078            0.001 
    14       -18079.420             0.073            0.001 
    15       -18073.580             0.068            0.001 
    16       -18061.365             0.064            0.001 
    17       -18061.406             0.060            0.001 
    18       -18059.115             0.057            0.001 
    19       -18055.489             0.054            0.000 
    20       -18058.316             0.051            0.000 
    21       -18050.930             0.001            0.000 
    22       -18054.326             0.001            0.000 
    23       -18052.840             0.000            0.000 
    24       -18046.714             0.000            0.000 
    25       -18044.637             0.000            0.000 
    26       -18041.166             0.000            0.000 
    27       -18033.307             0.000            0.000 
    28       -18036.821             0.000            0.000 
    29       -18034.447             0.000            0.000 
    30       -18029.747             0.000            0.000 
    31       -18030.593             0.000            0.000 
    32       -18027.198             0.000            0.000 
    33       -18024.128             0.000            0.000 
    34       -18017.298             0.000            0.000 
    35       -18018.640             0.000            0.000 
    36       -18016.509             0.000            0.000 
    37       -18014.659             0.000            0.000 
    38       -18015.147             0.000            0.000 
    39       -18013.620             0.000            0.000 
    40       -18010.883             0.000            0.000 
    41       -18010.204             0.000            0.000 
    42       -18010.063             0.000            0.000 
    43       -18012.203             0.000            0.000 
    44       -18005.633             0.000            0.000 
    45       -18008.228             0.000            0.000 
    46       -18005.570             0.000            0.000 
    47       -18007.053             0.000            0.000 
    48       -18000.458             0.000            0.000 
    49       -18000.488             0.000            0.000 
    50       -17997.356             0.000            0.000 
    51       -17996.951             0.000            0.000 
    52       -17994.978             0.000            0.000 
    53       -17998.986             0.000            0.000 
    54       -17996.759             0.000            0.000 
    55       -17993.011             0.000            0.000 
    56       -17992.138             0.000            0.000 
    57       -17995.824             0.000            0.000 
    58       -17995.110             0.000            0.000 
    59       -17997.385             0.000            0.000 
    60       -17996.258             0.000            0.000 
    61       -17992.410             0.000            0.000 
    62       -17989.341             0.000            0.000 
    63       -17994.593             0.000            0.000 
    64       -17991.519             0.000            0.000 
    65       -17992.228             0.000            0.000 
    66       -17991.358             0.000            0.000 
    67       -17992.072             0.000            0.000 
    68       -17993.575             0.000            0.000 
    69       -17986.736             0.000            0.000 
    70       -17988.491             0.000            0.000 
    71       -17987.650             0.000            0.000 
    72       -17987.272             0.000            0.000 
    73       -17988.800             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  92.7 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]         [,5]
 [1,] 0.0784341440 0.0174995967 0.0030651217 0.0005425034 0.9004586342
 [2,] 0.1888532331 0.0359174871 0.0057473230 0.0009157679 0.7685661889
 [3,] 0.3188812039 0.0516322039 0.0076725212 0.0011636169 0.6206504541
 [4,] 0.9719965483 0.0121393281 0.0011470058 0.0002238156 0.0144933023
 [5,] 0.0069583684 0.9905662533 0.0008633006 0.0001578773 0.0014542003
 [6,] 0.8005285871 0.1566729559 0.0066740276 0.0007621161 0.0353623133
 [7,] 0.9911513811 0.0042024253 0.0004315680 0.0001384180 0.0040762076
 [8,] 0.8609709887 0.0421969711 0.0044934629 0.0006480351 0.0916905422
 [9,] 0.1509039530 0.8183672786 0.0083531005 0.0008000140 0.0215756539
[10,] 0.0566242430 0.0208329652 0.0049810661 0.0009526003 0.9166091255
[11,] 0.2966246325 0.6564643785 0.0111904218 0.0010860822 0.0346344849
[12,] 0.7311875042 0.2192471040 0.0083200801 0.0009121695 0.0403331422
[13,] 0.0306834819 0.9530488569 0.0075271047 0.0005774133 0.0081631433
[14,] 0.0486718756 0.9385029780 0.0039980353 0.0004126228 0.0084144884
[15,] 0.1102007948 0.3007516616 0.5269733030 0.0100238809 0.0520503597
[16,] 0.9724395518 0.0176545183 0.0011692159 0.0002158370 0.0085208770
[17,] 0.3933735489 0.5533731096 0.0117838569 0.0011650310 0.0403044536
[18,] 0.8083763913 0.0508177300 0.0056740388 0.0008066898 0.1343251501
[19,] 0.9556886171 0.0295799240 0.0018010799 0.0002821753 0.0126482037
[20,] 0.1070478067 0.8690301155 0.0068345152 0.0006602071 0.0164273555
[21,] 0.9556886171 0.0295799240 0.0018010799 0.0002821753 0.0126482037
[22,] 0.7958750307 0.0524916863 0.0059211024 0.0008405972 0.1448715834
[23,] 0.0159277809 0.0272040190 0.9406016474 0.0063876214 0.0098789312
[24,] 0.9799203038 0.0090223157 0.0008567398 0.0001888695 0.0100117711
[25,] 0.1612884594 0.8065231822 0.0086566810 0.0008287231 0.0227029543
[26,] 0.0831989372 0.2076312111 0.6589188466 0.0091647820 0.0410862230
[27,] 0.0040783357 0.0072439612 0.9848468119 0.0013510217 0.0024798695
[28,] 0.0121467279 0.0247859291 0.9539722729 0.0023650405 0.0067300296
[29,] 0.8609709887 0.0421969711 0.0044934629 0.0006480351 0.0916905422
[30,] 0.0037219769 0.0010839648 0.0002879084 0.0001294798 0.9947766701
[31,] 0.1341932414 0.4154210765 0.3808570251 0.0097071926 0.0598214644
[32,] 0.0889594994 0.0194960792 0.0033754990 0.0005869236 0.8875819989
[33,] 0.0037219769 0.0010839648 0.0002879084 0.0001294798 0.9947766701
[34,] 0.0525796907 0.1208400481 0.7923424208 0.0071048532 0.0271329872
[35,] 0.1093630317 0.7872882770 0.0632409795 0.0032580783 0.0368496335
[36,] 0.0037219769 0.0010839648 0.0002879084 0.0001294798 0.9947766701
[37,] 0.1070478067 0.8690301155 0.0068345152 0.0006602071 0.0164273555
[38,] 0.0018881963 0.0033609448 0.9929673097 0.0006246981 0.0011588512
[39,] 0.9811125652 0.0085349477 0.0008123849 0.0001835626 0.0093565396
[40,] 0.0001013936 0.0001016974 0.0001032247 0.9995925523 0.0001011320
[41,] 0.9995886223 0.0001062943 0.0001004142 0.0001000025 0.0001046666
[42,] 0.6191130212 0.3252935587 0.0103218828 0.0010824064 0.0441891309
[43,] 0.1109321808 0.0462693114 0.0121928941 0.0023453094 0.8282603043
[44,] 0.0069583684 0.9905662533 0.0008633006 0.0001578773 0.0014542003
[45,] 0.2675312598 0.0461327471 0.0070469073 0.0010859861 0.6782030997
[46,] 0.0036072251 0.0064160211 0.9865941496 0.0011885477 0.0021940564
[47,] 0.0040783357 0.0072439612 0.9848468119 0.0013510217 0.0024798695
[48,] 0.0163658755 0.0339373021 0.9377130676 0.0030114552 0.0089722997
[49,] 0.9930262803 0.0033392808 0.0003589279 0.0001299054 0.0031456055
[50,] 0.1416440045 0.0633680510 0.0177805395 0.0035156450 0.7736917600
[51,] 0.0552464402 0.0860603590 0.7826344010 0.0394941020 0.0365646979
[52,] 0.9556886171 0.0295799240 0.0018010799 0.0002821753 0.0126482037
[53,] 0.3377924221 0.0534295651 0.0078617574 0.0011861503 0.5997301052
[54,] 0.7035031118 0.0612316044 0.0073827859 0.0010480929 0.2268344051
[55,] 0.5256527974 0.4175594635 0.0113627822 0.0011591551 0.0442658019
[56,] 0.0184366215 0.9759006528 0.0018948670 0.0002392820 0.0035285766
[57,] 0.1109321808 0.0462693114 0.0121928941 0.0023453094 0.8282603043
[58,] 0.8360135512 0.1257634992 0.0057085000 0.0006710784 0.0318433712
[59,] 0.9899821157 0.0059390370 0.0004844434 0.0001423590 0.0034520450
[60,] 0.1303848973 0.7119380402 0.1055452725 0.0047805323 0.0473512576
[61,] 0.9556886171 0.0295799240 0.0018010799 0.0002821753 0.0126482037
[62,] 0.1093630317 0.7872882770 0.0632409795 0.0032580783 0.0368496335
[63,] 0.5130162139 0.0640643058 0.0086181398 0.0012529902 0.4130483503
[64,] 0.0037219769 0.0010839648 0.0002879084 0.0001294798 0.9947766701

[[1]]$tau
[1] 0.779866328 0.708868329 0.517858823 0.001136962 0.861823350

[[1]]$phi
[1] 0.2 0.2 0.2 0.2 0.2

[[1]]$kappa
[1] 5


ELBO for this run: -18179.2
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.021317 seconds 
1000 transitions using 10 leapfrog steps per transition would take 213.17 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -19232.942             1.000            1.000 
     2       -18391.331             0.523            1.000 
     3       -18318.248             0.350            0.046 
     4       -18265.037             0.263            0.046 
     5       -18236.516             0.211            0.004 
     6       -18239.478             0.176            0.004 
     7       -18210.249             0.151            0.003 
     8       -18183.042             0.132            0.003 
     9       -18183.655             0.118            0.002 
    10       -18170.359             0.106            0.002 
    11       -18160.244             0.096            0.002 
    12       -18137.429             0.088            0.002 
    13       -18131.990             0.082            0.001 
    14       -18121.141             0.076            0.001 
    15       -18124.808             0.071            0.001 
    16       -18104.534             0.066            0.001 
    17       -18108.066             0.062            0.001 
    18       -18088.326             0.059            0.001 
    19       -18083.467             0.056            0.001 
    20       -18075.415             0.053            0.001 
    21       -18068.730             0.003            0.001 
    22       -18070.682             0.001            0.001 
    23       -18062.115             0.001            0.001 
    24       -18060.052             0.001            0.000 
    25       -18048.194             0.001            0.000 
    26       -18042.672             0.001            0.000 
    27       -18045.101             0.001            0.000 
    28       -18042.379             0.000            0.000 
    29       -18037.525             0.000            0.000 
    30       -18038.527             0.000            0.000 
    31       -18030.504             0.000            0.000 
    32       -18035.889             0.000            0.000 
    33       -18032.291             0.000            0.000 
    34       -18026.205             0.000            0.000 
    35       -18025.840             0.000            0.000 
    36       -18022.272             0.000            0.000 
    37       -18021.914             0.000            0.000 
    38       -18016.713             0.000            0.000 
    39       -18022.062             0.000            0.000 
    40       -18015.777             0.000            0.000 
    41       -18016.411             0.000            0.000 
    42       -18012.473             0.000            0.000 
    43       -18011.599             0.000            0.000 
    44       -18007.904             0.000            0.000 
    45       -18012.980             0.000            0.000 
    46       -18011.820             0.000            0.000 
    47       -18008.445             0.000            0.000 
    48       -18014.079             0.000            0.000 
    49       -18000.996             0.000            0.000 
    50       -18002.413             0.000            0.000 
    51       -18005.964             0.000            0.000 
    52       -18002.174             0.000            0.000 
    53       -18003.094             0.000            0.000 
    54       -18005.391             0.000            0.000 
    55       -18002.983             0.000            0.000 
    56       -17999.743             0.000            0.000 
    57       -17998.764             0.000            0.000 
    58       -18001.308             0.000            0.000 
    59       -17999.032             0.000            0.000 
    60       -17998.680             0.000            0.000 
    61       -17999.581             0.000            0.000 
    62       -18000.577             0.000            0.000 
    63       -17996.685             0.000            0.000 
    64       -17993.986             0.000            0.000 
    65       -17995.209             0.000            0.000 
    66       -17994.073             0.000            0.000 
    67       -17996.851             0.000            0.000 
    68       -17994.218             0.000            0.000 
    69       -17991.628             0.000            0.000 
    70       -17990.049             0.000            0.000 
    71       -17995.435             0.000            0.000 
    72       -17994.235             0.000            0.000 
    73       -17994.424             0.000            0.000 
    74       -17991.380             0.000            0.000 
    75       -17994.185             0.000            0.000 
    76       -17991.991             0.000            0.000 
    77       -17993.531             0.000            0.000 
    78       -17991.679             0.000            0.000 
    79       -17987.849             0.000            0.000 
    80       -17988.783             0.000            0.000 
    81       -17992.684             0.000            0.000 
    82       -17991.502             0.000            0.000 
    83       -17988.938             0.000            0.000 
    84       -17989.860             0.000            0.000 
    85       -17988.727             0.000            0.000 
    86       -17985.198             0.000            0.000 
    87       -17986.596             0.000            0.000 
    88       -17988.523             0.000            0.000 
    89       -17984.368             0.000            0.000 
    90       -17989.429             0.000            0.000 
    91       -17985.844             0.000            0.000 
    92       -17987.957             0.000            0.000 
    93       -17985.966             0.000            0.000 
    94       -17986.138             0.000            0.000 
    95       -17985.636             0.000            0.000 
    96       -17984.311             0.000            0.000 
    97       -17983.031             0.000            0.000 
    98       -17983.768             0.000            0.000 
    99       -17982.119             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  117.9 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]         [,5]
 [1,] 0.0784341440 0.0174995967 0.0030651217 0.0005425034 0.9004586342
 [2,] 0.1888532331 0.0359174871 0.0057473230 0.0009157679 0.7685661889
 [3,] 0.3188812039 0.0516322039 0.0076725212 0.0011636169 0.6206504541
 [4,] 0.9719965483 0.0121393281 0.0011470058 0.0002238156 0.0144933023
 [5,] 0.0069583684 0.9905662533 0.0008633006 0.0001578773 0.0014542003
 [6,] 0.8005285871 0.1566729559 0.0066740276 0.0007621161 0.0353623133
 [7,] 0.9911513811 0.0042024253 0.0004315680 0.0001384180 0.0040762076
 [8,] 0.8609709887 0.0421969711 0.0044934629 0.0006480351 0.0916905422
 [9,] 0.1509039530 0.8183672786 0.0083531005 0.0008000140 0.0215756539
[10,] 0.0566242430 0.0208329652 0.0049810661 0.0009526003 0.9166091255
[11,] 0.2966246325 0.6564643785 0.0111904218 0.0010860822 0.0346344849
[12,] 0.7311875042 0.2192471040 0.0083200801 0.0009121695 0.0403331422
[13,] 0.0306834819 0.9530488569 0.0075271047 0.0005774133 0.0081631433
[14,] 0.0486718756 0.9385029780 0.0039980353 0.0004126228 0.0084144884
[15,] 0.1102007948 0.3007516616 0.5269733030 0.0100238809 0.0520503597
[16,] 0.9724395518 0.0176545183 0.0011692159 0.0002158370 0.0085208770
[17,] 0.3933735489 0.5533731096 0.0117838569 0.0011650310 0.0403044536
[18,] 0.8083763913 0.0508177300 0.0056740388 0.0008066898 0.1343251501
[19,] 0.9556886171 0.0295799240 0.0018010799 0.0002821753 0.0126482037
[20,] 0.1070478067 0.8690301155 0.0068345152 0.0006602071 0.0164273555
[21,] 0.9556886171 0.0295799240 0.0018010799 0.0002821753 0.0126482037
[22,] 0.7958750307 0.0524916863 0.0059211024 0.0008405972 0.1448715834
[23,] 0.0159277809 0.0272040190 0.9406016474 0.0063876214 0.0098789312
[24,] 0.9799203038 0.0090223157 0.0008567398 0.0001888695 0.0100117711
[25,] 0.1612884594 0.8065231822 0.0086566810 0.0008287231 0.0227029543
[26,] 0.0831989372 0.2076312111 0.6589188466 0.0091647820 0.0410862230
[27,] 0.0040783357 0.0072439612 0.9848468119 0.0013510217 0.0024798695
[28,] 0.0121467279 0.0247859291 0.9539722729 0.0023650405 0.0067300296
[29,] 0.8609709887 0.0421969711 0.0044934629 0.0006480351 0.0916905422
[30,] 0.0037219769 0.0010839648 0.0002879084 0.0001294798 0.9947766701
[31,] 0.1341932414 0.4154210765 0.3808570251 0.0097071926 0.0598214644
[32,] 0.0889594994 0.0194960792 0.0033754990 0.0005869236 0.8875819989
[33,] 0.0037219769 0.0010839648 0.0002879084 0.0001294798 0.9947766701
[34,] 0.0525796907 0.1208400481 0.7923424208 0.0071048532 0.0271329872
[35,] 0.1093630317 0.7872882770 0.0632409795 0.0032580783 0.0368496335
[36,] 0.0037219769 0.0010839648 0.0002879084 0.0001294798 0.9947766701
[37,] 0.1070478067 0.8690301155 0.0068345152 0.0006602071 0.0164273555
[38,] 0.0018881963 0.0033609448 0.9929673097 0.0006246981 0.0011588512
[39,] 0.9811125652 0.0085349477 0.0008123849 0.0001835626 0.0093565396
[40,] 0.0001013936 0.0001016974 0.0001032247 0.9995925523 0.0001011320
[41,] 0.9995886223 0.0001062943 0.0001004142 0.0001000025 0.0001046666
[42,] 0.6191130212 0.3252935587 0.0103218828 0.0010824064 0.0441891309
[43,] 0.1109321808 0.0462693114 0.0121928941 0.0023453094 0.8282603043
[44,] 0.0069583684 0.9905662533 0.0008633006 0.0001578773 0.0014542003
[45,] 0.2675312598 0.0461327471 0.0070469073 0.0010859861 0.6782030997
[46,] 0.0036072251 0.0064160211 0.9865941496 0.0011885477 0.0021940564
[47,] 0.0040783357 0.0072439612 0.9848468119 0.0013510217 0.0024798695
[48,] 0.0163658755 0.0339373021 0.9377130676 0.0030114552 0.0089722997
[49,] 0.9930262803 0.0033392808 0.0003589279 0.0001299054 0.0031456055
[50,] 0.1416440045 0.0633680510 0.0177805395 0.0035156450 0.7736917600
[51,] 0.0552464402 0.0860603590 0.7826344010 0.0394941020 0.0365646979
[52,] 0.9556886171 0.0295799240 0.0018010799 0.0002821753 0.0126482037
[53,] 0.3377924221 0.0534295651 0.0078617574 0.0011861503 0.5997301052
[54,] 0.7035031118 0.0612316044 0.0073827859 0.0010480929 0.2268344051
[55,] 0.5256527974 0.4175594635 0.0113627822 0.0011591551 0.0442658019
[56,] 0.0184366215 0.9759006528 0.0018948670 0.0002392820 0.0035285766
[57,] 0.1109321808 0.0462693114 0.0121928941 0.0023453094 0.8282603043
[58,] 0.8360135512 0.1257634992 0.0057085000 0.0006710784 0.0318433712
[59,] 0.9899821157 0.0059390370 0.0004844434 0.0001423590 0.0034520450
[60,] 0.1303848973 0.7119380402 0.1055452725 0.0047805323 0.0473512576
[61,] 0.9556886171 0.0295799240 0.0018010799 0.0002821753 0.0126482037
[62,] 0.1093630317 0.7872882770 0.0632409795 0.0032580783 0.0368496335
[63,] 0.5130162139 0.0640643058 0.0086181398 0.0012529902 0.4130483503
[64,] 0.0037219769 0.0010839648 0.0002879084 0.0001294798 0.9947766701

[[1]]$tau
[1] 0.6894603 0.5469419 0.0700000 0.6922344 0.7040387

[[1]]$phi
[1] 0.2 0.2 0.2 0.2 0.2

[[1]]$kappa
[1] 5


ELBO for this run: -18318.2
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181950-1-3e86e8.csv\n"
init_taus from clustering  0.000454576713066447 init_taus from clustering  0.864837894982007 init_taus from clustering  0.592537241896523 init_taus from clustering  0.785675206469181 init_taus from clustering  0.72438664065152 init_taus from clustering  0.492977553600861Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.025883 seconds 
1000 transitions using 10 leapfrog steps per transition would take 258.83 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -18396.156             1.000            1.000 
     2       -18259.889             0.504            1.000 
     3       -18251.388             0.336            0.007 
     4       -18219.209             0.252            0.007 
     5       -18217.639             0.202            0.002 
     6       -18175.236             0.169            0.002 
     7       -18150.975             0.145            0.002 
     8       -18155.917             0.127            0.002 
     9       -18137.484             0.113            0.001 
    10       -18130.768             0.102            0.001 
    11       -18117.723             0.092            0.001 
    12       -18109.926             0.085            0.001 
    13       -18111.357             0.078            0.001 
    14       -18111.574             0.073            0.001 
    15       -18095.453             0.068            0.001 
    16       -18100.212             0.064            0.001 
    17       -18095.650             0.060            0.000 
    18       -18092.232             0.057            0.000 
    19       -18086.739             0.054            0.000 
    20       -18079.773             0.051            0.000 
    21       -18084.000             0.001            0.000 
    22       -18076.118             0.001            0.000 
    23       -18085.253             0.001            0.000 
    24       -18077.073             0.001            0.000 
    25       -18074.249             0.001            0.000 
    26       -18078.482             0.000            0.000 
    27       -18068.298             0.000            0.000 
    28       -18066.060             0.000            0.000 
    29       -18065.843             0.000            0.000 
    30       -18059.001             0.000            0.000 
    31       -18060.265             0.000            0.000 
    32       -18059.822             0.000            0.000 
    33       -18053.778             0.000            0.000 
    34       -18062.859             0.000            0.000 
    35       -18058.874             0.000            0.000 
    36       -18057.840             0.000            0.000 
    37       -18045.633             0.000            0.000 
    38       -18054.035             0.000            0.000 
    39       -18055.200             0.000            0.000 
    40       -18048.852             0.000            0.000 
    41       -18046.216             0.000            0.000 
    42       -18043.981             0.000            0.000 
    43       -18046.513             0.000            0.000 
    44       -18040.445             0.000            0.000 
    45       -18043.887             0.000            0.000 
    46       -18038.940             0.000            0.000 
    47       -18042.202             0.000            0.000 
    48       -18037.535             0.000            0.000 
    49       -18034.229             0.000            0.000 
    50       -18034.694             0.000            0.000 
    51       -18034.152             0.000            0.000 
    52       -18030.703             0.000            0.000 
    53       -18033.007             0.000            0.000 
    54       -18027.511             0.000            0.000 
    55       -18025.213             0.000            0.000 
    56       -18030.758             0.000            0.000 
    57       -18027.329             0.000            0.000 
    58       -18022.412             0.000            0.000 
    59       -18022.398             0.000            0.000 
    60       -18021.812             0.000            0.000 
    61       -18026.942             0.000            0.000 
    62       -18020.984             0.000            0.000 
    63       -18016.989             0.000            0.000 
    64       -18017.793             0.000            0.000 
    65       -18017.718             0.000            0.000 
    66       -18017.518             0.000            0.000 
    67       -18014.868             0.000            0.000 
    68       -18012.938             0.000            0.000 
    69       -18017.994             0.000            0.000 
    70       -18014.590             0.000            0.000 
    71       -18012.639             0.000            0.000 
    72       -18013.399             0.000            0.000 
    73       -18012.348             0.000            0.000 
    74       -18011.278             0.000            0.000 
    75       -18012.719             0.000            0.000 
    76       -18010.975             0.000            0.000 
    77       -18007.996             0.000            0.000 
    78       -18010.294             0.000            0.000 
    79       -18007.405             0.000            0.000 
    80       -18007.133             0.000            0.000 
    81       -18002.263             0.000            0.000 
    82       -18007.806             0.000            0.000 
    83       -18006.460             0.000            0.000 
    84       -18007.927             0.000            0.000 
    85       -18006.761             0.000            0.000 
    86       -18005.961             0.000            0.000 
    87       -18006.083             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  194.9 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]         [,5]
 [1,] 0.0006570492 0.8416280644 0.0063988021 0.1198431043 0.0281467021
 [2,] 0.0009840470 0.6759030134 0.0105945673 0.2564573420 0.0506912426
 [3,] 0.0011340769 0.5105203040 0.0129042784 0.4025145003 0.0665082879
 [4,] 0.0001151585 0.0017338080 0.0003455620 0.9952151979 0.0023822355
 [5,] 0.0002921465 0.0044235002 0.0067040551 0.0193389221 0.9671421973
 [6,] 0.0008456020 0.0376651840 0.0157159831 0.5627765252 0.3768071121
 [7,] 0.0001013351 0.0002337253 0.0001231675 0.9990962870 0.0003354646
 [8,] 0.0003945998 0.0449431679 0.0044756889 0.9150608979 0.0330275696
 [9,] 0.0001622614 0.0019305327 0.0018513300 0.0108810624 0.9844850994
[10,] 0.0007745555 0.9197175615 0.0061626691 0.0500735366 0.0197747332
[11,] 0.0003849836 0.0096331655 0.0074761833 0.0665454758 0.9132691564
[12,] 0.0008747132 0.0364710025 0.0168531460 0.4609502228 0.4783179534
[13,] 0.0016811207 0.0259224108 0.0747643498 0.0892098074 0.7894177153
[14,] 0.0001106030 0.0003721584 0.0004310455 0.0014704097 0.9974100206
[15,] 0.0002553475 0.0008968709 0.9884389311 0.0017215685 0.0037143784
[16,] 0.0004024163 0.0207196730 0.0057167206 0.8894880330 0.0812546635
[17,] 0.0005424159 0.0160262818 0.0110683834 0.1236958802 0.8446297172
[18,] 0.0005333917 0.0746436597 0.0063764928 0.8707849443 0.0446637474
[19,] 0.0004874250 0.0251705146 0.0074333489 0.8499651360 0.1138432104
[20,] 0.0001160201 0.0005490825 0.0005676690 0.0025935910 0.9959189844
[21,] 0.0004874250 0.0251705146 0.0074333489 0.8499651360 0.1138432104
[22,] 0.0005650379 0.0823117342 0.0067984025 0.8600406322 0.0470843595
[23,] 0.0009576058 0.0014168388 0.0152711908 0.0021839041 0.0033538554
[24,] 0.0001044943 0.0005696830 0.0001742415 0.9982079459 0.0008111530
[25,] 0.0001756525 0.0023479327 0.0022124380 0.0135130510 0.9809369665
[26,] 0.0002043441 0.0005629053 0.9920441003 0.0010041162 0.0019867447
[27,] 0.0003000009 0.0004752769 0.0059412945 0.0007121853 0.0010924591
[28,] 0.0039806075 0.0112742812 0.4940167753 0.0198069537 0.0355060494
[29,] 0.0003945998 0.0449431679 0.0044756889 0.9150608979 0.0330275696
[30,] 0.0001789448 0.9835193141 0.0009280042 0.0114473902 0.0033892071
[31,] 0.0013517354 0.0077113824 0.9028457564 0.0164361124 0.0399854590
[32,] 0.0007003086 0.8244276748 0.0069273992 0.1335744386 0.0307813551
[33,] 0.0001789448 0.9835193141 0.0009280042 0.0114473902 0.0033892071
[34,] 0.0013264571 0.0047475833 0.9029178956 0.0088179941 0.0172080593
[35,] 0.0037673642 0.0415721984 0.2959981211 0.1151302352 0.4894963944
[36,] 0.0001789448 0.9835193141 0.0009280042 0.0114473902 0.0033892071
[37,] 0.0001160201 0.0005490825 0.0005676690 0.0025935910 0.9959189844
[38,] 0.0007666532 0.0014263674 0.0230062709 0.0022843856 0.0036843045
[39,] 0.0001033200 0.0004462607 0.0001551823 0.9985397366 0.0006313853
[40,] 0.9994995331 0.0001000267 0.0001001247 0.0001000451 0.0001000636
[41,] 0.0001578883 0.0049528968 0.0011045395 0.9816512489 0.0116054420
[42,] 0.0008286931 0.0311654476 0.0166075610 0.3223853370 0.6227162588
[43,] 0.0020449898 0.8197718843 0.0161249565 0.1055167247 0.0471673063
[44,] 0.0002921465 0.0044235002 0.0067040551 0.0193389221 0.9671421973
[45,] 0.0010973329 0.5727326777 0.0122565214 0.3463537041 0.0614215891
[46,] 0.0003693431 0.0006110176 0.0082068418 0.0009350941 0.0014568699
[47,] 0.0003000009 0.0004752769 0.0059412945 0.0007121853 0.0010924591
[48,] 0.0037921984 0.0111657350 0.5678271983 0.0197793049 0.0358680041
[49,] 0.0001036363 0.0004487910 0.0001617623 0.9984238962 0.0007351998
[50,] 0.0031198345 0.7577972375 0.0236275887 0.1362478014 0.0652114905
[51,] 0.0208602577 0.0191164149 0.1294171003 0.0283287306 0.0409847343
[52,] 0.0004874250 0.0251705146 0.0074333489 0.8499651360 0.1138432104
[53,] 0.0011413012 0.4885232962 0.0130663100 0.4227571468 0.0680283592
[54,] 0.0007776692 0.1452230378 0.0095209065 0.7786752860 0.0612761011
[55,] 0.0007320219 0.0251771482 0.0149552552 0.2282133234 0.7253461299
[56,] 0.0001925397 0.0022905198 0.0031517505 0.0103196716 0.9830007002
[57,] 0.0020449898 0.8197718843 0.0161249565 0.1055167247 0.0471673063
[58,] 0.0008069472 0.0372342466 0.0146402791 0.6203183834 0.3211805069
[59,] 0.0002847215 0.0137678663 0.0034351510 0.9373262290 0.0436910993
[60,] 0.0040801216 0.0392115379 0.4274128075 0.1014123218 0.3632952403
[61,] 0.0004874250 0.0251705146 0.0074333489 0.8499651360 0.1138432104
[62,] 0.0037673642 0.0415721984 0.2959981211 0.1151302352 0.4894963944
[63,] 0.0010742294 0.3055010151 0.0128589920 0.6007794551 0.0735363218
[64,] 0.0001789448 0.9835193141 0.0009280042 0.0114473902 0.0033892071
              [,6]
 [1,] 0.0033262778
 [2,] 0.0053697878
 [3,] 0.0064185524
 [4,] 0.0002080381
 [5,] 0.0020991788
 [6,] 0.0061895936
 [7,] 0.0001100204
 [8,] 0.0020980759
 [9,] 0.0006897141
[10,] 0.0034969442
[11,] 0.0026910354
[12,] 0.0065329620
[13,] 0.0190045961
[14,] 0.0002057629
[15,] 0.0049729036
[16,] 0.0024184937
[17,] 0.0040373215
[18,] 0.0029977642
[19,] 0.0031003652
[20,] 0.0002546530
[21,] 0.0031003652
[22,] 0.0031998338
[23,] 0.9768166051
[24,] 0.0001324823
[25,] 0.0008139594
[26,] 0.0041977895
[27,] 0.9914787834
[28,] 0.4354153329
[29,] 0.0020980759
[30,] 0.0005371395
[31,] 0.0316695544
[32,] 0.0035888237
[33,] 0.0005371395
[34,] 0.0649820106
[35,] 0.0540356868
[36,] 0.0005371395
[37,] 0.0002546530
[38,] 0.9688320185
[39,] 0.0001241151
[40,] 0.0001002069
[41,] 0.0005279845
[42,] 0.0062967024
[43,] 0.0093741384
[44,] 0.0020991788
[45,] 0.0061381748
[46,] 0.9884208335
[47,] 0.9914787834
[48,] 0.3615675592
[49,] 0.0001267144
[50,] 0.0139960474
[51,] 0.7612927622
[52,] 0.0031003652
[53,] 0.0064835866
[54,] 0.0045269993
[55,] 0.0055761213
[56,] 0.0010448182
[57,] 0.0093741384
[58,] 0.0058196368
[59,] 0.0014949330
[60,] 0.0645879709
[61,] 0.0031003652
[62,] 0.0540356868
[63,] 0.0062499867
[64,] 0.0005371395

[[1]]$tau
[1] 0.0004545767 0.8648378950 0.5925372419 0.7856752065 0.7243866407
[6] 0.4929775536

[[1]]$phi
[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667

[[1]]$kappa
[1] 5


ELBO for this run: -18251.4
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.025494 seconds 
1000 transitions using 10 leapfrog steps per transition would take 254.94 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -19154.316             1.000            1.000 
     2       -18460.225             0.519            1.000 
     3       -18340.572             0.348            0.038 
     4       -18240.779             0.262            0.038 
     5       -18209.354             0.210            0.007 
     6       -18172.132             0.176            0.007 
     7       -18146.295             0.151            0.005 
     8       -18131.150             0.132            0.005 
     9       -18133.469             0.117            0.002 
    10       -18113.913             0.106            0.002 
    11       -18103.809             0.096            0.002 
    12       -18091.267             0.088            0.002 
    13       -18086.259             0.081            0.001 
    14       -18084.258             0.076            0.001 
    15       -18080.823             0.071            0.001 
    16       -18076.850             0.066            0.001 
    17       -18069.121             0.062            0.001 
    18       -18064.952             0.059            0.001 
    19       -18061.378             0.056            0.001 
    20       -18055.788             0.053            0.001 
    21       -18054.560             0.003            0.001 
    22       -18051.226             0.001            0.000 
    23       -18049.475             0.001            0.000 
    24       -18046.621             0.001            0.000 
    25       -18045.771             0.000            0.000 
    26       -18038.415             0.000            0.000 
    27       -18039.639             0.000            0.000 
    28       -18034.967             0.000            0.000 
    29       -18033.477             0.000            0.000 
    30       -18037.527             0.000            0.000 
    31       -18034.303             0.000            0.000 
    32       -18032.992             0.000            0.000 
    33       -18032.933             0.000            0.000 
    34       -18030.777             0.000            0.000 
    35       -18030.898             0.000            0.000 
    36       -18026.848             0.000            0.000 
    37       -18027.531             0.000            0.000 
    38       -18029.143             0.000            0.000 
    39       -18023.889             0.000            0.000 
    40       -18026.873             0.000            0.000 
    41       -18023.330             0.000            0.000 
    42       -18020.314             0.000            0.000 
    43       -18022.614             0.000            0.000 
    44       -18020.064             0.000            0.000 
    45       -18015.785             0.000            0.000 
    46       -18021.521             0.000            0.000 
    47       -18014.705             0.000            0.000 
    48       -18018.165             0.000            0.000 
    49       -18013.649             0.000            0.000 
    50       -18018.700             0.000            0.000 
    51       -18015.566             0.000            0.000 
    52       -18014.469             0.000            0.000 
    53       -18015.452             0.000            0.000 
    54       -18014.922             0.000            0.000 
    55       -18012.038             0.000            0.000 
    56       -18012.917             0.000            0.000 
    57       -18012.217             0.000            0.000 
    58       -18012.279             0.000            0.000 
    59       -18012.438             0.000            0.000 
    60       -18010.296             0.000            0.000 
    61       -18010.528             0.000            0.000 
    62       -18010.352             0.000            0.000 
    63       -18011.897             0.000            0.000 
    64       -18004.766             0.000            0.000 
    65       -18008.761             0.000            0.000 
    66       -18008.931             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  165.0 seconds.
[[1]]
[[1]]$w
              [,1]         [,2]         [,3]         [,4]         [,5]
 [1,] 0.0006570492 0.8416280644 0.0063988021 0.1198431043 0.0281467021
 [2,] 0.0009840470 0.6759030134 0.0105945673 0.2564573420 0.0506912426
 [3,] 0.0011340769 0.5105203040 0.0129042784 0.4025145003 0.0665082879
 [4,] 0.0001151585 0.0017338080 0.0003455620 0.9952151979 0.0023822355
 [5,] 0.0002921465 0.0044235002 0.0067040551 0.0193389221 0.9671421973
 [6,] 0.0008456020 0.0376651840 0.0157159831 0.5627765252 0.3768071121
 [7,] 0.0001013351 0.0002337253 0.0001231675 0.9990962870 0.0003354646
 [8,] 0.0003945998 0.0449431679 0.0044756889 0.9150608979 0.0330275696
 [9,] 0.0001622614 0.0019305327 0.0018513300 0.0108810624 0.9844850994
[10,] 0.0007745555 0.9197175615 0.0061626691 0.0500735366 0.0197747332
[11,] 0.0003849836 0.0096331655 0.0074761833 0.0665454758 0.9132691564
[12,] 0.0008747132 0.0364710025 0.0168531460 0.4609502228 0.4783179534
[13,] 0.0016811207 0.0259224108 0.0747643498 0.0892098074 0.7894177153
[14,] 0.0001106030 0.0003721584 0.0004310455 0.0014704097 0.9974100206
[15,] 0.0002553475 0.0008968709 0.9884389311 0.0017215685 0.0037143784
[16,] 0.0004024163 0.0207196730 0.0057167206 0.8894880330 0.0812546635
[17,] 0.0005424159 0.0160262818 0.0110683834 0.1236958802 0.8446297172
[18,] 0.0005333917 0.0746436597 0.0063764928 0.8707849443 0.0446637474
[19,] 0.0004874250 0.0251705146 0.0074333489 0.8499651360 0.1138432104
[20,] 0.0001160201 0.0005490825 0.0005676690 0.0025935910 0.9959189844
[21,] 0.0004874250 0.0251705146 0.0074333489 0.8499651360 0.1138432104
[22,] 0.0005650379 0.0823117342 0.0067984025 0.8600406322 0.0470843595
[23,] 0.0009576058 0.0014168388 0.0152711908 0.0021839041 0.0033538554
[24,] 0.0001044943 0.0005696830 0.0001742415 0.9982079459 0.0008111530
[25,] 0.0001756525 0.0023479327 0.0022124380 0.0135130510 0.9809369665
[26,] 0.0002043441 0.0005629053 0.9920441003 0.0010041162 0.0019867447
[27,] 0.0003000009 0.0004752769 0.0059412945 0.0007121853 0.0010924591
[28,] 0.0039806075 0.0112742812 0.4940167753 0.0198069537 0.0355060494
[29,] 0.0003945998 0.0449431679 0.0044756889 0.9150608979 0.0330275696
[30,] 0.0001789448 0.9835193141 0.0009280042 0.0114473902 0.0033892071
[31,] 0.0013517354 0.0077113824 0.9028457564 0.0164361124 0.0399854590
[32,] 0.0007003086 0.8244276748 0.0069273992 0.1335744386 0.0307813551
[33,] 0.0001789448 0.9835193141 0.0009280042 0.0114473902 0.0033892071
[34,] 0.0013264571 0.0047475833 0.9029178956 0.0088179941 0.0172080593
[35,] 0.0037673642 0.0415721984 0.2959981211 0.1151302352 0.4894963944
[36,] 0.0001789448 0.9835193141 0.0009280042 0.0114473902 0.0033892071
[37,] 0.0001160201 0.0005490825 0.0005676690 0.0025935910 0.9959189844
[38,] 0.0007666532 0.0014263674 0.0230062709 0.0022843856 0.0036843045
[39,] 0.0001033200 0.0004462607 0.0001551823 0.9985397366 0.0006313853
[40,] 0.9994995331 0.0001000267 0.0001001247 0.0001000451 0.0001000636
[41,] 0.0001578883 0.0049528968 0.0011045395 0.9816512489 0.0116054420
[42,] 0.0008286931 0.0311654476 0.0166075610 0.3223853370 0.6227162588
[43,] 0.0020449898 0.8197718843 0.0161249565 0.1055167247 0.0471673063
[44,] 0.0002921465 0.0044235002 0.0067040551 0.0193389221 0.9671421973
[45,] 0.0010973329 0.5727326777 0.0122565214 0.3463537041 0.0614215891
[46,] 0.0003693431 0.0006110176 0.0082068418 0.0009350941 0.0014568699
[47,] 0.0003000009 0.0004752769 0.0059412945 0.0007121853 0.0010924591
[48,] 0.0037921984 0.0111657350 0.5678271983 0.0197793049 0.0358680041
[49,] 0.0001036363 0.0004487910 0.0001617623 0.9984238962 0.0007351998
[50,] 0.0031198345 0.7577972375 0.0236275887 0.1362478014 0.0652114905
[51,] 0.0208602577 0.0191164149 0.1294171003 0.0283287306 0.0409847343
[52,] 0.0004874250 0.0251705146 0.0074333489 0.8499651360 0.1138432104
[53,] 0.0011413012 0.4885232962 0.0130663100 0.4227571468 0.0680283592
[54,] 0.0007776692 0.1452230378 0.0095209065 0.7786752860 0.0612761011
[55,] 0.0007320219 0.0251771482 0.0149552552 0.2282133234 0.7253461299
[56,] 0.0001925397 0.0022905198 0.0031517505 0.0103196716 0.9830007002
[57,] 0.0020449898 0.8197718843 0.0161249565 0.1055167247 0.0471673063
[58,] 0.0008069472 0.0372342466 0.0146402791 0.6203183834 0.3211805069
[59,] 0.0002847215 0.0137678663 0.0034351510 0.9373262290 0.0436910993
[60,] 0.0040801216 0.0392115379 0.4274128075 0.1014123218 0.3632952403
[61,] 0.0004874250 0.0251705146 0.0074333489 0.8499651360 0.1138432104
[62,] 0.0037673642 0.0415721984 0.2959981211 0.1151302352 0.4894963944
[63,] 0.0010742294 0.3055010151 0.0128589920 0.6007794551 0.0735363218
[64,] 0.0001789448 0.9835193141 0.0009280042 0.0114473902 0.0033892071
              [,6]
 [1,] 0.0033262778
 [2,] 0.0053697878
 [3,] 0.0064185524
 [4,] 0.0002080381
 [5,] 0.0020991788
 [6,] 0.0061895936
 [7,] 0.0001100204
 [8,] 0.0020980759
 [9,] 0.0006897141
[10,] 0.0034969442
[11,] 0.0026910354
[12,] 0.0065329620
[13,] 0.0190045961
[14,] 0.0002057629
[15,] 0.0049729036
[16,] 0.0024184937
[17,] 0.0040373215
[18,] 0.0029977642
[19,] 0.0031003652
[20,] 0.0002546530
[21,] 0.0031003652
[22,] 0.0031998338
[23,] 0.9768166051
[24,] 0.0001324823
[25,] 0.0008139594
[26,] 0.0041977895
[27,] 0.9914787834
[28,] 0.4354153329
[29,] 0.0020980759
[30,] 0.0005371395
[31,] 0.0316695544
[32,] 0.0035888237
[33,] 0.0005371395
[34,] 0.0649820106
[35,] 0.0540356868
[36,] 0.0005371395
[37,] 0.0002546530
[38,] 0.9688320185
[39,] 0.0001241151
[40,] 0.0001002069
[41,] 0.0005279845
[42,] 0.0062967024
[43,] 0.0093741384
[44,] 0.0020991788
[45,] 0.0061381748
[46,] 0.9884208335
[47,] 0.9914787834
[48,] 0.3615675592
[49,] 0.0001267144
[50,] 0.0139960474
[51,] 0.7612927622
[52,] 0.0031003652
[53,] 0.0064835866
[54,] 0.0045269993
[55,] 0.0055761213
[56,] 0.0010448182
[57,] 0.0093741384
[58,] 0.0058196368
[59,] 0.0014949330
[60,] 0.0645879709
[61,] 0.0031003652
[62,] 0.0540356868
[63,] 0.0062499867
[64,] 0.0005371395

[[1]]$tau
[1] 0.0700000 0.5512447 0.8195756 0.4009595 0.7974927 0.8445386

[[1]]$phi
[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667

[[1]]$kappa
[1] 5


ELBO for this run: -18340.6
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412181954-1-7cf44f.csv\n"
init_taus from clustering  0.734467848022504 init_taus from clustering  0.491012940722246 init_taus from clustering  0.665817119180911 init_taus from clustering  0.790737067749029 init_taus from clustering  0.575546864600343 init_taus from clustering  0.867368848991286 init_taus from clustering  0.00037113585024511Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.0271 seconds 
1000 transitions using 10 leapfrog steps per transition would take 271 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -18475.741             1.000            1.000 
     2       -18346.000             0.504            1.000 
     3       -18234.729             0.338            0.007 
     4       -18185.937             0.254            0.007 
     5       -18156.095             0.204            0.006 
     6       -18147.792             0.170            0.006 
     7       -18136.549             0.146            0.003 
     8       -18126.016             0.127            0.003 
     9       -18118.021             0.113            0.002 
    10       -18110.235             0.102            0.002 
    11       -18115.156             0.093            0.001 
    12       -18101.297             0.085            0.001 
    13       -18091.346             0.079            0.001 
    14       -18090.983             0.073            0.001 
    15       -18088.140             0.068            0.001 
    16       -18087.260             0.064            0.001 
    17       -18092.625             0.060            0.001 
    18       -18078.970             0.057            0.001 
    19       -18076.662             0.054            0.001 
    20       -18080.726             0.051            0.001 
    21       -18078.945             0.001            0.000 
    22       -18075.604             0.001            0.000 
    23       -18076.000             0.001            0.000 
    24       -18076.067             0.000            0.000 
    25       -18070.961             0.000            0.000 
    26       -18075.085             0.000            0.000 
    27       -18069.422             0.000            0.000 
    28       -18070.191             0.000            0.000 
    29       -18070.340             0.000            0.000 
    30       -18059.417             0.000            0.000 
    31       -18064.867             0.000            0.000 
    32       -18059.401             0.000            0.000 
    33       -18056.299             0.000            0.000 
    34       -18060.963             0.000            0.000 
    35       -18052.413             0.000            0.000 
    36       -18052.595             0.000            0.000 
    37       -18055.129             0.000            0.000 
    38       -18054.448             0.000            0.000 
    39       -18047.199             0.000            0.000 
    40       -18048.823             0.000            0.000 
    41       -18049.058             0.000            0.000 
    42       -18043.716             0.000            0.000 
    43       -18046.729             0.000            0.000 
    44       -18045.699             0.000            0.000 
    45       -18046.800             0.000            0.000 
    46       -18041.190             0.000            0.000 
    47       -18046.072             0.000            0.000 
    48       -18039.474             0.000            0.000 
    49       -18037.524             0.000            0.000 
    50       -18036.484             0.000            0.000 
    51       -18035.633             0.000            0.000 
    52       -18030.072             0.000            0.000 
Chain 1 stan::variational::advi::calc_ELBO: The number of dropped evaluations has reached its maximum amount (100). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  154.4 seconds.
An error occurred during inference: Fitting failed. Unable to retrieve the metadata.
Error processing 00db1b95-8ca3-4cc4-bb46-6b8c8019a7c7: object 'tol_rel_obj' not found
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
[1] 98
[1] 99
[1] 100
[1] 101
[1] 102
[1] 103
[1] 104
[1] 105
[1] 106
[1] 107
[1] 108
[1] 109
[1] 110
[1] 111
[1] 112
[1] 113
[1] 114
[1] 115
[1] 116
[1] 117
[1] 118
[1] 119
[1] 120
[1] 121
[1] 122
[1] 123
[1] 124
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
[1] 130
[1] 131
[1] 132
[1] 133
[1] 134
[1] 135
[1] 136
[1] 137
[1] 138
[1] 139
[1] 140
[1] 141
[1] 142
[1] 143
[1] 144
[1] 145
[1] 146
[1] 147
[1] 148
[1] 149
[1] 150
[1] 151
[1] 152
[1] 153
[1] 154
[1] 155
[1] 156
[1] 157
[1] 158
[1] 159
[1] 160
[1] 161
[1] 162
[1] 163
[1] 164
[1] 165
[1] 166
[1] 167
[1] 168
[1] 169
[1] 170
[1] 171
[1] 172
[1] 173
[1] 174
[1] 175
[1] 176
[1] 177
[1] 178
[1] 179
[1] 180
[1] 181
[1] 182
[1] 183
[1] 184
[1] 185
[1] 186
[1] 187
[1] 188
[1] 189
[1] 190
[1] 191
[1] 192
[1] 193
[1] 194
[1] 195
[1] 196
[1] 197
[1] 198
[1] 199
[1] 200
[1] 201
[1] 202
[1] 203
[1] 204
[1] 205
[1] 206
[1] 207
[1] 208
[1] 209
[1] 210
[1] 211
[1] 212
[1] 213
[1] 214
[1] 215
[1] 216
[1] 217
[1] 218
[1] 219
[1] 220
[1] 221
[1] 222
[1] 223
[1] 224
[1] 225
[1] 226
[1] 227
[1] 228
[1] 229
[1] 230
[1] 231
[1] 232
[1] 233
[1] 234
[1] 235
[1] 236
[1] 237
[1] 238
[1] 239
[1] 240
[1] 241
[1] 242
[1] 243
[1] 244
[1] 245
[1] 246
[1] 247
[1] 248
[1] 249
[1] 250
[1] 251
[1] 252
[1] 253
[1] 254
[1] 255
[1] 256
[1] 257
[1] 258
[1] 259
[1] 260
[1] 261
[1] 262
[1] 263
[1] 264
[1] 265
[1] 266
[1] 267
[1] 268
[1] 269
[1] 270
[1] 271
[1] 272
[1] 273
[1] 274
[1] 275
[1] 276
[1] 277
[1] 278
[1] 279
[1] 280
[1] 281
[1] 282
[1] 283
[1] 284
[1] 285
[1] 286
[1] 287
[1] 288
[1] 289
[1] 290
[1] 291
[1] 292
[1] 293
[1] 294
[1] 295
[1] 296
[1] 297
[1] 298
[1] 299
[1] 300
[1] 301
[1] 302
[1] 303
[1] 304
[1] 305
[1] 306
[1] 307
[1] 308
[1] 309
[1] 310
[1] 311
[1] 312
[1] 313
[1] 314
[1] 315
[1] 316
[1] 317
[1] 318
[1] 319
[1] 320
[1] 321
[1] 322
[1] 323
[1] 324
[1] 325
[1] 326
[1] 327
[1] 328
[1] 329
[1] 330
[1] 331
[1] 332
[1] 333
[1] 334
[1] 335
[1] 336
[1] 337
[1] 338
[1] 339
[1] 340
[1] 341
[1] 342
[1] 343
[1] 344
[1] 345
[1] 346
[1] 347
[1] 348
[1] 349
[1] 350
[1] 351
[1] 352
[1] 353
[1] 354
[1] 355
[1] 356
[1] 357
[1] 358
[1] 359
[1] 360
[1] 361
[1] 362
[1] 363
[1] 364
[1] 365
[1] 366
[1] 367
[1] 368
[1] 369
[1] 370
[1] 371
[1] 372
[1] 373
[1] 374
[1] 375
[1] 376
[1] 377
[1] 378
[1] 379
[1] 380
[1] 381
[1] 382
[1] 383
[1] 384
[1] 385
[1] 386
[1] 387
[1] 388
[1] 389
[1] 390
[1] 391
[1] 392
[1] 393
[1] 394
[1] 395
[1] 396
[1] 397
[1] 398
[1] 399
[1] 400
[1] 401
[1] 402
[1] 403
[1] 404
[1] 405
[1] 406
[1] 407
[1] 408
[1] 409
[1] 410
[1] 411
[1] 412
[1] 413
[1] 414
[1] 415
[1] 416
[1] 417
[1] 418
[1] 419
[1] 420
[1] 421
[1] 422
[1] 423
[1] 424
[1] 425
[1] 426
[1] 427
[1] 428
[1] 429
[1] 430
[1] 431
[1] 432
[1] 433
[1] 434
[1] 435
[1] 436
[1] 437
[1] 438
[1] 439
[1] 440
[1] 441
[1] 442
[1] 443
[1] 444
[1] 445
[1] 446
[1] 447
[1] 448
[1] 449
[1] 450
[1] 451
[1] 452
[1] 453
[1] 454
[1] 455
[1] 456
[1] 457
[1] 458
[1] 459
[1] 460
[1] 461
[1] 462
[1] 463
[1] 464
[1] 465
[1] 466
[1] 467
[1] 468
[1] 469
[1] 470
[1] 471
[1] 472
[1] 473
[1] 474
[1] 475
[1] 476
[1] 477
[1] 478
[1] 479
[1] 480
[1] 481
[1] 482
[1] 483
[1] 484
[1] 485
[1] 486
[1] 487
[1] 488
[1] 489
[1] 490
[1] 491
[1] 492
[1] 493
[1] 494
[1] 495
[1] 496
[1] 497
[1] 498
[1] 499
[1] 500
[1] 501
[1] 502
[1] 503
[1] 504
[1] 505
[1] 506
[1] 507
[1] 508
[1] 509
[1] 510
[1] 511
[1] 512
[1] 513
[1] 514
[1] 515
[1] 516
[1] 517
[1] 518
[1] 519
[1] 520
[1] 521
[1] 522
[1] 523
[1] 524
[1] 525
[1] 526
[1] 527
[1] 528
[1] 529
[1] 530
[1] 531
[1] 532
[1] 533
[1] 534
[1] 535
[1] 536
[1] 537
[1] 538
[1] 539
[1] 540
[1] 541
[1] 542
[1] 543
[1] 544
[1] 545
[1] 546
[1] 547
[1] 548
[1] 549
[1] 550
[1] 551
[1] 552
[1] 553
[1] 554
[1] 555
[1] 556
[1] 557
[1] 558
[1] 559
[1] 560
[1] 561
[1] 562
[1] 563
[1] 564
[1] 565
[1] 566
[1] 567
[1] 568
[1] 569
[1] 570
[1] 571
[1] 572
[1] 573
[1] 574
[1] 575
[1] 576
[1] 577
[1] 578
[1] 579
[1] 580
[1] 581
[1] 582
[1] 583
[1] 584
[1] 585
[1] 586
[1] 587
[1] 588
[1] 589
[1] 590
[1] 591
[1] 592
[1] 593
[1] 594
[1] 595
[1] 596
[1] 597
[1] 598
[1] 599
[1] 600
[1] 601
[1] 602
[1] 603
[1] 604
[1] 605
[1] 606
[1] 607
[1] 608
[1] 609
[1] 610
[1] 611
[1] 612
[1] 613
[1] 614
[1] 615
[1] 616
[1] 617
[1] 618
[1] 619
[1] 620
[1] 621
[1] 622
[1] 623
[1] 624
[1] 625
[1] 626
[1] 627
[1] 628
[1] 629
[1] 630
[1] 631
[1] 632
[1] 633
[1] 634
[1] 635
[1] 636
[1] 637
[1] 638
[1] 639
[1] 640
[1] 641
[1] 642
[1] 643
[1] 644
[1] 645
[1] 646
[1] 647
[1] 648
[1] 649
[1] 650
[1] 651
[1] 652
[1] 653
[1] 654
[1] 655
[1] 656
[1] 657
[1] 658
[1] 659
[1] 660
[1] 661
[1] 662
[1] 663
[1] 664
[1] 665
[1] 666
[1] 667
[1] 668
[1] 669
[1] 670
[1] 671
[1] 672
[1] 673
[1] 674
[1] 675
[1] 676
[1] 677
[1] 678
[1] 679
[1] 680
[1] 681
[1] 682
[1] 683
[1] 684
[1] 685
[1] 686
[1] 687
[1] 688
[1] 689
[1] 690
[1] 691
[1] 692
[1] 693
[1] 694
[1] 695
[1] 696
[1] 697
[1] 698
[1] 699
[1] 700
[1] 701
[1] 702
[1] 703
[1] 704
[1] 705
[1] 706
[1] 707
[1] 708
[1] 709
[1] 710
[1] 711
[1] 712
[1] 713
[1] 714
[1] 715
[1] 716
[1] 717
[1] 718
[1] 719
[1] 720
[1] 721
[1] 722
Error processing 00db4dc2-3ec7-4ff9-9233-d69c8c8a607f: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
ℹ Adding segment with index 3 to segments included in the inference.
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
ℹ Adding segment with index 51 to segments included in the inference.
[1] 52
[1] 53
ℹ Adding segment with index 53 to segments included in the inference.
[1] 54
ℹ Adding segment with index 54 to segments included in the inference.
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
[1] 98
[1] 99
[1] 100
[1] 101
[1] 102
[1] 103
[1] 104
[1] 105
[1] 106
[1] 107
[1] 108
[1] 109
[1] 110
[1] 111
[1] 112
[1] 113
[1] 114
[1] 115
[1] 116
[1] 117
[1] 118
[1] 119
[1] 120
[1] 121
[1] 122
[1] 123
[1] 124
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
[1] 130
[1] 131
[1] 132
[1] 133
[1] 134
[1] 135
[1] 136
[1] 137
[1] 138
[1] 139
[1] 140
[1] 141
[1] 142
[1] 143
ℹ Adding segment with index 143 to segments included in the inference.
[1] 144
[1] 145
[1] 146
[1] 147
[1] 148
[1] 149
[1] 150
[1] 151
[1] 152
[1] 153
[1] 154
[1] 155
[1] 156
[1] 157
[1] 158
[1] 159
[1] 160
[1] 161
[1] 162
[1] 163
[1] 164
[1] 165
[1] 166
[1] 167
[1] 168
[1] 169
[1] 170
[1] 171
[1] 172
[1] 173
[1] 174
[1] 175
[1] 176
[1] 177
[1] 178
[1] 179
[1] 180
[1] 181
[1] 182
[1] 183
[1] 184
[1] 185
[1] 186
[1] 187
[1] 188
[1] 189
[1] 190
[1] 191
[1] 192
[1] 193
[1] 194
[1] 195
[1] 196
[1] 197
[1] 198
[1] 199
[1] 200
[1] 201
[1] 202
[1] 203
[1] 204
[1] 205
[1] 206
[1] 207
[1] 208
[1] 209
[1] 210
[1] 211
[1] 212
[1] 213
[1] 214
[1] 215
[1] 216
[1] 217
[1] 218
[1] 219
[1] 220
[1] 221
[1] 222
[1] 223
[1] 224
[1] 225
[1] 226
[1] 227
[1] 228
[1] 229
[1] 230
[1] 231
[1] 232
[1] 233
[1] 234
[1] 235
[1] 236
[1] 237
[1] 238
[1] 239
[1] 240
[1] 241
[1] 242
[1] 243
[1] 244
[1] 245
[1] 246
[1] 247
[1] 248
[1] 249
[1] 250
[1] 251
[1] 252
[1] 253
[1] 254
[1] 255
[1] 256
[1] 257
[1] 258
[1] 259
[1] 260
[1] 261
[1] 262
[1] 263
[1] 264
[1] 265
[1] 266
[1] 267
[1] 268
[1] 269
[1] 270
[1] 271
[1] 272
ℹ Adding segment with index 272 to segments included in the inference.
[1] 273
[1] 274
[1] 275
[1] 276
[1] 277
[1] 278
[1] 279
[1] 280
[1] 281
[1] 282
ℹ Adding segment with index 282 to segments included in the inference.
[1] 283
[1] 284
[1] 285
[1] 286
[1] 287
[1] 288
[1] 289
[1] 290
[1] 291
[1] 292
[1] 293
[1] 294
[1] 295
[1] 296
[1] 297
[1] 298
[1] 299
[1] 300
[1] 301
[1] 302
[1] 303
[1] 304
ℹ Adding segment with index 304 to segments included in the inference.
[1] 305
[1] 306
[1] 307
[1] 308
[1] 309
[1] 310
[1] 311
[1] 312
[1] 313
[1] 314
[1] 315
[1] 316
[1] 317
[1] 318
[1] 319
[1] 320
[1] 321
[1] 322
[1] 323
[1] 324
[1] 325
[1] 326
[1] 327
[1] 328
[1] 329
[1] 330
[1] 331
[1] 332
[1] 333
[1] 334
[1] 335
[1] 336
[1] 337
[1] 338
[1] 339
[1] 340
[1] 341
[1] 342
[1] 343
[1] 344
[1] 345
[1] 346
[1] 347
[1] 348
[1] 349
[1] 350
[1] 351
[1] 352
[1] 353
ℹ Adding segment with index 353 to segments included in the inference.
[1] 354
[1] 355
[1] 356
[1] 357
[1] 358
[1] 359
[1] 360
[1] 361
ℹ Adding segment with index 361 to segments included in the inference.
[1] 362
[1] 363
[1] 364
[1] 365
[1] 366
[1] 367
[1] 368
[1] 369
[1] 370
[1] 371
[1] 372
[1] 373
[1] 374
[1] 375
[1] 376
[1] 377
[1] 378
ℹ Adding segment with index 378 to segments included in the inference.
[1] 379
[1] 380
[1] 381
[1] 382
[1] 383
[1] 384
[1] 385
[1] 386
[1] 387
[1] 388
[1] 389
[1] 390
[1] 391
[1] 392
[1] 393
[1] 394
[1] 395
[1] 396
[1] 397
[1] 398
[1] 399
[1] 400
[1] 401
[1] 402
[1] 403
[1] 404
[1] 405
[1] 406
[1] 407
[1] 408
[1] 409
[1] 410
[1] 411
[1] 412
[1] 413
[1] 414
[1] 415
[1] 416
[1] 417
[1] 418
[1] 419
[1] 420
[1] 421
[1] 422
[1] 423
[1] 424
[1] 425
[1] 426
[1] 427
[1] 428
[1] 429
[1] 430
[1] 431
[1] 432
[1] 433
[1] 434
[1] 435
[1] 436
ℹ Adding segment with index 436 to segments included in the inference.
[1] 437
[1] 438
[1] 439
[1] 440
[1] 441
[1] 442
[1] 443
[1] 444
[1] 445
[1] 446
[1] 447
[1] 448
[1] 449
[1] 450
ℹ Adding segment with index 450 to segments included in the inference.
[1] 451
[1] 452
[1] 453
[1] 454
[1] 455
[1] 456
[1] 457
[1] 458
[1] 459
[1] 460
[1] 461
[1] 462
[1] 463
[1] 464
[1] 465
[1] 466
[1] 467
[1] 468
[1] 469
[1] 470
[1] 471
[1] 472
[1] 473
[1] 474
[1] 475
[1] 476
[1] 477
[1] 478
[1] 479
[1] 480
[1] 481
[1] 482
[1] 483
[1] 484
[1] 485
[1] 486
[1] 487
[1] 488
[1] 489
[1] 490
[1] 491
[1] 492
[1] 493
[1] 494
[1] 495
[1] 496
[1] 497
[1] 498
[1] 499
[1] 500
[1] 501
[1] 502
[1] 503
[1] 504
[1] 505
[1] 506
[1] 507
[1] 508
[1] 509
[1] 510
[1] 511
[1] 512
[1] 513
[1] 514
[1] 515
[1] 516
[1] 517
[1] 518
[1] 519
[1] 520
[1] 521
[1] 522
[1] 523
[1] 524
[1] 525
[1] 526
[1] 527
[1] 528
[1] 529
[1] 530
[1] 531
[1] 532
[1] 533
[1] 534
[1] 535
[1] 536
[1] 537
[1] 538
[1] 539
[1] 540
[1] 541
[1] 542
[1] 543
[1] 544
[1] 545
[1] 546
[1] 547
[1] 548
[1] 549
[1] 550
[1] 551
[1] 552
[1] 553
[1] 554
[1] 555
[1] 556
[1] 557
[1] 558
[1] 559
[1] 560
[1] 561
[1] 562
[1] 563
[1] 564
[1] 565
[1] 566
[1] 567
[1] 568
[1] 569
[1] 570
[1] 571
[1] 572
[1] 573
[1] 574
[1] 575
[1] 576
[1] 577
[1] 578
[1] 579
[1] 580
[1] 581
[1] 582
[1] 583
[1] 584
[1] 585
[1] 586
[1] 587
[1] 588
[1] 589
[1] 590
[1] 591
[1] 592
[1] 593
[1] 594
[1] 595
[1] 596
[1] 597
[1] 598
[1] 599
[1] 600
ℹ Adding segment with index 600 to segments included in the inference.
[1] 601
[1] 602
ℹ Adding segment with index 602 to segments included in the inference.
[1] 603
[1] 604
[1] 605
[1] 606
[1] 607
[1] 608
[1] 609
[1] 610
[1] 611
[1] 612
[1] 613
[1] 614
[1] 615
[1] 616
[1] 617
[1] 618
[1] 619
[1] 620
[1] 621
[1] 622
[1] 623
[1] 624
[1] 625
[1] 626
[1] 627
[1] 628
[1] 629
[1] 630
[1] 631
[1] 632
[1] 633
[1] 634
[1] 635
[1] 636
[1] 637
[1] 638
ℹ Adding segment with index 638 to segments included in the inference.
[1] 639
[1] 640
[1] 641
[1] 642
[1] 643
[1] 644
[1] 645
[1] 646
[1] 647
[1] 648
[1] 649
[1] 650
[1] 651
[1] 652
ℹ Adding segment with index 652 to segments included in the inference.
[1] 653
[1] 654
[1] 655
[1] 656
[1] 657
[1] 658
[1] 659
[1] 660
[1] 661
[1] 662
[1] 663
[1] 664
[1] 665
[1] 666
[1] 667
[1] 668
[1] 669
[1] 670
[1] 671
[1] 672
[1] 673
[1] 674
[1] 675
[1] 676
[1] 677
[1] 678
[1] 679
[1] 680
[1] 681
[1] 682
[1] 683
[1] 684
[1] 685
[1] 686
[1] 687
[1] 688
[1] 689
[1] 690
[1] 691
[1] 692
[1] 693
[1] 694
[1] 695
[1] 696
[1] 697
[1] 698
[1] 699
[1] 700
[1] 701
[1] 702
[1] 703
[1] 704
[1] 705
[1] 706
[1] 707
[1] 708
[1] 709
[1] 710
[1] 711
[1] 712
[1] 713
[1] 714
[1] 715
[1] 716
[1] 717
[1] 718
[1] 719
[1] 720
[1] 721
[1] 722
[1] 723
[1] 724
[1] 725
[1] 726
[1] 727
[1] 728
[1] 729
[1] 730
[1] 731
[1] 732
[1] 733
[1] 734
[1] 735
[1] 736
[1] 737
[1] 738
[1] 739
[1] 740
[1] 741
[1] 742
[1] 743
[1] 744
[1] 745
[1] 746
[1] 747
[1] 748
[1] 749
[1] 750
[1] 751
[1] 752
[1] 753
[1] 754
[1] 755
[1] 756
[1] 757
[1] 758
[1] 759
[1] 760
ℹ Adding segment with index 760 to segments included in the inference.
[1] 761
[1] 762
[1] 763
[1] 764
[1] 765
[1] 766
ℹ Adding segment with index 766 to segments included in the inference.
[1] 767
[1] 768
[1] 769
[1] 770
[1] 771
ℹ Adding segment with index 771 to segments included in the inference.
[1] 772
[1] 773
ℹ Adding segment with index 773 to segments included in the inference.
[1] 774
[1] 775
[1] 776
[1] 777
[1] 778
[1] 779
[1] 780
[1] 781
[1] 782
[1] 783
[1] 784
[1] 785
[1] 786
[1] 787
[1] 788
[1] 789
[1] 790
[1] 791
[1] 792
[1] 793
[1] 794
[1] 795
[1] 796
[1] 797
[1] 798
[1] 799
[1] 800
[1] 801
[1] 802
[1] 803
[1] 804
[1] 805
[1] 806
[1] 807
[1] 808
[1] 809
[1] 810
[1] 811
ℹ Adding segment with index 811 to segments included in the inference.
[1] 812
[1] 813
[1] 814
[1] 815
[1] 816
[1] 817
[1] 818
[1] 819
[1] 820
[1] 821
[1] 822
[1] 823
[1] 824
[1] 825
[1] 826
[1] 827
[1] 828
[1] 829
[1] 830
[1] 831
[1] 832
[1] 833
[1] 834
[1] 835
[1] 836
[1] 837
[1] 838
init_taus from clustering  0.317519906926326Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000154 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1.54 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -231.840             1.000            1.000 
     2         -230.712             0.502            1.000 
     3         -230.804             0.335            0.005 
     4         -230.732             0.251            0.005 
     5         -230.794             0.201            0.000 
     6         -230.727             0.168            0.000 
     7         -230.925             0.144            0.000 
     8         -230.646             0.126            0.001 
     9         -230.691             0.112            0.000 
    10         -230.928             0.101            0.001 
    11         -230.528             0.092            0.001 
    12         -230.878             0.084            0.001 
    13         -231.046             0.078            0.001 
    14         -230.743             0.072            0.001 
    15         -230.843             0.068            0.001 
    16         -230.646             0.064            0.001 
    17         -230.863             0.060            0.001 
    18         -230.666             0.057            0.001 
    19         -230.702             0.054            0.001 
    20         -230.883             0.051            0.001 
    21         -230.743             0.001            0.001 
    22         -230.754             0.001            0.001 
    23         -230.761             0.001            0.001 
    24         -230.762             0.001            0.001 
    25         -230.758             0.001            0.001 
    26         -230.839             0.001            0.001 
    27         -230.775             0.001            0.001 
    28         -231.190             0.001            0.001 
    29         -230.976             0.001            0.001 
    30         -230.967             0.001            0.001 
    31         -230.613             0.001            0.001 
    32         -230.618             0.001            0.001 
    33         -230.598             0.001            0.000 
    34         -230.664             0.001            0.000 
    35         -230.876             0.001            0.000 
    36         -230.641             0.001            0.000 
    37         -230.804             0.001            0.000 
    38         -230.602             0.001            0.000 
    39         -230.765             0.001            0.001 
    40         -231.038             0.001            0.001 
    41         -230.693             0.001            0.001 
    42         -230.585             0.001            0.001 
    43         -230.632             0.001            0.001 
    44         -230.783             0.001            0.001 
    45         -230.739             0.001            0.001 
    46         -230.755             0.001            0.001 
    47         -230.738             0.001            0.001 
    48         -230.683             0.001            0.001 
    49         -230.605             0.001            0.000 
    50         -230.683             0.001            0.000 
    51         -230.863             0.001            0.000 
    52         -230.682             0.001            0.001 
    53         -230.876             0.001            0.001 
    54         -230.742             0.001            0.001 
    55         -230.800             0.001            0.001 
    56         -230.784             0.001            0.001 
    57         -230.834             0.001            0.000 
    58         -230.627             0.001            0.000 
    59         -230.804             0.001            0.000 
    60         -230.979             0.001            0.000 
    61         -230.719             0.000            0.000 
    62         -230.624             0.000            0.000 
    63         -230.733             0.000            0.000 
    64         -230.681             0.000            0.000 
    65         -230.651             0.000            0.000 
    66         -230.848             0.001            0.000 
    67         -230.753             0.001            0.000 
    68         -230.797             0.001            0.000 
    69         -230.757             0.001            0.000 
    70         -230.763             0.000            0.000 
    71         -230.828             0.000            0.000 
    72         -230.804             0.000            0.000 
    73         -230.892             0.000            0.000 
    74         -230.978             0.000            0.000 
    75         -230.801             0.000            0.000 
    76         -230.759             0.000            0.000 
    77         -230.508             0.000            0.000 
    78         -230.726             0.000            0.000 
    79         -230.768             0.000            0.000 
    80         -230.615             0.000            0.000 
    81         -230.793             0.000            0.000 
    82         -230.694             0.000            0.000 
    83         -230.621             0.000            0.000 
    84         -230.611             0.000            0.000 
    85         -230.762             0.000            0.000 
    86         -231.097             0.000            0.000 
    87         -230.855             0.001            0.000 
    88         -230.660             0.001            0.000 
    89         -230.642             0.001            0.000 
    90         -230.918             0.001            0.001 
    91         -230.682             0.001            0.001 
    92         -230.510             0.001            0.001 
    93         -230.719             0.001            0.001 
    94         -230.607             0.001            0.001 
    95         -230.615             0.001            0.001 
    96         -230.683             0.001            0.001 
    97         -230.847             0.001            0.001 
    98         -230.539             0.001            0.001 
    99         -230.586             0.001            0.001 
   100         -230.888             0.001            0.001 
   101         -230.798             0.001            0.001 
   102         -231.027             0.001            0.001 
   103         -230.674             0.001            0.001 
   104         -230.618             0.001            0.001 
   105         -230.959             0.001            0.001 
   106         -230.706             0.001            0.001 
   107         -230.882             0.001            0.001 
   108         -230.744             0.001            0.001 
   109         -230.817             0.001            0.001 
   110         -230.625             0.001            0.001 
   111         -230.586             0.001            0.001 
   112         -230.753             0.001            0.001 
   113         -230.840             0.001            0.001 
   114         -230.667             0.001            0.001 
   115         -230.834             0.001            0.001 
   116         -230.670             0.001            0.001 
   117         -230.605             0.001            0.001 
   118         -230.844             0.001            0.001 
   119         -230.725             0.001            0.001 
   120         -230.779             0.001            0.001 
   121         -230.723             0.001            0.001 
   122         -230.748             0.001            0.001 
   123         -230.768             0.001            0.001 
   124         -230.803             0.001            0.001 
   125         -230.973             0.001            0.001 
   126         -230.899             0.000            0.001 
   127         -230.649             0.000            0.001 
   128         -230.547             0.000            0.000 
   129         -230.690             0.001            0.001 
   130         -230.777             0.000            0.000 
   131         -230.635             0.001            0.001 
   132         -230.824             0.001            0.001 
   133         -230.689             0.001            0.001 
   134         -230.628             0.000            0.001 
   135         -230.800             0.000            0.001 
   136         -230.662             0.000            0.001 
   137         -230.769             0.001            0.001 
   138         -230.664             0.000            0.000 
   139         -230.721             0.000            0.000 
   140         -230.593             0.000            0.000 
   141         -230.766             0.001            0.001 
   142         -230.542             0.001            0.001 
   143         -230.763             0.001            0.001 
   144         -230.798             0.001            0.001 
   145         -230.659             0.001            0.001 
   146         -230.572             0.001            0.001 
   147         -231.032             0.001            0.001 
   148         -230.752             0.001            0.001 
   149         -230.689             0.001            0.001 
   150         -230.557             0.001            0.001 
   151         -230.722             0.001            0.001 
   152         -230.869             0.001            0.001 
   153         -230.877             0.001            0.001 
   154         -230.589             0.001            0.001 
   155         -230.671             0.001            0.001 
   156         -230.566             0.001            0.001 
   157         -231.182             0.001            0.001 
   158         -230.806             0.001            0.001 
   159         -230.701             0.001            0.001 
   160         -230.747             0.001            0.001 
   161         -230.854             0.001            0.001 
   162         -230.812             0.001            0.001 
   163         -230.712             0.001            0.000 
   164         -230.601             0.001            0.000 
   165         -230.631             0.001            0.000 
   166         -230.776             0.001            0.000 
   167         -230.821             0.001            0.000 
   168         -230.829             0.001            0.000 
   169         -230.797             0.001            0.000 
   170         -230.734             0.001            0.000 
   171         -230.703             0.001            0.000 
   172         -230.763             0.001            0.000 
   173         -231.019             0.001            0.000 
   174         -230.672             0.001            0.000 
   175         -230.806             0.001            0.000 
   176         -230.638             0.001            0.000 
   177         -230.682             0.000            0.000 
   178         -230.683             0.000            0.000 
   179         -230.899             0.000            0.000 
   180         -230.728             0.000            0.000 
   181         -230.787             0.000            0.000 
   182         -230.665             0.000            0.000 
   183         -230.577             0.000            0.000 
   184         -230.857             0.000            0.000 
   185         -230.637             0.001            0.001 
   186         -230.826             0.001            0.001 
   187         -230.749             0.001            0.001 
   188         -230.691             0.001            0.001 
   189         -230.641             0.001            0.001 
   190         -230.627             0.001            0.001 
   191         -230.676             0.001            0.001 
   192         -230.689             0.001            0.001 
   193         -230.794             0.001            0.000 
   194         -230.800             0.000            0.000 
   195         -230.842             0.000            0.000 
   196         -230.731             0.000            0.000 
   197         -230.841             0.000            0.000 
   198         -230.784             0.000            0.000 
   199         -230.892             0.000            0.000 
   200         -230.813             0.000            0.000 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  1.1 seconds.
[[1]]
[[1]]$w
      [,1]
 [1,]    1
 [2,]    1
 [3,]    1
 [4,]    1
 [5,]    1
 [6,]    1
 [7,]    1
 [8,]    1
 [9,]    1
[10,]    1
[11,]    1
[12,]    1
[13,]    1
[14,]    1
[15,]    1
[16,]    1
[17,]    1
[18,]    1
[19,]    1
[20,]    1
[21,]    1
[22,]    1

[[1]]$tau
[1] 0.3175199

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -230.804
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.00016 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1.6 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -234.263             1.000            1.000 
     2         -232.491             0.504            1.000 
     3         -232.266             0.336            0.008 
     4         -231.845             0.253            0.008 
     5         -231.735             0.202            0.002 
     6         -231.545             0.169            0.002 
     7         -231.405             0.145            0.001 
     8         -231.307             0.127            0.001 
     9         -231.125             0.113            0.001 
    10         -231.003             0.101            0.001 
    11         -231.019             0.092            0.001 
    12         -230.979             0.085            0.001 
    13         -230.944             0.078            0.001 
    14         -230.735             0.073            0.001 
    15         -230.880             0.068            0.001 
    16         -230.811             0.064            0.001 
    17         -230.828             0.060            0.001 
    18         -230.822             0.056            0.001 
    19         -230.659             0.054            0.001 
    20         -230.792             0.051            0.001 
    21         -230.923             0.001            0.001 
    22         -230.647             0.001            0.001 
    23         -230.563             0.001            0.001 
    24         -230.759             0.001            0.001 
    25         -230.919             0.001            0.001 
    26         -230.760             0.001            0.001 
    27         -230.846             0.001            0.001 
    28         -230.692             0.001            0.001 
    29         -230.893             0.001            0.001 
    30         -230.645             0.001            0.001 
    31         -230.740             0.001            0.001 
    32         -230.684             0.001            0.001 
    33         -230.751             0.001            0.001 
    34         -230.813             0.001            0.001 
    35         -230.640             0.001            0.001 
    36         -230.645             0.001            0.001 
    37         -230.618             0.001            0.001 
    38         -230.700             0.001            0.001 
    39         -230.818             0.001            0.001 
    40         -230.860             0.001            0.001 
    41         -230.833             0.001            0.000 
    42         -230.660             0.000            0.000 
    43         -230.621             0.000            0.000 
    44         -230.568             0.000            0.000 
    45         -230.683             0.000            0.000 
    46         -230.800             0.000            0.000 
    47         -230.922             0.000            0.000 
    48         -230.727             0.000            0.000 
    49         -230.695             0.000            0.000 
    50         -230.735             0.000            0.000 
    51         -230.492             0.000            0.000 
    52         -230.660             0.000            0.000 
    53         -230.641             0.000            0.000 
    54         -230.636             0.000            0.000 
    55         -230.945             0.000            0.000 
    56         -230.867             0.000            0.000 
    57         -230.897             0.000            0.000 
    58         -230.846             0.000            0.000 
    59         -230.791             0.000            0.000 
    60         -230.737             0.000            0.000 
    61         -230.839             0.000            0.000 
    62         -230.854             0.000            0.000 
    63         -230.745             0.000            0.000 
    64         -230.972             0.000            0.000 
    65         -230.843             0.000            0.000 
    66         -230.734             0.000            0.000 
    67         -230.776             0.000            0.000 
    68         -230.650             0.000            0.000 
    69         -230.815             0.000            0.000 
    70         -230.924             0.000            0.000 
    71         -230.917             0.000            0.000 
    72         -230.688             0.000            0.000 
    73         -230.492             0.000            0.000 
    74         -230.567             0.000            0.000 
    75         -230.703             0.000            0.000 
    76         -230.743             0.000            0.000 
    77         -230.635             0.000            0.000 
    78         -230.818             0.000            0.000 
    79         -231.008             0.001            0.000 
    80         -230.974             0.001            0.000 
    81         -230.872             0.001            0.000 
    82         -230.799             0.001            0.000 
    83         -230.675             0.001            0.001 
    84         -230.753             0.000            0.000 
    85         -230.725             0.000            0.000 
    86         -231.020             0.001            0.000 
    87         -230.724             0.001            0.001 
    88         -230.784             0.001            0.000 
    89         -230.662             0.001            0.000 
    90         -230.569             0.001            0.000 
    91         -230.541             0.001            0.000 
    92         -230.834             0.001            0.000 
    93         -230.865             0.001            0.000 
    94         -230.741             0.001            0.000 
    95         -230.726             0.001            0.000 
    96         -230.612             0.001            0.000 
    97         -230.698             0.001            0.000 
    98         -230.631             0.000            0.000 
    99         -230.819             0.000            0.000 
   100         -230.710             0.001            0.000 
   101         -230.675             0.000            0.000 
   102         -230.627             0.000            0.000 
   103         -230.743             0.000            0.000 
   104         -230.604             0.000            0.000 
   105         -230.610             0.000            0.000 
   106         -230.637             0.000            0.000 
   107         -230.783             0.000            0.000 
   108         -230.806             0.000            0.000 
   109         -230.592             0.000            0.000 
   110         -230.671             0.000            0.000 
   111         -230.699             0.000            0.000 
   112         -230.685             0.000            0.000 
   113         -230.697             0.000            0.000 
   114         -230.731             0.000            0.000 
   115         -230.710             0.000            0.000 
   116         -230.744             0.000            0.000 
   117         -230.739             0.000            0.000 
   118         -230.678             0.000            0.000 
   119         -230.836             0.000            0.000 
   120         -230.664             0.000            0.000 
   121         -230.682             0.000            0.000 
   122         -230.766             0.000            0.000 
   123         -230.636             0.000            0.000 
   124         -230.772             0.000            0.000 
   125         -230.848             0.000            0.000 
   126         -230.844             0.000            0.000 
   127         -230.824             0.000            0.000 
   128         -230.746             0.000            0.000 
   129         -230.943             0.000            0.000 
   130         -230.645             0.000            0.000 
   131         -230.670             0.000            0.000 
   132         -230.696             0.000            0.000 
   133         -230.730             0.000            0.000 
   134         -230.750             0.000            0.000 
   135         -230.624             0.000            0.000 
   136         -230.571             0.000            0.000 
   137         -230.654             0.000            0.000 
   138         -230.556             0.000            0.000 
   139         -230.741             0.000            0.000 
   140         -231.163             0.000            0.000 
   141         -230.891             0.001            0.000 
   142         -230.510             0.001            0.000 
   143         -231.130             0.001            0.000 
   144         -230.724             0.001            0.000 
   145         -230.796             0.001            0.000 
   146         -231.028             0.001            0.001 
   147         -231.082             0.001            0.001 
   148         -230.604             0.001            0.001 
   149         -230.613             0.001            0.001 
   150         -230.591             0.001            0.000 
   151         -230.914             0.001            0.001 
   152         -230.708             0.001            0.001 
   153         -230.836             0.001            0.001 
   154         -230.717             0.001            0.001 
   155         -230.771             0.001            0.001 
   156         -230.641             0.001            0.001 
   157         -230.940             0.001            0.001 
   158         -230.454             0.001            0.001 
   159         -230.618             0.001            0.001 
   160         -230.730             0.001            0.001 
   161         -230.682             0.001            0.001 
   162         -230.834             0.001            0.001 
   163         -230.747             0.001            0.001 
   164         -230.640             0.001            0.001 
   165         -230.734             0.001            0.001 
   166         -230.883             0.001            0.001 
   167         -230.910             0.001            0.001 
   168         -230.660             0.001            0.001 
   169         -230.827             0.001            0.001 
   170         -230.685             0.001            0.001 
   171         -230.582             0.001            0.001 
   172         -230.703             0.001            0.001 
   173         -230.663             0.001            0.001 
   174         -230.713             0.001            0.001 
   175         -230.725             0.001            0.001 
   176         -230.552             0.001            0.001 
   177         -230.529             0.001            0.000 
   178         -230.569             0.000            0.000 
   179         -230.694             0.000            0.000 
   180         -230.684             0.000            0.000 
   181         -230.737             0.000            0.000 
   182         -230.691             0.000            0.000 
   183         -230.570             0.000            0.000 
   184         -230.653             0.000            0.000 
   185         -230.668             0.000            0.000 
   186         -231.005             0.000            0.000 
   187         -230.691             0.000            0.000 
   188         -230.639             0.000            0.000 
   189         -230.722             0.000            0.000 
   190         -230.785             0.000            0.000 
   191         -230.652             0.000            0.000 
   192         -230.634             0.000            0.000 
   193         -230.607             0.000            0.000 
   194         -230.720             0.000            0.000 
   195         -230.721             0.000            0.000 
   196         -230.601             0.000            0.000 
   197         -230.729             0.000            0.000 
   198         -230.778             0.000            0.000 
   199         -230.571             0.000            0.000 
   200         -230.729             0.000            0.000 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  1.3 seconds.
[[1]]
[[1]]$w
      [,1]
 [1,]    1
 [2,]    1
 [3,]    1
 [4,]    1
 [5,]    1
 [6,]    1
 [7,]    1
 [8,]    1
 [9,]    1
[10,]    1
[11,]    1
[12,]    1
[13,]    1
[14,]    1
[15,]    1
[16,]    1
[17,]    1
[18,]    1
[19,]    1
[20,]    1
[21,]    1
[22,]    1

[[1]]$tau
[1] 0.3664311

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -232.266
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412182002-1-996435.csv\n"
init_taus from clustering  0.00908503941346307 init_taus from clustering  0.726883273264501Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000279 seconds 
1000 transitions using 10 leapfrog steps per transition would take 2.79 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -294.675             1.000            1.000 
     2         -279.235             0.528            1.000 
     3         -271.597             0.361            0.055 
     4         -261.940             0.280            0.055 
     5         -257.751             0.227            0.037 
     6         -257.887             0.190            0.037 
     7         -255.114             0.164            0.028 
     8         -252.183             0.145            0.028 
     9         -252.366             0.129            0.016 
    10         -250.550             0.117            0.016 
    11         -249.864             0.106            0.012 
    12         -249.878             0.098            0.012 
    13         -248.884             0.090            0.011 
    14         -247.196             0.084            0.011 
    15         -247.335             0.079            0.007 
    16         -245.662             0.074            0.007 
    17         -246.280             0.070            0.007 
    18         -245.804             0.066            0.007 
    19         -244.246             0.063            0.007 
    20         -244.964             0.060            0.007 
    21         -243.663             0.010            0.006 
    22         -244.550             0.008            0.005 
    23         -243.937             0.007            0.004 
    24         -243.455             0.005            0.004 
    25         -243.118             0.004            0.003 
    26         -243.609             0.004            0.003 
    27         -242.487             0.004            0.003 
    28         -242.078             0.003            0.003 
    29         -241.657             0.003            0.003 
    30         -241.731             0.003            0.003 
    31         -242.038             0.003            0.003 
    32         -242.562             0.003            0.003 
    33         -242.103             0.003            0.002 
    34         -241.770             0.003            0.002 
    35         -241.822             0.003            0.002 
    36         -239.974             0.003            0.002 
    37         -240.255             0.003            0.002 
    38         -240.641             0.003            0.002 
    39         -241.105             0.002            0.002 
    40         -240.118             0.002            0.002 
    41         -240.765             0.002            0.002 
    42         -239.582             0.002            0.002 
    43         -239.504             0.002            0.002 
    44         -240.765             0.002            0.002 
    45         -240.475             0.002            0.002 
    46         -239.710             0.002            0.002 
    47         -239.124             0.002            0.002 
    48         -239.846             0.002            0.002 
    49         -239.831             0.002            0.002 
    50         -239.951             0.002            0.002 
    51         -239.327             0.002            0.002 
    52         -239.257             0.002            0.002 
    53         -239.610             0.002            0.002 
    54         -239.877             0.002            0.002 
    55         -239.704             0.002            0.002 
    56         -239.476             0.002            0.002 
    57         -240.235             0.002            0.002 
    58         -239.005             0.002            0.002 
    59         -239.164             0.002            0.002 
    60         -238.884             0.002            0.001 
    61         -238.752             0.002            0.001 
    62         -238.800             0.002            0.001 
    63         -238.754             0.002            0.001 
    64         -239.242             0.002            0.001 
    65         -239.027             0.002            0.001 
    66         -239.028             0.001            0.001 
    67         -238.870             0.001            0.001 
    68         -238.867             0.001            0.001 
    69         -239.101             0.001            0.001 
    70         -239.159             0.001            0.001 
    71         -239.199             0.001            0.001 
    72         -238.719             0.001            0.001 
    73         -238.810             0.001            0.001 
    74         -239.018             0.001            0.001 
    75         -238.989             0.001            0.001 
    76         -239.544             0.001            0.001 
    77         -239.169             0.001            0.001 
    78         -238.997             0.001            0.001 
    79         -239.205             0.001            0.001 
    80         -239.484             0.001            0.001 
    81         -238.939             0.001            0.001 
    82         -239.625             0.001            0.001 
    83         -238.831             0.001            0.001 
    84         -238.771             0.001            0.001 
    85         -239.485             0.001            0.001 
    86         -239.062             0.001            0.001 
    87         -238.310             0.001            0.001 
    88         -238.477             0.001            0.001 
    89         -238.898             0.001            0.002 
    90         -237.688             0.002            0.002 
    91         -239.103             0.002            0.002 
    92         -238.421             0.002            0.002 
    93         -239.050             0.002            0.002 
    94         -238.582             0.002            0.002 
    95         -239.124             0.002            0.002 
    96         -238.917             0.002            0.002 
    97         -239.214             0.002            0.002 
    98         -238.835             0.002            0.002 
    99         -238.647             0.002            0.002 
   100         -238.673             0.002            0.002 
   101         -239.073             0.002            0.002 
   102         -238.400             0.002            0.002 
   103         -239.034             0.002            0.002 
   104         -239.400             0.002            0.002 
   105         -238.877             0.002            0.002 
   106         -238.876             0.002            0.002 
   107         -239.468             0.002            0.002 
   108         -238.630             0.002            0.002 
   109         -238.488             0.002            0.002 
   110         -238.249             0.002            0.002 
   111         -238.828             0.002            0.002 
   112         -238.330             0.002            0.002 
   113         -238.114             0.002            0.002 
   114         -239.005             0.002            0.002 
   115         -238.525             0.002            0.002 
   116         -238.874             0.002            0.002 
   117         -238.860             0.002            0.002 
   118         -238.356             0.002            0.002 
   119         -238.295             0.002            0.002 
   120         -238.406             0.002            0.002 
   121         -237.902             0.002            0.002 
   122         -238.452             0.002            0.002 
   123         -238.881             0.002            0.002 
   124         -239.239             0.002            0.002 
   125         -238.802             0.002            0.002 
   126         -238.343             0.002            0.002 
   127         -238.146             0.002            0.002 
   128         -237.847             0.002            0.002 
   129         -238.274             0.002            0.002 
   130         -239.098             0.002            0.002 
   131         -238.538             0.002            0.002 
   132         -238.721             0.002            0.002 
   133         -238.489             0.002            0.002 
   134         -238.309             0.001            0.002 
   135         -238.305             0.001            0.001 
   136         -237.868             0.001            0.002 
   137         -238.564             0.002            0.002 
   138         -238.011             0.002            0.002 
   139         -238.198             0.002            0.002 
   140         -238.959             0.002            0.002 
   141         -238.615             0.002            0.002 
   142         -238.500             0.002            0.002 
   143         -238.469             0.002            0.001 
   144         -237.612             0.002            0.002 
   145         -238.297             0.002            0.002 
   146         -238.414             0.002            0.001 
   147         -238.641             0.002            0.001 
   148         -238.392             0.002            0.001 
   149         -238.154             0.002            0.001 
   150         -238.275             0.001            0.001 
   151         -238.496             0.001            0.001 
   152         -238.838             0.001            0.001 
   153         -238.164             0.001            0.001 
   154         -238.886             0.002            0.001 
   155         -238.365             0.002            0.001 
   156         -238.598             0.002            0.001 
   157         -237.527             0.002            0.001 
   158         -238.701             0.002            0.001 
   159         -238.737             0.002            0.001 
   160         -237.687             0.002            0.001 
   161         -239.004             0.002            0.001 
   162         -238.446             0.002            0.002 
   163         -238.125             0.002            0.002 
   164         -238.263             0.002            0.001 
   165         -238.230             0.002            0.001 
   166         -238.430             0.002            0.001 
   167         -238.330             0.002            0.001 
   168         -237.368             0.002            0.001 
   169         -237.655             0.002            0.001 
   170         -238.216             0.002            0.002 
   171         -237.928             0.002            0.002 
   172         -238.245             0.002            0.002 
   173         -239.184             0.002            0.002 
   174         -238.729             0.002            0.002 
   175         -238.460             0.002            0.001 
   176         -238.443             0.002            0.001 
   177         -237.586             0.002            0.001 
   178         -238.148             0.002            0.001 
   179         -238.650             0.002            0.002 
   180         -238.373             0.002            0.001 
   181         -238.153             0.002            0.001 
   182         -237.522             0.002            0.001 
   183         -238.700             0.002            0.001 
   184         -238.096             0.002            0.002 
   185         -239.307             0.002            0.002 
   186         -237.987             0.002            0.002 
   187         -238.395             0.002            0.002 
   188         -237.946             0.002            0.002 
   189         -239.052             0.003            0.002 
   190         -238.386             0.003            0.002 
   191         -238.280             0.003            0.002 
   192         -238.550             0.003            0.002 
   193         -238.532             0.002            0.002 
   194         -238.156             0.002            0.002 
   195         -238.548             0.002            0.002 
   196         -239.061             0.002            0.002 
   197         -238.257             0.002            0.002 
   198         -237.800             0.002            0.002 
   199         -238.689             0.002            0.002 
   200         -237.420             0.003            0.003 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  2.4 seconds.
[[1]]
[[1]]$w
             [,1]         [,2]
 [1,] 0.005266585 0.9947334152
 [2,] 0.999750575 0.0002494247
 [3,] 0.999750575 0.0002494247
 [4,] 0.999750575 0.0002494247
 [5,] 0.999750575 0.0002494247
 [6,] 0.999750575 0.0002494247
 [7,] 0.175926999 0.8240730009
 [8,] 0.175926999 0.8240730009
 [9,] 0.008400888 0.9915991117
[10,] 0.070689155 0.9293108448
[11,] 0.008400888 0.9915991117
[12,] 0.999750575 0.0002494247
[13,] 0.999750575 0.0002494247
[14,] 0.999750575 0.0002494247
[15,] 0.008400888 0.9915991117
[16,] 0.999750575 0.0002494247
[17,] 0.070689155 0.9293108448
[18,] 0.999750575 0.0002494247
[19,] 0.411255199 0.5887448012
[20,] 0.999750575 0.0002494247
[21,] 0.999750575 0.0002494247
[22,] 0.008577088 0.9914229117

[[1]]$tau
[1] 0.009085039 0.726883273

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -271.597
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000249 seconds 
1000 transitions using 10 leapfrog steps per transition would take 2.49 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -296.338             1.000            1.000 
     2         -285.355             0.519            1.000 
     3         -278.489             0.354            0.038 
     4         -271.018             0.273            0.038 
     5         -267.324             0.221            0.028 
     6         -266.044             0.185            0.028 
     7         -264.263             0.159            0.025 
     8         -262.668             0.140            0.025 
     9         -261.091             0.125            0.014 
    10         -259.474             0.113            0.014 
    11         -257.361             0.104            0.008 
    12         -256.539             0.095            0.008 
    13         -254.388             0.089            0.008 
    14         -254.894             0.083            0.008 
    15         -252.317             0.078            0.008 
    16         -252.834             0.073            0.008 
    17         -252.191             0.069            0.007 
    18         -248.939             0.066            0.008 
    19         -250.324             0.063            0.007 
    20         -249.648             0.060            0.007 
    21         -247.945             0.010            0.007 
    22         -247.816             0.008            0.006 
    23         -247.692             0.007            0.006 
    24         -245.938             0.006            0.006 
    25         -247.162             0.005            0.006 
    26         -247.116             0.005            0.006 
    27         -245.441             0.005            0.006 
    28         -245.141             0.005            0.006 
    29         -245.148             0.005            0.005 
    30         -244.164             0.005            0.004 
    31         -246.129             0.005            0.004 
    32         -244.036             0.005            0.005 
    33         -244.451             0.004            0.004 
    34         -243.862             0.004            0.004 
    35         -245.234             0.004            0.004 
    36         -243.091             0.005            0.005 
    37         -242.332             0.005            0.005 
    38         -242.375             0.004            0.004 
    39         -243.977             0.004            0.004 
    40         -242.729             0.004            0.005 
    41         -242.054             0.004            0.004 
    42         -241.889             0.004            0.004 
    43         -240.869             0.004            0.004 
    44         -243.177             0.004            0.004 
    45         -242.457             0.004            0.004 
    46         -242.615             0.004            0.004 
    47         -242.208             0.004            0.003 
    48         -242.012             0.004            0.003 
    49         -241.341             0.004            0.003 
    50         -241.162             0.004            0.003 
    51         -241.110             0.003            0.003 
    52         -241.472             0.003            0.003 
    53         -241.028             0.003            0.003 
    54         -240.629             0.003            0.003 
    55         -240.360             0.003            0.002 
    56         -240.067             0.002            0.002 
    57         -239.631             0.002            0.002 
    58         -239.490             0.002            0.002 
    59         -240.264             0.002            0.002 
    60         -241.394             0.002            0.002 
    61         -239.606             0.002            0.002 
    62         -240.996             0.003            0.002 
    63         -239.813             0.003            0.002 
    64         -239.583             0.002            0.002 
    65         -239.983             0.002            0.002 
    66         -240.006             0.002            0.002 
    67         -239.072             0.002            0.002 
    68         -239.491             0.002            0.002 
    69         -239.973             0.002            0.002 
    70         -239.283             0.002            0.002 
    71         -239.349             0.002            0.002 
    72         -239.152             0.002            0.002 
    73         -238.561             0.002            0.002 
    74         -239.563             0.003            0.002 
    75         -239.240             0.003            0.002 
    76         -238.507             0.003            0.002 
    77         -239.027             0.003            0.002 
    78         -239.504             0.003            0.002 
    79         -239.128             0.003            0.002 
    80         -238.693             0.003            0.002 
    81         -239.221             0.002            0.002 
    82         -239.440             0.002            0.002 
    83         -238.830             0.002            0.002 
    84         -238.945             0.002            0.002 
    85         -238.085             0.002            0.002 
    86         -240.371             0.002            0.002 
    87         -239.536             0.002            0.002 
    88         -239.347             0.002            0.002 
    89         -238.559             0.002            0.002 
    90         -238.579             0.002            0.002 
    91         -239.019             0.002            0.002 
    92         -238.442             0.002            0.002 
    93         -238.982             0.002            0.002 
    94         -238.888             0.002            0.002 
    95         -239.085             0.002            0.002 
    96         -238.215             0.002            0.002 
    97         -239.395             0.002            0.002 
    98         -238.950             0.002            0.002 
    99         -238.983             0.002            0.002 
   100         -238.826             0.002            0.002 
   101         -238.051             0.002            0.002 
   102         -238.191             0.002            0.002 
   103         -239.273             0.002            0.002 
   104         -238.103             0.003            0.002 
   105         -238.033             0.002            0.002 
   106         -238.601             0.002            0.002 
   107         -239.209             0.002            0.002 
   108         -238.132             0.002            0.002 
   109         -238.923             0.002            0.002 
   110         -238.361             0.002            0.002 
   111         -238.839             0.002            0.002 
   112         -239.201             0.002            0.002 
   113         -239.171             0.002            0.002 
   114         -238.377             0.002            0.002 
   115         -238.109             0.002            0.002 
   116         -238.902             0.002            0.002 
   117         -238.399             0.002            0.002 
   118         -238.081             0.002            0.002 
   119         -238.723             0.002            0.002 
   120         -238.811             0.002            0.002 
   121         -238.505             0.002            0.002 
   122         -237.914             0.002            0.002 
   123         -238.543             0.002            0.002 
   124         -238.510             0.002            0.002 
   125         -237.638             0.002            0.002 
   126         -239.537             0.002            0.002 
   127         -238.654             0.002            0.002 
   128         -238.814             0.002            0.002 
   129         -238.575             0.002            0.002 
   130         -238.247             0.002            0.002 
   131         -238.358             0.002            0.002 
   132         -238.896             0.002            0.002 
   133         -238.395             0.002            0.002 
   134         -238.950             0.002            0.002 
   135         -238.352             0.002            0.002 
   136         -238.736             0.002            0.002 
   137         -237.474             0.002            0.002 
   138         -238.897             0.003            0.002 
   139         -238.138             0.003            0.002 
   140         -238.684             0.003            0.002 
   141         -238.182             0.003            0.002 
   142         -238.629             0.003            0.002 
   143         -238.703             0.003            0.002 
   144         -238.707             0.003            0.002 
   145         -238.472             0.002            0.002 
   146         -238.568             0.002            0.002 
   147         -237.722             0.002            0.002 
   148         -238.443             0.002            0.002 
   149         -237.540             0.002            0.002 
   150         -238.903             0.002            0.002 
   151         -238.486             0.003            0.002 
   152         -237.972             0.003            0.002 
   153         -237.841             0.002            0.002 
   154         -238.299             0.002            0.002 
   155         -238.164             0.002            0.002 
   156         -238.247             0.002            0.002 
   157         -238.720             0.002            0.002 
   158         -237.682             0.002            0.002 
   159         -237.939             0.002            0.002 
   160         -238.129             0.002            0.002 
   161         -238.428             0.002            0.002 
   162         -238.067             0.002            0.002 
   163         -238.161             0.002            0.002 
   164         -239.231             0.002            0.002 
   165         -238.339             0.002            0.002 
   166         -238.169             0.002            0.002 
   167         -238.763             0.002            0.002 
   168         -238.771             0.002            0.002 
   169         -238.655             0.002            0.002 
   170         -239.476             0.002            0.002 
   171         -239.180             0.002            0.001 
   172         -238.295             0.002            0.001 
   173         -238.129             0.002            0.001 
   174         -238.468             0.002            0.001 
   175         -238.908             0.002            0.001 
   176         -237.889             0.002            0.002 
   177         -237.965             0.002            0.001 
   178         -237.348             0.002            0.001 
   179         -237.951             0.002            0.002 
   180         -238.245             0.002            0.002 
   181         -238.698             0.002            0.002 
   182         -238.292             0.002            0.002 
   183         -238.355             0.002            0.002 
   184         -238.271             0.002            0.002 
   185         -238.148             0.002            0.001 
   186         -238.679             0.002            0.002 
   187         -238.622             0.002            0.001 
   188         -238.281             0.002            0.001 
   189         -238.540             0.002            0.001 
   190         -238.030             0.002            0.001 
   191         -238.208             0.002            0.001 
   192         -237.916             0.001            0.001 
   193         -238.596             0.002            0.001 
   194         -238.982             0.002            0.002 
   195         -237.807             0.002            0.002 
   196         -237.858             0.002            0.001 
   197         -238.185             0.002            0.001 
   198         -238.975             0.002            0.001 
   199         -238.122             0.002            0.001 
   200         -237.733             0.002            0.002 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  2.4 seconds.
[[1]]
[[1]]$w
             [,1]         [,2]
 [1,] 0.005266585 0.9947334152
 [2,] 0.999750575 0.0002494247
 [3,] 0.999750575 0.0002494247
 [4,] 0.999750575 0.0002494247
 [5,] 0.999750575 0.0002494247
 [6,] 0.999750575 0.0002494247
 [7,] 0.175926999 0.8240730009
 [8,] 0.175926999 0.8240730009
 [9,] 0.008400888 0.9915991117
[10,] 0.070689155 0.9293108448
[11,] 0.008400888 0.9915991117
[12,] 0.999750575 0.0002494247
[13,] 0.999750575 0.0002494247
[14,] 0.999750575 0.0002494247
[15,] 0.008400888 0.9915991117
[16,] 0.999750575 0.0002494247
[17,] 0.070689155 0.9293108448
[18,] 0.999750575 0.0002494247
[19,] 0.411255199 0.5887448012
[20,] 0.999750575 0.0002494247
[21,] 0.999750575 0.0002494247
[22,] 0.008577088 0.9914229117

[[1]]$tau
[1] 0.070000 0.608887

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -278.489
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412182002-1-71f9de.csv\n"
init_taus from clustering  0.0010570360937082 init_taus from clustering  0.919157235309572 init_taus from clustering  0.574962520625049Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000342 seconds 
1000 transitions using 10 leapfrog steps per transition would take 3.42 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -338.462             1.000            1.000 
     2         -319.339             0.530            1.000 
     3         -307.769             0.366            0.060 
     4         -297.906             0.283            0.060 
     5         -291.207             0.231            0.038 
     6         -286.009             0.195            0.038 
     7         -279.956             0.170            0.033 
     8         -274.005             0.152            0.033 
     9         -274.983             0.135            0.023 
    10         -268.898             0.124            0.023 
    11         -268.497             0.113            0.023 
    12         -267.909             0.104            0.023 
    13         -263.975             0.097            0.022 
    14         -263.549             0.090            0.022 
    15         -260.256             0.085            0.022 
    16         -259.540             0.080            0.022 
    17         -258.069             0.075            0.018 
    18         -258.184             0.071            0.018 
    19         -256.093             0.068            0.015 
    20         -257.036             0.065            0.015 
    21         -255.215             0.015            0.013 
    22         -252.627             0.013            0.010 
    23         -254.746             0.011            0.008 
    24         -253.170             0.010            0.008 
    25         -254.855             0.009            0.007 
    26         -253.557             0.008            0.007 
    27         -252.162             0.008            0.006 
    28         -250.140             0.007            0.006 
    29         -251.793             0.007            0.007 
    30         -250.036             0.006            0.007 
    31         -250.084             0.006            0.007 
    32         -250.554             0.006            0.007 
    33         -250.499             0.005            0.006 
    34         -249.975             0.005            0.006 
    35         -249.120             0.005            0.006 
    36         -248.744             0.005            0.006 
    37         -248.568             0.005            0.006 
    38         -248.236             0.005            0.006 
    39         -247.855             0.004            0.005 
    40         -246.990             0.004            0.005 
    41         -247.757             0.004            0.004 
    42         -246.910             0.004            0.003 
    43         -247.537             0.004            0.003 
    44         -248.837             0.003            0.003 
    45         -247.150             0.003            0.003 
    46         -247.720             0.003            0.003 
    47         -246.494             0.003            0.003 
    48         -246.365             0.003            0.003 
    49         -246.917             0.003            0.002 
    50         -246.553             0.002            0.002 
    51         -246.355             0.002            0.002 
    52         -246.139             0.002            0.002 
    53         -245.440             0.003            0.002 
    54         -245.862             0.003            0.002 
    55         -245.389             0.002            0.002 
    56         -244.258             0.003            0.002 
    57         -244.913             0.003            0.003 
    58         -244.009             0.003            0.003 
    59         -245.841             0.003            0.003 
    60         -244.967             0.003            0.003 
    61         -246.049             0.003            0.003 
    62         -245.521             0.003            0.003 
    63         -245.184             0.003            0.003 
    64         -244.989             0.003            0.002 
    65         -244.995             0.003            0.002 
    66         -244.774             0.002            0.002 
    67         -244.230             0.002            0.002 
    68         -245.012             0.002            0.002 
    69         -245.361             0.002            0.002 
    70         -244.002             0.003            0.002 
    71         -245.808             0.003            0.003 
    72         -243.550             0.003            0.003 
    73         -243.876             0.003            0.003 
    74         -244.315             0.003            0.003 
    75         -244.669             0.003            0.003 
    76         -243.297             0.003            0.003 
    77         -244.430             0.003            0.003 
    78         -244.508             0.003            0.002 
    79         -244.994             0.003            0.002 
    80         -244.564             0.003            0.002 
    81         -243.333             0.003            0.002 
    82         -243.228             0.003            0.002 
    83         -243.615             0.003            0.002 
    84         -244.580             0.003            0.002 
    85         -242.832             0.003            0.002 
    86         -243.652             0.003            0.003 
    87         -244.382             0.004            0.003 
    88         -243.544             0.004            0.003 
    89         -243.326             0.004            0.003 
    90         -243.952             0.003            0.003 
    91         -244.679             0.003            0.003 
    92         -243.627             0.003            0.003 
    93         -243.067             0.003            0.003 
    94         -243.165             0.003            0.003 
    95         -242.517             0.003            0.003 
    96         -243.975             0.003            0.003 
    97         -244.376             0.003            0.003 
    98         -243.332             0.003            0.003 
    99         -244.128             0.003            0.003 
   100         -243.345             0.003            0.003 
   101         -242.632             0.003            0.003 
   102         -243.085             0.003            0.003 
   103         -242.292             0.003            0.003 
   104         -243.178             0.003            0.003 
   105         -243.788             0.003            0.003 
   106         -243.707             0.003            0.003 
   107         -243.255             0.003            0.003 
   108         -243.962             0.003            0.003 
   109         -243.417             0.003            0.003 
   110         -243.040             0.003            0.003 
   111         -242.040             0.003            0.003 
   112         -242.915             0.003            0.003 
   113         -244.222             0.003            0.003 
   114         -242.470             0.003            0.003 
   115         -243.640             0.003            0.003 
   116         -243.444             0.003            0.003 
   117         -243.014             0.003            0.003 
   118         -242.943             0.003            0.003 
   119         -244.392             0.003            0.003 
   120         -242.577             0.003            0.003 
   121         -243.163             0.003            0.003 
   122         -243.087             0.003            0.003 
   123         -242.438             0.003            0.003 
   124         -244.477             0.003            0.003 
   125         -243.606             0.003            0.003 
   126         -243.581             0.003            0.003 
   127         -243.802             0.003            0.003 
   128         -242.727             0.003            0.004 
   129         -242.639             0.003            0.004 
   130         -242.798             0.003            0.004 
   131         -242.665             0.003            0.003 
   132         -243.307             0.003            0.003 
   133         -243.829             0.003            0.002 
   134         -242.669             0.003            0.002 
   135         -243.282             0.003            0.002 
   136         -243.028             0.003            0.002 
   137         -243.760             0.003            0.003 
   138         -242.841             0.003            0.003 
   139         -242.089             0.003            0.003 
   140         -242.607             0.002            0.003 
   141         -242.821             0.002            0.003 
   142         -243.420             0.003            0.003 
   143         -243.486             0.002            0.002 
   144         -243.495             0.002            0.002 
   145         -243.254             0.002            0.002 
   146         -243.378             0.002            0.002 
   147         -241.752             0.002            0.002 
   148         -241.957             0.002            0.002 
   149         -243.723             0.002            0.002 
   150         -243.432             0.002            0.002 
   151         -242.985             0.002            0.002 
   152         -243.534             0.002            0.002 
   153         -243.328             0.002            0.002 
   154         -243.466             0.002            0.002 
   155         -243.363             0.002            0.001 
   156         -242.544             0.002            0.002 
   157         -243.329             0.002            0.002 
   158         -242.545             0.002            0.002 
   159         -241.314             0.002            0.002 
   160         -242.775             0.002            0.002 
   161         -243.373             0.002            0.002 
   162         -242.863             0.002            0.002 
   163         -241.656             0.003            0.002 
   164         -242.515             0.003            0.002 
   165         -241.606             0.003            0.003 
   166         -242.415             0.003            0.003 
   167         -241.853             0.003            0.003 
   168         -242.491             0.003            0.003 
   169         -243.005             0.003            0.003 
   170         -243.137             0.003            0.003 
   171         -241.486             0.003            0.003 
   172         -242.070             0.003            0.003 
   173         -242.333             0.003            0.003 
   174         -242.052             0.003            0.003 
   175         -242.127             0.003            0.003 
   176         -242.625             0.003            0.003 
   177         -242.988             0.003            0.002 
   178         -243.119             0.003            0.002 
   179         -242.921             0.003            0.002 
   180         -242.373             0.002            0.002 
   181         -243.295             0.002            0.002 
   182         -242.735             0.002            0.002 
   183         -242.030             0.002            0.002 
   184         -243.093             0.002            0.002 
   185         -241.853             0.002            0.002 
   186         -243.337             0.003            0.002 
   187         -242.208             0.003            0.002 
   188         -242.761             0.003            0.002 
   189         -242.783             0.003            0.002 
   190         -241.815             0.003            0.002 
   191         -242.645             0.003            0.002 
   192         -242.711             0.002            0.002 
   193         -242.033             0.003            0.002 
   194         -242.455             0.003            0.002 
   195         -242.704             0.003            0.002 
   196         -242.142             0.003            0.002 
   197         -241.607             0.003            0.002 
   198         -243.905             0.003            0.003 
   199         -242.123             0.003            0.003 
   200         -242.053             0.003            0.003 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  3.5 seconds.
[[1]]
[[1]]$w
             [,1]         [,2]        [,3]
 [1,] 0.020953673 0.6835742901 0.295472037
 [2,] 0.999796967 0.0001008396 0.000102193
 [3,] 0.999796967 0.0001008396 0.000102193
 [4,] 0.999796967 0.0001008396 0.000102193
 [5,] 0.999796967 0.0001008396 0.000102193
 [6,] 0.999796967 0.0001008396 0.000102193
 [7,] 0.021451519 0.0303735095 0.948174972
 [8,] 0.021451519 0.0303735095 0.948174972
 [9,] 0.016599207 0.1148158695 0.868584923
[10,] 0.006379114 0.9588370582 0.034783827
[11,] 0.016599207 0.1148158695 0.868584923
[12,] 0.999796967 0.0001008396 0.000102193
[13,] 0.999796967 0.0001008396 0.000102193
[14,] 0.999796967 0.0001008396 0.000102193
[15,] 0.016599207 0.1148158695 0.868584923
[16,] 0.999796967 0.0001008396 0.000102193
[17,] 0.006379114 0.9588370582 0.034783827
[18,] 0.999796967 0.0001008396 0.000102193
[19,] 0.147150095 0.0870077701 0.765842135
[20,] 0.999796967 0.0001008396 0.000102193
[21,] 0.999796967 0.0001008396 0.000102193
[22,] 0.017165642 0.7676649451 0.215169413

[[1]]$tau
[1] 0.001057036 0.880000000 0.574962521

[[1]]$phi
[1] 0.3333333 0.3333333 0.3333333

[[1]]$kappa
[1] 5


ELBO for this run: -307.769
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000348 seconds 
1000 transitions using 10 leapfrog steps per transition would take 3.48 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -361.951             1.000            1.000 
     2         -338.980             0.534            1.000 
     3         -320.465             0.375            0.068 
     4         -312.345             0.288            0.068 
     5         -302.291             0.237            0.058 
     6         -293.969             0.202            0.058 
     7         -287.843             0.176            0.033 
     8         -286.806             0.155            0.033 
     9         -282.863             0.139            0.028 
    10         -276.858             0.127            0.028 
    11         -275.888             0.116            0.026 
    12         -273.300             0.107            0.026 
    13         -271.243             0.100            0.022 
    14         -271.748             0.093            0.022 
    15         -267.329             0.088            0.021 
    16         -265.536             0.082            0.021 
    17         -266.448             0.078            0.017 
    18         -263.162             0.074            0.017 
    19         -261.682             0.071            0.014 
    20         -259.723             0.067            0.014 
    21         -259.639             0.017            0.012 
    22         -258.901             0.014            0.009 
    23         -258.631             0.011            0.008 
    24         -258.370             0.010            0.008 
    25         -255.643             0.009            0.008 
    26         -256.289             0.008            0.007 
    27         -255.255             0.007            0.006 
    28         -255.138             0.007            0.006 
    29         -255.042             0.006            0.004 
    30         -252.155             0.005            0.004 
    31         -254.276             0.006            0.006 
    32         -252.896             0.006            0.005 
    33         -252.049             0.005            0.004 
    34         -251.872             0.005            0.004 
    35         -252.837             0.005            0.004 
    36         -250.036             0.005            0.004 
    37         -250.004             0.005            0.004 
    38         -251.277             0.004            0.004 
    39         -250.899             0.004            0.003 
    40         -250.700             0.004            0.003 
    41         -249.781             0.004            0.003 
    42         -251.242             0.004            0.004 
    43         -249.743             0.004            0.004 
    44         -248.551             0.005            0.004 
    45         -249.772             0.004            0.004 
    46         -248.519             0.004            0.005 
    47         -248.180             0.004            0.005 
    48         -248.345             0.004            0.005 
    49         -248.072             0.004            0.005 
    50         -247.572             0.004            0.004 
    51         -248.354             0.004            0.004 
    52         -247.090             0.004            0.004 
    53         -246.427             0.003            0.004 
    54         -247.759             0.004            0.004 
    55         -247.317             0.004            0.004 
    56         -246.297             0.003            0.004 
    57         -246.700             0.003            0.004 
    58         -245.762             0.003            0.004 
    59         -248.861             0.004            0.004 
    60         -245.944             0.004            0.004 
    61         -245.563             0.004            0.004 
    62         -246.343             0.004            0.004 
    63         -245.479             0.004            0.004 
    64         -245.954             0.004            0.003 
    65         -246.004             0.004            0.003 
    66         -245.458             0.003            0.003 
    67         -245.691             0.003            0.003 
    68         -245.598             0.003            0.003 
    69         -245.349             0.003            0.003 
    70         -245.822             0.003            0.003 
    71         -245.417             0.003            0.002 
    72         -245.573             0.003            0.002 
    73         -245.075             0.003            0.002 
    74         -244.981             0.003            0.002 
    75         -244.285             0.003            0.002 
    76         -244.449             0.003            0.002 
    77         -243.017             0.003            0.002 
    78         -243.670             0.003            0.002 
    79         -245.122             0.003            0.002 
    80         -243.971             0.002            0.002 
    81         -244.421             0.002            0.002 
    82         -243.844             0.002            0.002 
    83         -244.424             0.002            0.002 
    84         -245.178             0.002            0.002 
    85         -243.511             0.003            0.002 
    86         -244.607             0.003            0.002 
    87         -244.429             0.003            0.002 
    88         -244.640             0.003            0.002 
    89         -243.497             0.003            0.002 
    90         -243.965             0.003            0.002 
    91         -244.287             0.003            0.002 
    92         -243.915             0.003            0.002 
    93         -244.505             0.003            0.002 
    94         -244.173             0.003            0.002 
    95         -244.043             0.003            0.002 
    96         -245.138             0.003            0.002 
    97         -244.074             0.003            0.002 
    98         -244.150             0.003            0.002 
    99         -244.182             0.003            0.002 
   100         -244.225             0.002            0.002 
   101         -244.632             0.002            0.002 
   102         -244.127             0.002            0.002 
   103         -243.425             0.002            0.002 
   104         -242.757             0.002            0.002 
   105         -244.098             0.002            0.002 
   106         -244.174             0.002            0.002 
   107         -243.546             0.002            0.002 
   108         -243.970             0.002            0.002 
   109         -243.169             0.002            0.002 
   110         -243.301             0.002            0.002 
   111         -243.303             0.002            0.002 
   112         -243.231             0.002            0.002 
   113         -243.230             0.002            0.002 
   114         -243.446             0.002            0.002 
   115         -243.216             0.002            0.002 
   116         -243.044             0.002            0.001 
   117         -243.177             0.001            0.001 
   118         -243.474             0.001            0.001 
   119         -243.427             0.001            0.001 
   120         -243.154             0.001            0.001 
   121         -242.080             0.002            0.001 
   122         -242.738             0.002            0.001 
   123         -242.776             0.001            0.001 
   124         -243.201             0.001            0.001 
   125         -243.535             0.001            0.001 
   126         -242.799             0.001            0.001 
   127         -242.548             0.001            0.001 
   128         -243.367             0.001            0.001 
   129         -243.210             0.001            0.001 
   130         -243.192             0.001            0.001 
   131         -243.247             0.001            0.001 
   132         -242.667             0.001            0.001 
   133         -243.401             0.001            0.001 
   134         -243.711             0.002            0.001 
   135         -243.913             0.002            0.001 
   136         -242.999             0.002            0.001 
   137         -242.753             0.002            0.001 
   138         -243.581             0.002            0.001 
   139         -242.641             0.002            0.002 
   140         -242.783             0.002            0.002 
   141         -242.708             0.002            0.001 
   142         -243.099             0.002            0.001 
   143         -243.576             0.002            0.002 
   144         -242.345             0.002            0.002 
   145         -243.119             0.002            0.002 
   146         -242.281             0.002            0.002 
   147         -240.944             0.002            0.002 
   148         -243.758             0.003            0.002 
   149         -243.326             0.003            0.002 
   150         -242.732             0.003            0.002 
   151         -242.397             0.003            0.002 
   152         -244.308             0.003            0.003 
   153         -241.877             0.004            0.003 
   154         -242.542             0.004            0.003 
   155         -243.165             0.004            0.003 
   156         -243.195             0.004            0.003 
   157         -241.530             0.004            0.003 
   158         -241.271             0.004            0.003 
   159         -243.893             0.004            0.003 
   160         -242.964             0.004            0.003 
   161         -242.300             0.004            0.003 
   162         -243.040             0.004            0.003 
   163         -243.375             0.004            0.003 
   164         -242.861             0.004            0.003 
   165         -242.334             0.004            0.003 
   166         -243.177             0.004            0.003 
   167         -243.215             0.004            0.003 
   168         -243.292             0.003            0.003 
   169         -242.870             0.003            0.003 
   170         -242.853             0.003            0.003 
   171         -243.373             0.003            0.003 
   172         -242.931             0.003            0.002 
   173         -242.139             0.003            0.002 
   174         -241.719             0.003            0.002 
   175         -242.556             0.003            0.002 
   176         -242.259             0.003            0.002 
   177         -242.648             0.002            0.002 
   178         -243.524             0.003            0.002 
   179         -242.684             0.002            0.002 
   180         -242.639             0.002            0.002 
   181         -242.323             0.002            0.002 
   182         -242.659             0.002            0.002 
   183         -242.696             0.002            0.002 
   184         -242.683             0.002            0.002 
   185         -243.215             0.002            0.002 
   186         -242.846             0.002            0.002 
   187         -242.697             0.002            0.002 
   188         -242.234             0.002            0.002 
   189         -242.395             0.002            0.002 
   190         -243.676             0.002            0.002 
   191         -241.462             0.002            0.002 
   192         -243.509             0.003            0.002 
   193         -241.644             0.003            0.002 
   194         -241.640             0.003            0.002 
   195         -243.397             0.003            0.002 
   196         -242.687             0.003            0.002 
   197         -242.832             0.003            0.002 
   198         -241.801             0.003            0.002 
   199         -242.985             0.003            0.002 
   200         -243.506             0.003            0.002 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  3.6 seconds.
[[1]]
[[1]]$w
             [,1]         [,2]        [,3]
 [1,] 0.020953673 0.6835742901 0.295472037
 [2,] 0.999796967 0.0001008396 0.000102193
 [3,] 0.999796967 0.0001008396 0.000102193
 [4,] 0.999796967 0.0001008396 0.000102193
 [5,] 0.999796967 0.0001008396 0.000102193
 [6,] 0.999796967 0.0001008396 0.000102193
 [7,] 0.021451519 0.0303735095 0.948174972
 [8,] 0.021451519 0.0303735095 0.948174972
 [9,] 0.016599207 0.1148158695 0.868584923
[10,] 0.006379114 0.9588370582 0.034783827
[11,] 0.016599207 0.1148158695 0.868584923
[12,] 0.999796967 0.0001008396 0.000102193
[13,] 0.999796967 0.0001008396 0.000102193
[14,] 0.999796967 0.0001008396 0.000102193
[15,] 0.016599207 0.1148158695 0.868584923
[16,] 0.999796967 0.0001008396 0.000102193
[17,] 0.006379114 0.9588370582 0.034783827
[18,] 0.999796967 0.0001008396 0.000102193
[19,] 0.147150095 0.0870077701 0.765842135
[20,] 0.999796967 0.0001008396 0.000102193
[21,] 0.999796967 0.0001008396 0.000102193
[22,] 0.017165642 0.7676649451 0.215169413

[[1]]$tau
[1] 0.8800000 0.0700000 0.6649293

[[1]]$phi
[1] 0.3333333 0.3333333 0.3333333

[[1]]$kappa
[1] 5


ELBO for this run: -320.465
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412182002-1-75615f.csv\n"
init_taus from clustering  0.470717311211857 init_taus from clustering  0.000240922954675365 init_taus from clustering  0.706229907464412 init_taus from clustering  0.995679392796509Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000402 seconds 
1000 transitions using 10 leapfrog steps per transition would take 4.02 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -377.948             1.000            1.000 
     2         -339.683             0.556            1.000 
     3         -326.312             0.385            0.113 
     4         -316.637             0.296            0.113 
     5         -305.378             0.244            0.041 
     6         -298.184             0.208            0.041 
     7         -288.171             0.183            0.037 
     8         -287.433             0.160            0.037 
     9         -287.332             0.143            0.035 
    10         -283.233             0.130            0.035 
    11         -277.328             0.120            0.031 
    12         -275.244             0.111            0.031 
    13         -274.477             0.102            0.024 
    14         -273.361             0.095            0.024 
    15         -270.316             0.090            0.021 
    16         -271.914             0.084            0.021 
    17         -268.443             0.080            0.014 
    18         -267.645             0.076            0.014 
    19         -266.922             0.072            0.013 
    20         -267.451             0.069            0.013 
    21         -262.186             0.020            0.013 
    22         -264.252             0.014            0.011 
    23         -263.823             0.012            0.008 
    24         -261.319             0.011            0.008 
    25         -261.533             0.009            0.008 
    26         -259.862             0.009            0.006 
    27         -257.573             0.007            0.006 
    28         -258.833             0.007            0.006 
    29         -257.444             0.008            0.006 
    30         -256.772             0.007            0.006 
    31         -255.138             0.006            0.006 
    32         -256.602             0.006            0.006 
    33         -255.276             0.006            0.006 
    34         -255.908             0.006            0.006 
    35         -256.035             0.006            0.005 
    36         -254.964             0.006            0.005 
    37         -254.382             0.005            0.005 
    38         -254.649             0.005            0.005 
    39         -253.009             0.005            0.005 
    40         -252.509             0.005            0.005 
    41         -254.383             0.005            0.005 
    42         -253.640             0.004            0.005 
    43         -253.631             0.004            0.005 
    44         -253.767             0.004            0.004 
    45         -252.984             0.004            0.004 
    46         -252.072             0.004            0.004 
    47         -251.876             0.003            0.003 
    48         -250.697             0.003            0.003 
    49         -252.968             0.004            0.003 
    50         -252.866             0.003            0.003 
    51         -252.071             0.003            0.003 
    52         -251.878             0.003            0.003 
    53         -251.464             0.003            0.002 
    54         -250.876             0.003            0.002 
    55         -251.718             0.003            0.003 
    56         -249.915             0.003            0.003 
    57         -250.860             0.003            0.003 
    58         -249.478             0.003            0.003 
    59         -250.227             0.003            0.003 
    60         -251.319             0.003            0.003 
    61         -251.016             0.003            0.003 
    62         -249.979             0.003            0.003 
    63         -249.861             0.003            0.003 
    64         -249.835             0.003            0.003 
    65         -249.788             0.003            0.003 
    66         -250.276             0.003            0.003 
    67         -249.072             0.003            0.003 
    68         -248.620             0.003            0.003 
    69         -249.163             0.003            0.002 
    70         -249.884             0.003            0.003 
    71         -249.282             0.003            0.002 
    72         -250.068             0.003            0.003 
    73         -249.171             0.003            0.003 
    74         -248.394             0.003            0.003 
    75         -248.450             0.003            0.003 
    76         -247.929             0.003            0.003 
    77         -250.012             0.003            0.003 
    78         -249.759             0.003            0.002 
    79         -248.518             0.003            0.002 
    80         -249.108             0.003            0.002 
    81         -248.682             0.003            0.002 
    82         -249.284             0.002            0.002 
    83         -248.715             0.003            0.002 
    84         -249.278             0.003            0.002 
    85         -248.240             0.003            0.002 
    86         -248.328             0.003            0.002 
    87         -248.959             0.003            0.002 
    88         -248.064             0.003            0.002 
    89         -248.553             0.003            0.002 
    90         -246.814             0.003            0.002 
    91         -249.109             0.003            0.003 
    92         -247.812             0.003            0.003 
    93         -246.840             0.003            0.003 
    94         -248.694             0.004            0.003 
    95         -249.083             0.004            0.003 
    96         -247.710             0.004            0.004 
    97         -248.027             0.004            0.003 
    98         -248.736             0.004            0.003 
    99         -247.463             0.004            0.003 
   100         -247.247             0.004            0.003 
   101         -246.229             0.004            0.004 
   102         -246.761             0.004            0.004 
   103         -248.250             0.004            0.004 
   104         -246.940             0.004            0.004 
   105         -247.972             0.004            0.004 
   106         -246.518             0.004            0.004 
   107         -247.622             0.004            0.004 
Chain 1 stan::variational::advi::calc_ELBO: The number of dropped evaluations has reached its maximum amount (100). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  2.6 seconds.
An error occurred during inference: Fitting failed. Unable to retrieve the metadata.
Error processing 01658141-8398-4585-9f0f-8355dd9b0604: object 'tol_rel_obj' not found
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
ℹ Adding segment with index 31 to segments included in the inference.
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
ℹ Adding segment with index 50 to segments included in the inference.
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
init_taus from clustering  0.407551106388624Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000358 seconds 
1000 transitions using 10 leapfrog steps per transition would take 3.58 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -1001.526             1.000            1.000 
     2         -999.540             0.501            1.000 
     3        -1000.213             0.334            0.002 
     4         -999.560             0.251            0.002 
     5         -999.343             0.201            0.001 
     6         -999.291             0.167            0.001 
     7         -999.203             0.143            0.001 
     8         -999.143             0.125            0.001 
     9         -999.247             0.112            0.000 
    10         -999.118             0.100            0.000 
    11         -999.243             0.091            0.000 
    12         -999.311             0.084            0.000 
    13         -999.299             0.077            0.000 
    14         -999.131             0.072            0.000 
    15         -999.194             0.067            0.000 
    16         -999.162             0.063            0.000 
    17         -999.135             0.059            0.000 
    18         -999.152             0.056            0.000 
    19         -999.205             0.053            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  0.9 seconds.
[[1]]
[[1]]$w
     [,1]
[1,]    1
[2,]    1

[[1]]$tau
[1] 0.4075511

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -1000.21
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000359 seconds 
1000 transitions using 10 leapfrog steps per transition would take 3.59 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1         -999.777             1.000            1.000 
     2         -999.518             0.500            1.000 
     3         -999.713             0.333            0.000 
     4         -999.533             0.250            0.000 
     5         -999.383             0.200            0.000 
     6         -999.310             0.167            0.000 
     7         -999.170             0.143            0.000 
     8         -999.457             0.125            0.000 
     9         -999.384             0.111            0.000 
    10         -999.170             0.100            0.000 
    11         -999.242             0.091            0.000 
    12         -999.385             0.083            0.000 
    13         -999.081             0.077            0.000 
    14         -999.418             0.072            0.000 
    15         -999.152             0.067            0.000 
    16         -999.181             0.063            0.000 
    17         -999.187             0.059            0.000 
    18         -999.027             0.056            0.000 
    19         -999.245             0.053            0.000 
    20         -999.132             0.050            0.000 
    21         -999.034             0.000            0.000 
    22         -999.176             0.000            0.000 
    23         -999.103             0.000            0.000 
    24         -999.331             0.000            0.000 
    25         -999.269             0.000            0.000 
    26         -999.069             0.000            0.000 
    27         -999.014             0.000            0.000 
    28         -999.210             0.000            0.000 
    29         -999.154             0.000            0.000 
    30         -999.150             0.000            0.000 
    31         -999.380             0.000            0.000 
    32         -999.130             0.000            0.000 
    33         -998.956             0.000            0.000 
    34         -999.216             0.000            0.000 
    35         -999.207             0.000            0.000 
    36         -999.069             0.000            0.000 
    37         -999.350             0.000            0.000 
    38         -999.092             0.000            0.000 
    39         -999.852             0.000            0.000 
    40         -999.349             0.000            0.000 
    41         -999.138             0.000            0.000 
    42         -999.160             0.000            0.000 
    43         -999.160             0.000            0.000 
    44         -999.067             0.000            0.000 
    45         -999.215             0.000            0.000 
    46         -999.117             0.000            0.000 
    47         -999.378             0.000            0.000 
    48         -999.160             0.000            0.000 
    49         -999.066             0.000            0.000 
    50         -998.994             0.000            0.000 
    51         -999.397             0.000            0.000 
    52         -999.109             0.000            0.000 
    53         -999.090             0.000            0.000 
    54         -999.138             0.000            0.000 
    55         -999.177             0.000            0.000 
    56         -999.245             0.000            0.000 
    57         -999.058             0.000            0.000 
    58         -999.019             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  1.5 seconds.
[[1]]
[[1]]$w
     [,1]
[1,]    1
[2,]    1

[[1]]$tau
[1] 0.5835124

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -999.713
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412182003-1-80f526.csv\n"
init_taus from clustering  0.445768596413148 init_taus from clustering  0.369333616364101Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000623 seconds 
1000 transitions using 10 leapfrog steps per transition would take 6.23 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -1017.661             1.000            1.000 
     2        -1001.479             0.508            1.000 
     3        -1001.354             0.339            0.016 
     4        -1001.354             0.254            0.016 
     5        -1001.474             0.203            0.000 
     6        -1001.617             0.169            0.000 
     7        -1001.328             0.145            0.000 
     8        -1001.381             0.127            0.000 
     9        -1001.221             0.113            0.000 
    10        -1001.382             0.102            0.000 
    11        -1001.203             0.092            0.000 
    12        -1000.983             0.085            0.000 
    13        -1001.372             0.078            0.000 
    14        -1001.131             0.073            0.000 
    15        -1001.377             0.068            0.000 
    16        -1001.079             0.064            0.000 
    17        -1001.743             0.060            0.000 
    18        -1001.531             0.057            0.000 
    19        -1001.520             0.054            0.000 
    20        -1001.101             0.051            0.000 
    21        -1001.558             0.001            0.000 
    22        -1001.127             0.000            0.000 
    23        -1001.221             0.000            0.000 
    24        -1001.416             0.000            0.000 
    25        -1001.136             0.000            0.000 
    26        -1001.105             0.000            0.000 
    27        -1000.993             0.000            0.000 
    28        -1001.163             0.000            0.000 
    29        -1000.897             0.000            0.000 
    30        -1001.149             0.000            0.000 
    31        -1001.477             0.000            0.000 
    32        -1001.284             0.000            0.000 
    33        -1001.386             0.000            0.000 
    34        -1001.498             0.000            0.000 
    35        -1001.196             0.000            0.000 
    36        -1000.953             0.000            0.000 
    37        -1001.436             0.000            0.000 
    38        -1001.173             0.000            0.000 
    39        -1001.271             0.000            0.000 
    40        -1001.278             0.000            0.000 
    41        -1001.737             0.000            0.000 
    42        -1001.707             0.000            0.000 
    43        -1001.258             0.000            0.000 
    44        -1001.245             0.000            0.000 
    45        -1001.080             0.000            0.000 
    46        -1001.066             0.000            0.000 
    47        -1001.292             0.000            0.000 
    48        -1001.432             0.000            0.000 
    49        -1001.349             0.000            0.000 
    50        -1000.870             0.000            0.000 
    51        -1001.392             0.000            0.000 
    52        -1001.243             0.000            0.000 
    53        -1001.578             0.000            0.000 
    54        -1001.239             0.000            0.000 
    55        -1001.206             0.000            0.000 
    56        -1001.053             0.000            0.000 
    57        -1001.297             0.000            0.000 
    58        -1001.468             0.000            0.000 
    59        -1001.164             0.000            0.000 
    60        -1001.241             0.000            0.000 
    61        -1001.355             0.000            0.000 
    62        -1001.400             0.000            0.000 
    63        -1000.817             0.000            0.000 
    64        -1001.029             0.000            0.000 
    65        -1001.648             0.000            0.000 
    66        -1001.349             0.000            0.000 
    67        -1001.472             0.000            0.000 
    68        -1001.007             0.000            0.000 
    69        -1001.750             0.000            0.000 
    70        -1000.976             0.000            0.000 
    71        -1000.946             0.000            0.000 
    72        -1001.495             0.000            0.000 
    73        -1000.856             0.000            0.000 
    74        -1001.539             0.000            0.000 
    75        -1001.174             0.000            0.000 
    76        -1001.186             0.000            0.000 
    77        -1001.001             0.000            0.000 
    78        -1001.241             0.000            0.000 
    79        -1001.235             0.000            0.000 
    80        -1001.213             0.000            0.000 
    81        -1001.104             0.000            0.000 
    82        -1001.423             0.000            0.000 
    83        -1001.108             0.000            0.000 
    84        -1000.905             0.000            0.000 
    85        -1001.214             0.000            0.000 
    86        -1001.059             0.000            0.000 
    87        -1001.081             0.000            0.000 
    88        -1001.298             0.000            0.000 
    89        -1001.455             0.000            0.000 
    90        -1001.483             0.000            0.000 
    91        -1001.470             0.000            0.000 
    92        -1001.733             0.000            0.000 
    93        -1001.000             0.000            0.000 
    94        -1000.953             0.000            0.000 
    95        -1001.309             0.000            0.000 
    96        -1001.324             0.000            0.000 
    97        -1001.080             0.000            0.000 
    98        -1001.259             0.000            0.000 
    99        -1001.301             0.000            0.000 
   100        -1001.135             0.000            0.000 
   101        -1001.166             0.000            0.000 
   102        -1001.240             0.000            0.000 
   103        -1001.031             0.000            0.000 
   104        -1001.117             0.000            0.000 
   105        -1001.274             0.000            0.000 
   106        -1001.292             0.000            0.000 
   107        -1001.572             0.000            0.000 
   108        -1001.150             0.000            0.000 
   109        -1001.302             0.000            0.000 
   110        -1001.203             0.000            0.000 
   111        -1001.337             0.000            0.000 
   112        -1001.000             0.000            0.000 
   113        -1001.043             0.000            0.000 
   114        -1001.544             0.000            0.000 
   115        -1001.021             0.000            0.000 
   116        -1001.483             0.000            0.000 
   117        -1001.331             0.000            0.000 
   118        -1001.357             0.000            0.000 
   119        -1001.497             0.000            0.000 
   120        -1001.047             0.000            0.000 
   121        -1001.216             0.000            0.000 
   122        -1001.710             0.000            0.000 
   123        -1001.092             0.000            0.000 
   124        -1000.880             0.000            0.000 
   125        -1001.266             0.000            0.000 
   126        -1001.614             0.000            0.000 
   127        -1001.280             0.000            0.000 
   128        -1001.202             0.000            0.000 
   129        -1001.447             0.000            0.000 
   130        -1001.248             0.000            0.000 
   131        -1001.754             0.000            0.000 
   132        -1001.693             0.000            0.000 
   133        -1001.029             0.000            0.000 
   134        -1001.410             0.000            0.000 
   135        -1001.726             0.000            0.000 
   136        -1001.169             0.000            0.000 
   137        -1001.362             0.000            0.000 
   138        -1000.986             0.000            0.000 
   139        -1001.244             0.000            0.000 
   140        -1001.299             0.000            0.000 
   141        -1001.016             0.000            0.000 
   142        -1001.059             0.000            0.000 
   143        -1001.261             0.000            0.000 
   144        -1001.177             0.000            0.000 
   145        -1001.522             0.000            0.000 
   146        -1000.909             0.000            0.000 
   147        -1000.825             0.000            0.000 
   148        -1001.483             0.000            0.000 
   149        -1001.086             0.000            0.000 
   150        -1001.063             0.000            0.000 
   151        -1001.500             0.000            0.000 
   152        -1001.360             0.000            0.000 
   153        -1001.114             0.000            0.000 
   154        -1001.730             0.000            0.000 
   155        -1001.156             0.000            0.000 
   156        -1000.957             0.000            0.000 
   157        -1001.245             0.000            0.000 
   158        -1001.216             0.000            0.000 
   159        -1001.452             0.000            0.000 
   160        -1001.163             0.000            0.000 
   161        -1001.015             0.000            0.000 
   162        -1000.810             0.000            0.000 
   163        -1001.312             0.000            0.000 
   164        -1000.999             0.000            0.000 
   165        -1000.998             0.000            0.000 
   166        -1001.824             0.000            0.000 
   167        -1001.248             0.000            0.000 
   168        -1001.119             0.000            0.000 
   169        -1001.061             0.000            0.000 
   170        -1001.130             0.000            0.000 
   171        -1001.084             0.000            0.000 
   172        -1001.008             0.000            0.000 
   173        -1000.977             0.000            0.000 
   174        -1001.237             0.000            0.000 
   175        -1001.295             0.000            0.000 
   176        -1001.074             0.000            0.000 
   177        -1001.453             0.000            0.000 
   178        -1001.510             0.000            0.000 
   179        -1001.008             0.000            0.000 
   180        -1001.178             0.000            0.000 
   181        -1001.194             0.000            0.000 
   182        -1000.827             0.000            0.000 
   183        -1001.366             0.000            0.000 
   184        -1001.405             0.000            0.000 
   185        -1001.115             0.000            0.000 
   186        -1001.154             0.000            0.000 
   187        -1000.882             0.000            0.000 
   188        -1001.400             0.000            0.000 
   189        -1000.929             0.000            0.000 
   190        -1001.324             0.000            0.000 
   191        -1001.116             0.000            0.000 
   192        -1001.113             0.000            0.000 
   193        -1001.387             0.000            0.000 
   194        -1001.299             0.000            0.000 
   195        -1000.987             0.000            0.000 
   196        -1001.262             0.000            0.000 
   197        -1001.304             0.000            0.000 
   198        -1001.254             0.000            0.000 
   199        -1001.273             0.000            0.000 
   200        -1001.137             0.000            0.000 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  6.2 seconds.
[[1]]
[[1]]$w
     [,1] [,2]
[1,]  0.5  0.5
[2,]  0.5  0.5

[[1]]$tau
[1] 0.4457686 0.3693336

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -1001.35
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.000603 seconds 
1000 transitions using 10 leapfrog steps per transition would take 6.03 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1        -1006.038             1.000            1.000 
     2        -1002.553             0.502            1.000 
     3        -1001.822             0.335            0.003 
     4        -1001.468             0.251            0.003 
     5        -1001.546             0.201            0.001 
     6        -1001.108             0.168            0.001 
     7        -1001.352             0.144            0.000 
     8        -1001.392             0.126            0.000 
     9        -1001.294             0.112            0.000 
    10        -1001.565             0.101            0.000 
    11        -1001.177             0.091            0.000 
    12        -1001.337             0.084            0.000 
    13        -1001.443             0.077            0.000 
    14        -1001.179             0.072            0.000 
    15        -1001.058             0.067            0.000 
    16        -1001.378             0.063            0.000 
    17        -1001.570             0.059            0.000 
    18        -1001.537             0.056            0.000 
    19        -1001.094             0.053            0.000 
    20        -1001.460             0.050            0.000 
    21        -1001.611             0.000            0.000 
    22        -1001.479             0.000            0.000 
    23        -1001.583             0.000            0.000 
    24        -1001.432             0.000            0.000 
    25        -1001.091             0.000            0.000 
    26        -1000.979             0.000            0.000 
    27        -1001.326             0.000            0.000 
    28        -1001.009             0.000            0.000 
    29        -1001.449             0.000            0.000 
    30        -1001.202             0.000            0.000 
    31        -1001.711             0.000            0.000 
    32        -1001.010             0.000            0.000 
    33        -1001.166             0.000            0.000 
    34        -1001.031             0.000            0.000 
    35        -1001.269             0.000            0.000 
    36        -1001.268             0.000            0.000 
    37        -1001.005             0.000            0.000 
    38        -1001.705             0.000            0.000 
    39        -1001.244             0.000            0.000 
    40        -1001.257             0.000            0.000 
    41        -1001.011             0.000            0.000 
    42        -1001.286             0.000            0.000 
    43        -1001.401             0.000            0.000 
    44        -1001.605             0.000            0.000 
    45        -1001.196             0.000            0.000 
    46        -1001.115             0.000            0.000 
    47        -1001.334             0.000            0.000 
    48        -1001.225             0.000            0.000 
    49        -1001.199             0.000            0.000 
    50        -1000.978             0.000            0.000 
    51        -1001.314             0.000            0.000 
    52        -1001.488             0.000            0.000 
    53        -1001.244             0.000            0.000 
    54        -1001.277             0.000            0.000 
    55        -1000.941             0.000            0.000 
    56        -1001.006             0.000            0.000 
    57        -1000.996             0.000            0.000 
    58        -1001.237             0.000            0.000 
    59        -1001.164             0.000            0.000 
    60        -1001.323             0.000            0.000 
    61        -1000.929             0.000            0.000 
    62        -1001.105             0.000            0.000 
    63        -1001.174             0.000            0.000 
    64        -1001.303             0.000            0.000 
    65        -1001.336             0.000            0.000 
    66        -1001.718             0.000            0.000 
    67        -1001.710             0.000            0.000 
    68        -1001.329             0.000            0.000 
    69        -1001.108             0.000            0.000 
    70        -1001.249             0.000            0.000 
    71        -1001.062             0.000            0.000 
    72        -1000.918             0.000            0.000 
    73        -1001.263             0.000            0.000 
    74        -1001.325             0.000            0.000 
    75        -1001.133             0.000            0.000 
    76        -1001.227             0.000            0.000 
    77        -1001.550             0.000            0.000 
    78        -1001.060             0.000            0.000 
    79        -1001.104             0.000            0.000 
    80        -1001.478             0.000            0.000 
    81        -1001.160             0.000            0.000 
    82        -1001.853             0.000            0.000 
    83        -1001.237             0.000            0.000 
    84        -1000.973             0.000            0.000 
    85        -1000.983             0.000            0.000 
    86        -1001.225             0.000            0.000 
    87        -1001.261             0.000            0.000 
    88        -1001.122             0.000            0.000 
    89        -1001.196             0.000            0.000 
    90        -1001.306             0.000            0.000 
    91        -1001.293             0.000            0.000 
    92        -1000.898             0.000            0.000 
    93        -1001.242             0.000            0.000 
    94        -1000.930             0.000            0.000 
    95        -1001.107             0.000            0.000 
    96        -1001.616             0.000            0.000 
    97        -1001.486             0.000            0.000 
    98        -1001.286             0.000            0.000 
    99        -1000.878             0.000            0.000 
   100        -1001.305             0.000            0.000 
   101        -1001.326             0.000            0.000 
   102        -1001.135             0.000            0.000 
   103        -1001.071             0.000            0.000 
   104        -1001.148             0.000            0.000 
   105        -1001.529             0.000            0.000 
   106        -1001.153             0.000            0.000 
   107        -1001.108             0.000            0.000 
   108        -1000.715             0.000            0.000 
   109        -1001.539             0.000            0.000 
   110        -1000.748             0.000            0.000 
   111        -1001.101             0.000            0.000 
   112        -1001.070             0.000            0.000 
   113        -1001.343             0.000            0.000 
   114        -1001.707             0.000            0.000 
   115        -1001.681             0.000            0.000 
   116        -1001.449             0.000            0.000 
   117        -1000.819             0.000            0.000 
   118        -1001.144             0.000            0.000 
   119        -1000.881             0.000            0.000 
   120        -1001.143             0.000            0.000 
   121        -1000.997             0.000            0.000 
   122        -1001.570             0.000            0.000 
   123        -1001.552             0.000            0.000 
   124        -1001.466             0.000            0.000 
   125        -1001.456             0.000            0.000 
   126        -1000.937             0.000            0.000 
   127        -1000.930             0.000            0.000 
   128        -1001.112             0.000            0.000 
   129        -1001.311             0.000            0.000 
   130        -1001.362             0.000            0.000 
   131        -1001.646             0.000            0.000 
   132        -1001.055             0.000            0.000 
   133        -1001.180             0.000            0.000 
   134        -1000.868             0.000            0.000 
   135        -1000.909             0.000            0.000 
   136        -1001.128             0.000            0.000 
   137        -1001.840             0.000            0.000 
   138        -1001.500             0.000            0.000 
   139        -1001.198             0.000            0.000 
   140        -1001.440             0.000            0.000 
   141        -1001.387             0.000            0.000 
   142        -1000.937             0.000            0.000 
   143        -1001.007             0.000            0.000 
   144        -1001.333             0.000            0.000 
   145        -1001.166             0.000            0.000 
   146        -1001.232             0.000            0.000 
   147        -1001.286             0.000            0.000 
   148        -1001.420             0.000            0.000 
   149        -1001.098             0.000            0.000 
   150        -1001.055             0.000            0.000 
   151        -1001.117             0.000            0.000 
   152        -1000.719             0.000            0.000 
   153        -1000.868             0.000            0.000 
   154        -1001.651             0.000            0.000 
   155        -1001.178             0.000            0.000 
   156        -1000.922             0.000            0.000 
   157        -1001.543             0.000            0.000 
   158        -1001.121             0.000            0.000 
   159        -1001.533             0.000            0.000 
   160        -1001.292             0.000            0.000 
   161        -1001.649             0.000            0.000 
   162        -1001.285             0.000            0.000 
   163        -1001.143             0.000            0.000 
   164        -1001.214             0.000            0.000 
   165        -1001.123             0.000            0.000 
   166        -1001.279             0.000            0.000 
   167        -1001.270             0.000            0.000 
   168        -1001.541             0.000            0.000 
   169        -1000.989             0.000            0.000 
   170        -1000.879             0.000            0.000 
   171        -1001.332             0.000            0.000 
   172        -1001.490             0.000            0.000 
   173        -1001.315             0.000            0.000 
   174        -1000.753             0.000            0.000 
   175        -1001.727             0.000            0.000 
   176        -1001.165             0.000            0.000 
   177        -1001.353             0.000            0.000 
   178        -1001.469             0.000            0.000 
   179        -1001.055             0.000            0.000 
   180        -1001.479             0.000            0.000 
   181        -1001.264             0.000            0.000 
   182        -1000.774             0.000            0.000 
   183        -1001.902             0.000            0.000 
   184        -1001.072             0.000            0.000 
   185        -1001.921             0.000            0.000 
   186        -1001.578             0.000            0.000 
   187        -1001.160             0.000            0.000 
   188        -1001.230             0.000            0.000 
   189        -1000.875             0.000            0.000 
   190        -1001.175             0.000            0.000 
   191        -1001.152             0.000            0.000 
   192        -1001.468             0.000            0.000 
   193        -1001.046             0.000            0.000 
   194        -1001.266             0.000            0.000 
   195        -1001.021             0.000            0.000 
   196        -1001.261             0.000            0.000 
   197        -1001.459             0.000            0.000 
   198        -1001.364             0.000            0.000 
   199        -1001.387             0.000            0.000 
   200        -1001.034             0.000            0.000 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  5.1 seconds.
[[1]]
[[1]]$w
     [,1] [,2]
[1,]  0.5  0.5
[2,]  0.5  0.5

[[1]]$tau
[1] 0.4325702 0.3601529

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -1001.82
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412182003-1-5b1e6d.csv\n"
[1] "entropy per segment: "
[1] -0.0003319998
[1] "entropy per segment normalized: "
[1] -9.999995e-07
[1] "entropy per segment: "
[1] 104.7649
[1] "entropy per segment normalized: "
[1] 0.315557
# A tibble: 2 × 8
  segment_original_indx segment_name       segment_id karyotype chr   clock_mean
                  <int> <chr>                   <dbl> <chr>     <chr>      <dbl>
1                    31 chr8_68073511_146…          1 2:1       chr8       0.732
2                    50 chr12_75496447_90…          2 2:1       chr12      0.732
# ℹ 2 more variables: clock_low <dbl>, clock_high <dbl>
# A tibble: 2 × 4
      K   BIC Log_lik   ICL
  <int> <dbl>   <dbl> <dbl>
1     1 2012.   -997. 2012.
2     2 2024.   -998. 2250.
ℹ Fitting segment with index 31
Running MCMC with 8 parallel chains...

Chain 1 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 1 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 1 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 1 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 2 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 2 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 2 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 2 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 3 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 3 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 3 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 3 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 4 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 4 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 4 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 4 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 5 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 5 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 5 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 5 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 6 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 6 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 6 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 6 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 7 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 7 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 7 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 8 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 8 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 8 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 5 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 5 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 6 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 6 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 7 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 7 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 8 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 8 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 5 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 5 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 5 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 6 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 6 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 7 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 7 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 8 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 8 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 5 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 5 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 6 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 6 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 6 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 7 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 7 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 7 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 8 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 8 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 5 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 5 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 6 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 6 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 7 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 7 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 8 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 8 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 5 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 5 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 5 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 6 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 6 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 7 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 7 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 8 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 8 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 8 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 5 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 5 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 6 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 6 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 6 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 7 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 7 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 7 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 8 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 8 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 8 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 5 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 5 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 5 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 5 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 6 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 6 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 6 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 6 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 7 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 7 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 8 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 8 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 5 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 5 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 6 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 6 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 7 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 7 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 7 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 7 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 8 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 8 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 8 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 8 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 5 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 5 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 6 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 6 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 7 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 7 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 8 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 8 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 5 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 5 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 6 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 6 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 7 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 7 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 8 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 8 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 5 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 5 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 6 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 6 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 7 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 7 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 8 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 8 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 8 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 5 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 5 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 6 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 6 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 7 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 7 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 7 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 8 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 8 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 5 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 5 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 6 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 6 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 6 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 7 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 7 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 8 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 8 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 8 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 5 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 5 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 6 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 6 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 7 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 7 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 8 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 8 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 5 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 5 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 6 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 6 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 7 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 7 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 8 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 8 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 4 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 5 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 5 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 6 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 6 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 7 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 7 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 7 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 8 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 8 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 8 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 4 finished in 2.0 seconds.
Chain 8 finished in 1.9 seconds.
Chain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 1 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 2 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 3 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 5 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 5 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 6 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 7 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 1 finished in 2.1 seconds.
Chain 2 finished in 2.1 seconds.
Chain 3 finished in 2.1 seconds.
Chain 5 finished in 2.1 seconds.
Chain 6 finished in 2.0 seconds.
Chain 7 finished in 2.0 seconds.

All 8 chains finished successfully.
Mean chain execution time: 2.0 seconds.
Total execution time: 2.3 seconds.

ℹ Fitting segment with index 50
Running MCMC with 8 parallel chains...

Chain 1 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 1 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 1 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 1 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 2 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 2 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 2 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 2 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 3 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 3 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 3 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 3 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 4 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 4 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 4 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 4 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 5 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 5 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 5 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 5 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 5 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 5 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 5 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 5 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 5 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 5 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 5 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 5 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 5 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 5 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 5 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 5 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 5 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 5 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 5 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 5 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 5 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 5 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 5 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 6 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 6 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 6 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 6 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 6 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 6 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 6 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 6 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 6 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 6 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 6 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 6 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 6 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 6 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 6 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 6 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 6 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 6 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 6 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 6 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 7 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 7 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 7 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 7 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 7 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 7 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 7 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 7 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 7 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 7 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 7 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 7 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 7 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 7 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 7 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 7 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 7 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 7 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 7 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 8 Iteration:    1 / 4000 [  0%]  (Warmup) 
Chain 8 Iteration:  100 / 4000 [  2%]  (Warmup) 
Chain 8 Iteration:  200 / 4000 [  5%]  (Warmup) 
Chain 8 Iteration:  300 / 4000 [  7%]  (Warmup) 
Chain 8 Iteration:  400 / 4000 [ 10%]  (Warmup) 
Chain 8 Iteration:  500 / 4000 [ 12%]  (Warmup) 
Chain 8 Iteration:  600 / 4000 [ 15%]  (Warmup) 
Chain 8 Iteration:  700 / 4000 [ 17%]  (Warmup) 
Chain 8 Iteration:  800 / 4000 [ 20%]  (Warmup) 
Chain 8 Iteration:  900 / 4000 [ 22%]  (Warmup) 
Chain 8 Iteration: 1000 / 4000 [ 25%]  (Warmup) 
Chain 8 Iteration: 1100 / 4000 [ 27%]  (Warmup) 
Chain 8 Iteration: 1200 / 4000 [ 30%]  (Warmup) 
Chain 8 Iteration: 1300 / 4000 [ 32%]  (Warmup) 
Chain 8 Iteration: 1400 / 4000 [ 35%]  (Warmup) 
Chain 8 Iteration: 1500 / 4000 [ 37%]  (Warmup) 
Chain 8 Iteration: 1600 / 4000 [ 40%]  (Warmup) 
Chain 8 Iteration: 1700 / 4000 [ 42%]  (Warmup) 
Chain 8 Iteration: 1800 / 4000 [ 45%]  (Warmup) 
Chain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 1 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 2 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 3 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 5 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 5 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 5 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 5 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 5 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 5 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 5 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 5 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 5 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 5 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 5 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 5 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 5 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 5 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 5 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 6 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 6 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 6 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 6 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 6 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 6 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 6 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 6 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 6 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 6 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 6 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 6 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 6 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 6 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 6 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 6 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 6 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 7 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 7 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 7 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 7 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 7 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 7 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 7 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 7 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 7 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 7 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 7 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 7 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 7 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 7 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 7 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 7 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 8 Iteration: 1900 / 4000 [ 47%]  (Warmup) 
Chain 8 Iteration: 2000 / 4000 [ 50%]  (Warmup) 
Chain 8 Iteration: 2001 / 4000 [ 50%]  (Sampling) 
Chain 8 Iteration: 2100 / 4000 [ 52%]  (Sampling) 
Chain 8 Iteration: 2200 / 4000 [ 55%]  (Sampling) 
Chain 8 Iteration: 2300 / 4000 [ 57%]  (Sampling) 
Chain 8 Iteration: 2400 / 4000 [ 60%]  (Sampling) 
Chain 8 Iteration: 2500 / 4000 [ 62%]  (Sampling) 
Chain 8 Iteration: 2600 / 4000 [ 65%]  (Sampling) 
Chain 8 Iteration: 2700 / 4000 [ 67%]  (Sampling) 
Chain 8 Iteration: 2800 / 4000 [ 70%]  (Sampling) 
Chain 8 Iteration: 2900 / 4000 [ 72%]  (Sampling) 
Chain 1 finished in 0.4 seconds.
Chain 2 finished in 0.4 seconds.
Chain 3 finished in 0.4 seconds.
Chain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 4 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 5 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 5 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 5 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 5 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 6 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 6 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 6 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 6 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 6 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 7 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 7 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 7 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 7 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 7 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 7 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 7 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 8 Iteration: 3000 / 4000 [ 75%]  (Sampling) 
Chain 8 Iteration: 3100 / 4000 [ 77%]  (Sampling) 
Chain 8 Iteration: 3200 / 4000 [ 80%]  (Sampling) 
Chain 8 Iteration: 3300 / 4000 [ 82%]  (Sampling) 
Chain 8 Iteration: 3400 / 4000 [ 85%]  (Sampling) 
Chain 8 Iteration: 3500 / 4000 [ 87%]  (Sampling) 
Chain 8 Iteration: 3600 / 4000 [ 90%]  (Sampling) 
Chain 8 Iteration: 3700 / 4000 [ 92%]  (Sampling) 
Chain 8 Iteration: 3800 / 4000 [ 95%]  (Sampling) 
Chain 4 finished in 0.4 seconds.
Chain 5 finished in 0.4 seconds.
Chain 6 finished in 0.4 seconds.
Chain 7 finished in 0.4 seconds.
Chain 8 Iteration: 3900 / 4000 [ 97%]  (Sampling) 
Chain 8 Iteration: 4000 / 4000 [100%]  (Sampling) 
Chain 8 finished in 0.4 seconds.

All 8 chains finished successfully.
Mean chain execution time: 0.4 seconds.
Total execution time: 0.7 seconds.

# A tibble: 2 × 7
  tau_low tau_mean tau_high segment karyotype chr   segment_id             
    <dbl>    <dbl>    <dbl>   <int> <chr>     <chr> <chr>                  
1   0.605    0.720    0.831      31 2:1       chr8  chr8_68073511_146364021
2   0.441    0.696    0.938      50 2:1       chr12 chr12_75496447_90785292
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
ℹ Adding segment with index 65 to segments included in the inference.
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
[1] 98
[1] 99
[1] 100
[1] 101
[1] 102
[1] 103
[1] 104
[1] 105
[1] 106
[1] 107
[1] 108
[1] 109
[1] 110
[1] 111
[1] 112
[1] 113
[1] 114
[1] 115
[1] 116
[1] 117
[1] 118
[1] 119
[1] 120
[1] 121
[1] 122
[1] 123
[1] 124
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
[1] 130
[1] 131
[1] 132
[1] 133
[1] 134
[1] 135
[1] 136
[1] 137
[1] 138
[1] 139
[1] 140
[1] 141
[1] 142
[1] 143
[1] 144
[1] 145
[1] 146
[1] 147
[1] 148
[1] 149
[1] 150
[1] 151
[1] 152
[1] 153
[1] 154
[1] 155
[1] 156
[1] 157
[1] 158
[1] 159
[1] 160
init_taus from clustering  1Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 5e-05 seconds 
1000 transitions using 10 leapfrog steps per transition would take 0.5 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Success! Found best value [eta = 10] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1          -80.919             1.000            1.000 
     2          -39.476             1.025            1.050 
     3          -34.490             0.731            1.000 
     4          -35.536             0.556            1.000 
     5          -28.719             0.492            0.237 
     6          -24.771             0.437            0.237 
     7          -22.213             0.391            0.159 
     8          -22.704             0.345            0.159 
     9          -22.163             0.309            0.145 
    10          -22.477             0.280            0.145 
    11          -22.273             0.255            0.115 
    12          -21.771             0.236            0.115 
    13          -20.744             0.221            0.050 
    14          -20.680             0.206            0.050 
    15          -29.086             0.211            0.050 
    16          -25.488             0.207            0.115 
    17          -23.212             0.201            0.098 
    18          -22.274             0.192            0.098 
    19          -21.380             0.184            0.050 
    20          -20.495             0.177            0.050 
    21          -19.638             0.129            0.044 
    22          -18.852             0.079            0.043 
    23          -18.305             0.073            0.042 
    24          -17.855             0.073            0.042 
    25          -17.812             0.061            0.042 
    26          -17.914             0.053            0.042 
    27          -19.743             0.052            0.042 
    28          -17.419             0.058            0.042 
    29          -16.605             0.059            0.042 
    30          -16.126             0.060            0.042 
    31          -16.429             0.060            0.042 
    32          -15.590             0.062            0.043 
    33          -16.866             0.063            0.043 
    34          -14.889             0.069            0.044 
    35          -14.641             0.056            0.043 
    36          -14.712             0.049            0.042 
    37          -13.776             0.048            0.042 
    38          -14.613             0.048            0.043 
    39          -13.087             0.052            0.044 
    40          -12.901             0.051            0.044 
    41          -18.055             0.063            0.049 
    42          -15.612             0.068            0.054 
    43          -13.692             0.074            0.057 
    44          -12.433             0.078            0.068 
    45          -11.532             0.082            0.076 
    46          -10.668             0.085            0.078 
    47           -9.867             0.085            0.078 
    48           -9.199             0.082            0.076 
    49           -8.892             0.081            0.076 
    50           -8.277             0.083            0.076 
    51           -7.737             0.086            0.076 
    52           -7.276             0.086            0.076 
    53           -7.063             0.084            0.074 
    54           -6.649             0.080            0.073 
    55           -6.632             0.080            0.073 
    56           -6.666             0.080            0.073 
    57           -6.876             0.078            0.073 
    58           -6.768             0.076            0.073 
    59           -6.420             0.073            0.070 
    60           -6.588             0.073            0.070 
    61           -7.336             0.064            0.070 
    62           -9.109             0.066            0.070 
    63           -7.350             0.071            0.070 
    64           -6.926             0.069            0.063 
    65           -6.698             0.067            0.062 
    66           -7.103             0.065            0.061 
    67           -6.494             0.066            0.061 
    68           -6.456             0.063            0.057 
    69           -6.524             0.062            0.057 
    70           -6.739             0.059            0.054 
    71           -6.787             0.056            0.034 
    72           -6.738             0.054            0.032 
    73           -7.088             0.054            0.034 
    74           -6.655             0.055            0.034 
    75           -6.630             0.055            0.034 
    76           -7.187             0.058            0.049 
    77           -6.767             0.060            0.054 
    78           -6.482             0.061            0.054 
    79           -6.548             0.059            0.049 
    80           -6.392             0.059            0.049 
    81           -7.490             0.061            0.049 
    82           -6.617             0.058            0.049 
    83           -6.795             0.047            0.044 
    84           -6.660             0.045            0.034 
    85           -6.577             0.044            0.032 
    86           -7.487             0.048            0.032 
    87           -6.676             0.049            0.032 
    88           -6.615             0.049            0.032 
    89           -6.538             0.049            0.032 
    90           -7.350             0.053            0.044 
    91           -6.714             0.058            0.049 
    92           -6.424             0.059            0.049 
    93           -8.070             0.067            0.062 
    94           -7.041             0.071            0.062 
    95           -6.663             0.074            0.062 
    96           -6.538             0.071            0.057 
    97           -6.251             0.070            0.046 
    98           -6.506             0.070            0.046 
    99           -7.088             0.073            0.057 
   100           -7.608             0.076            0.068 
   101           -6.732             0.075            0.068 
   102           -6.480             0.070            0.057 
   103           -6.732             0.071            0.057 
   104           -6.913             0.071            0.057 
   105           -6.908             0.070            0.057 
   106           -7.910             0.071            0.057 
   107          -10.177             0.076            0.057 
   108           -8.889             0.083            0.068 
   109           -8.235             0.086            0.079 
   110           -7.550             0.085            0.079 
   111           -7.045             0.084            0.072 
   112           -6.786             0.083            0.072 
   113           -6.695             0.074            0.068 
   114           -6.607             0.067            0.057 
   115           -6.926             0.067            0.046 
   116           -6.578             0.068            0.053 
   117           -6.721             0.067            0.053 
   118           -6.633             0.066            0.053 
   119           -6.910             0.064            0.046 
   120           -6.714             0.062            0.040 
   121           -6.522             0.057            0.039 
   122           -6.772             0.057            0.038 
   123           -6.565             0.056            0.038 
   124           -6.318             0.057            0.039 
   125           -6.487             0.058            0.039 
   126           -7.376             0.058            0.039 
   127           -7.040             0.049            0.039 
   128           -6.545             0.046            0.039 
   129           -6.507             0.042            0.038 
   130           -6.863             0.040            0.038 
   131           -6.489             0.039            0.038 
   132           -6.560             0.038            0.037 
   133           -7.259             0.042            0.039 
   134           -6.529             0.047            0.040 
   135           -6.830             0.047            0.040 
   136           -6.382             0.048            0.040 
   137           -6.547             0.048            0.040 
   138           -6.912             0.050            0.044 
   139           -7.163             0.050            0.044 
   140           -6.896             0.050            0.044 
   141           -6.552             0.051            0.048 
   142           -6.555             0.050            0.048 
   143           -6.376             0.049            0.048 
   144           -6.402             0.048            0.048 
   145           -6.487             0.047            0.048 
   146           -6.542             0.041            0.044 
   147           -6.828             0.041            0.042 
   148           -6.468             0.040            0.042 
   149           -7.149             0.045            0.044 
   150           -6.606             0.046            0.044 
   151           -6.286             0.046            0.044 
   152           -6.567             0.047            0.044 
   153           -7.297             0.048            0.044 
   154           -8.274             0.048            0.044 
   155           -7.620             0.050            0.051 
   156           -7.116             0.050            0.051 
   157           -6.718             0.052            0.052 
   158           -6.574             0.050            0.051 
   159           -6.632             0.049            0.051 
   160           -6.754             0.048            0.051 
   161           -6.457             0.048            0.046 
   162           -6.878             0.051            0.051 
   163           -6.597             0.051            0.051 
   164           -6.679             0.052            0.051 
   165           -6.511             0.052            0.051 
   166           -6.508             0.052            0.051 
   167           -6.666             0.051            0.051 
   168           -6.563             0.049            0.046 
   169           -6.726             0.046            0.043 
   170           -7.208             0.045            0.043 
   171           -7.946             0.047            0.043 
   172           -7.247             0.050            0.046 
   173           -6.657             0.049            0.046 
   174           -6.586             0.044            0.043 
   175           -6.595             0.039            0.026 
   176           -6.548             0.036            0.024 
   177           -6.426             0.034            0.024 
   178           -6.462             0.033            0.024 
   179           -6.455             0.033            0.024 
   180           -6.889             0.035            0.024 
   181           -6.736             0.034            0.024 
   182           -6.873             0.032            0.023 
   183           -6.768             0.031            0.020 
   184           -6.497             0.032            0.023 
   185           -6.634             0.032            0.021 
   186           -6.546             0.033            0.021 
   187           -6.486             0.032            0.020 
   188           -6.578             0.032            0.020 
   189           -6.542             0.031            0.019 
   190           -6.535             0.027            0.015 
   191           -6.437             0.024            0.015 
   192           -6.918             0.022            0.015 
   193           -6.426             0.022            0.015 
   194           -6.761             0.024            0.015 
   195           -6.511             0.025            0.019 
   196           -6.428             0.026            0.019 
   197           -6.568             0.026            0.020 
   198           -6.595             0.026            0.020 
   199           -7.657             0.033            0.021 
   200           -6.712             0.037            0.021 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  0.1 seconds.
[[1]]
[[1]]$w
     [,1]
[1,]    1

[[1]]$tau
[1] 0.88

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -34.4896
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 4.7e-05 seconds 
1000 transitions using 10 leapfrog steps per transition would take 0.47 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1           -6.663             1.000            1.000 
     2           -6.554             0.508            1.000 
     3           -6.623             0.342            0.017 
     4           -6.421             0.265            0.031 
     5           -6.501             0.214            0.017 
     6           -6.524             0.179            0.017 
     7           -6.423             0.156            0.016 
     8           -6.517             0.138            0.016 
     9           -6.529             0.123            0.014 
    10           -6.487             0.111            0.014 
    11           -6.383             0.103            0.014 
    12           -6.612             0.097            0.016 
    13           -6.338             0.093            0.016 
    14           -6.354             0.086            0.016 
    15           -6.657             0.084            0.016 
    16           -6.601             0.079            0.016 
    17           -6.437             0.076            0.016 
    18           -6.494             0.072            0.016 
    19           -6.875             0.071            0.016 
    20           -6.483             0.071            0.016 
    21           -6.368             0.022            0.016 
    22           -6.539             0.022            0.016 
    23           -6.460             0.022            0.016 
    24           -6.533             0.021            0.016 
    25           -6.223             0.023            0.016 
    26           -6.538             0.025            0.018 
    27           -6.508             0.025            0.018 
    28           -6.521             0.024            0.018 
    29           -6.511             0.024            0.018 
    30           -6.361             0.025            0.024 
    31           -6.383             0.024            0.024 
    32           -6.401             0.023            0.018 
    33           -6.794             0.023            0.018 
    34           -6.599             0.025            0.024 
    35           -6.313             0.025            0.024 
    36           -6.465             0.025            0.024 
    37           -6.393             0.025            0.024 
    38           -6.526             0.025            0.024 
    39           -6.585             0.023            0.020 
    40           -6.373             0.022            0.020 
    41           -6.374             0.021            0.020 
    42           -6.564             0.021            0.020 
    43           -6.427             0.021            0.021 
    44           -6.543             0.022            0.021 
    45           -6.538             0.019            0.020 
    46           -6.557             0.017            0.018 
    47           -6.534             0.017            0.018 
    48           -6.625             0.018            0.018 
    49           -6.552             0.018            0.018 
    50           -6.625             0.017            0.014 
    51           -6.418             0.019            0.018 
    52           -6.347             0.019            0.018 
    53           -6.566             0.018            0.018 
    54           -6.471             0.017            0.015 
    55           -6.409             0.015            0.014 
    56           -6.383             0.015            0.011 
    57           -6.449             0.014            0.011 
    58           -6.471             0.014            0.011 
    59           -6.266             0.015            0.011 
    60           -6.327             0.014            0.011 
    61           -6.507             0.015            0.011 
    62           -6.361             0.015            0.011 
    63           -6.343             0.014            0.011 
    64           -6.460             0.014            0.011 
    65           -6.494             0.014            0.011 
    66           -6.643             0.015            0.011 
    67           -6.489             0.016            0.014 
    68           -6.387             0.016            0.015 
    69           -6.467             0.016            0.015 
    70           -6.337             0.017            0.016 
    71           -6.281             0.015            0.015 
    72           -6.519             0.017            0.016 
    73           -6.557             0.015            0.015 
    74           -6.580             0.015            0.012 
    75           -6.435             0.015            0.016 
    76           -6.567             0.016            0.018 
    77           -6.626             0.016            0.018 
    78           -6.543             0.017            0.018 
    79           -6.581             0.015            0.016 
    80           -6.638             0.015            0.016 
    81           -6.677             0.014            0.013 
    82           -6.291             0.016            0.013 
    83           -6.528             0.018            0.016 
    84           -6.555             0.017            0.013 
    85           -6.433             0.018            0.016 
    86           -6.582             0.018            0.016 
    87           -6.546             0.017            0.013 
    88           -6.367             0.017            0.013 
    89           -6.232             0.018            0.019 
    90           -6.383             0.018            0.019 
    91           -6.411             0.018            0.019 
    92           -6.434             0.016            0.013 
    93           -6.491             0.016            0.013 
    94           -6.573             0.017            0.013 
    95           -6.403             0.017            0.013 
    96           -6.356             0.016            0.012 
    97           -6.457             0.017            0.013 
    98           -6.652             0.018            0.016 
    99           -6.684             0.017            0.016 
   100           -6.591             0.018            0.016 
   101           -6.552             0.018            0.016 
   102           -6.454             0.015            0.015 
   103           -6.334             0.015            0.015 
   104           -6.529             0.016            0.016 
   105           -6.473             0.015            0.015 
   106           -6.558             0.015            0.014 
   107           -6.615             0.015            0.014 
   108           -6.816             0.015            0.014 
   109           -6.501             0.016            0.014 
   110           -6.454             0.016            0.013 
   111           -6.506             0.016            0.013 
   112           -6.455             0.016            0.013 
   113           -6.377             0.016            0.013 
   114           -6.686             0.018            0.014 
   115           -6.422             0.019            0.014 
   116           -6.406             0.018            0.014 
   117           -6.693             0.020            0.014 
   118           -6.332             0.021            0.014 
   119           -6.396             0.021            0.014 
   120           -6.524             0.022            0.015 
   121           -6.439             0.022            0.015 
   122           -6.517             0.022            0.013 
   123           -6.436             0.022            0.013 
   124           -6.354             0.021            0.013 
   125           -6.459             0.021            0.013 
   126           -6.503             0.021            0.013 
   127           -6.628             0.021            0.013 
   128           -6.618             0.020            0.013 
   129           -6.371             0.019            0.013 
   130           -6.320             0.019            0.013 
   131           -6.440             0.020            0.013 
   132           -6.423             0.020            0.013 
   133           -6.542             0.020            0.016 
   134           -6.487             0.018            0.013 
   135           -6.525             0.016            0.013 
   136           -6.548             0.016            0.013 
   137           -6.526             0.014            0.013 
   138           -6.638             0.012            0.013 
   139           -6.398             0.014            0.013 
   140           -6.344             0.013            0.013 
   141           -6.597             0.014            0.013 
   142           -6.413             0.015            0.013 
   143           -6.552             0.016            0.016 
   144           -6.628             0.016            0.016 
   145           -6.442             0.016            0.017 
   146           -6.388             0.016            0.017 
   147           -6.391             0.015            0.011 
   148           -6.544             0.017            0.017 
   149           -6.391             0.016            0.017 
   150           -6.501             0.016            0.017 
   151           -6.546             0.016            0.017 
   152           -6.732             0.017            0.017 
   153           -6.464             0.018            0.017 
   154           -6.513             0.018            0.017 
   155           -6.337             0.019            0.021 
   156           -6.438             0.020            0.021 
   157           -6.612             0.021            0.023 
   158           -6.441             0.021            0.024 
   159           -6.297             0.021            0.023 
   160           -6.547             0.022            0.024 
   161           -6.278             0.022            0.024 
   162           -6.541             0.023            0.024 
   163           -6.516             0.022            0.024 
   164           -6.244             0.024            0.026 
   165           -6.463             0.024            0.026 
   166           -6.466             0.024            0.026 
   167           -6.660             0.025            0.027 
   168           -6.924             0.026            0.028 
   169           -6.370             0.029            0.028 
   170           -6.461             0.029            0.028 
   171           -6.508             0.029            0.028 
   172           -6.246             0.029            0.029 
   173           -6.462             0.029            0.029 
   174           -6.569             0.029            0.029 
   175           -6.545             0.028            0.029 
   176           -6.409             0.029            0.029 
   177           -6.514             0.028            0.029 
   178           -6.450             0.027            0.029 
   179           -6.492             0.026            0.029 
   180           -6.691             0.026            0.029 
   181           -6.472             0.026            0.029 
   182           -6.356             0.024            0.021 
   183           -6.601             0.026            0.029 
   184           -6.410             0.025            0.029 
   185           -6.638             0.025            0.029 
   186           -6.495             0.026            0.029 
   187           -6.667             0.026            0.026 
   188           -6.720             0.025            0.022 
   189           -6.404             0.023            0.022 
   190           -6.577             0.024            0.026 
   191           -6.262             0.026            0.026 
   192           -6.464             0.025            0.026 
   193           -6.383             0.024            0.026 
   194           -6.472             0.024            0.026 
   195           -6.424             0.024            0.026 
   196           -6.411             0.023            0.026 
   197           -6.344             0.023            0.026 
   198           -6.479             0.023            0.026 
   199           -6.739             0.025            0.026 
   200           -6.290             0.027            0.026 
Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. 
This variational approximation is not guaranteed to be meaningful. 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  0.2 seconds.
[[1]]
[[1]]$w
     [,1]
[1,]    1

[[1]]$tau
[1] 0.88

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -6.62277
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412182003-1-abc579.csv\n"
[1] "entropy per segment: "
[1] -1.999999e-06
[1] "entropy per segment normalized: "
[1] -9.999995e-07
Error processing 0176cf1d-0760-4769-a493-277f4bb7585e: argument is of length zero
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
[1] 11
[1] 12
[1] 13
[1] 14
[1] 15
[1] 16
[1] 17
[1] 18
[1] 19
[1] 20
[1] 21
[1] 22
[1] 23
[1] 24
[1] 25
[1] 26
[1] 27
[1] 28
[1] 29
[1] 30
[1] 31
[1] 32
[1] 33
[1] 34
[1] 35
[1] 36
[1] 37
[1] 38
[1] 39
[1] 40
[1] 41
[1] 42
[1] 43
[1] 44
[1] 45
[1] 46
[1] 47
[1] 48
[1] 49
[1] 50
[1] 51
[1] 52
[1] 53
[1] 54
[1] 55
[1] 56
[1] 57
[1] 58
[1] 59
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
[1] 67
[1] 68
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
[1] 82
[1] 83
[1] 84
[1] 85
[1] 86
[1] 87
[1] 88
[1] 89
[1] 90
[1] 91
[1] 92
[1] 93
[1] 94
[1] 95
[1] 96
[1] 97
[1] 98
[1] 99
[1] 100
[1] 101
[1] 102
[1] 103
[1] 104
[1] 105
[1] 106
[1] 107
[1] 108
[1] 109
[1] 110
[1] 111
[1] 112
[1] 113
[1] 114
[1] 115
[1] 116
[1] 117
[1] 118
[1] 119
[1] 120
[1] 121
[1] 122
[1] 123
[1] 124
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
[1] 130
[1] 131
[1] 132
[1] 133
[1] 134
[1] 135
[1] 136
[1] 137
[1] 138
[1] 139
[1] 140
[1] 141
[1] 142
[1] 143
[1] 144
[1] 145
[1] 146
[1] 147
[1] 148
[1] 149
[1] 150
[1] 151
[1] 152
[1] 153
[1] 154
[1] 155
[1] 156
[1] 157
[1] 158
[1] 159
[1] 160
[1] 161
[1] 162
[1] 163
[1] 164
[1] 165
[1] 166
[1] 167
[1] 168
[1] 169
[1] 170
[1] 171
[1] 172
[1] 173
[1] 174
[1] 175
[1] 176
[1] 177
[1] 178
[1] 179
[1] 180
[1] 181
[1] 182
[1] 183
[1] 184
[1] 185
[1] 186
[1] 187
[1] 188
[1] 189
[1] 190
[1] 191
[1] 192
[1] 193
[1] 194
[1] 195
[1] 196
[1] 197
[1] 198
[1] 199
[1] 200
[1] 201
[1] 202
[1] 203
[1] 204
[1] 205
Error processing 0192d529-7340-45d8-a5f0-249cbb11ca19: No segments respected the constraint to perform the clock inference in this CNAqc object.
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
ℹ Adding segment with index 5 to segments included in the inference.
[1] 6
[1] 7
ℹ Adding segment with index 7 to segments included in the inference.
[1] 8
ℹ Adding segment with index 8 to segments included in the inference.
[1] 9
[1] 10
[1] 11
ℹ Adding segment with index 11 to segments included in the inference.
[1] 12
[1] 13
ℹ Adding segment with index 13 to segments included in the inference.
[1] 14
ℹ Adding segment with index 14 to segments included in the inference.
[1] 15
ℹ Adding segment with index 15 to segments included in the inference.
[1] 16
ℹ Adding segment with index 16 to segments included in the inference.
[1] 17
[1] 18
ℹ Adding segment with index 18 to segments included in the inference.
[1] 19
[1] 20
[1] 21
[1] 22
ℹ Adding segment with index 22 to segments included in the inference.
[1] 23
ℹ Adding segment with index 23 to segments included in the inference.
[1] 24
ℹ Adding segment with index 24 to segments included in the inference.
[1] 25
[1] 26
ℹ Adding segment with index 26 to segments included in the inference.
[1] 27
ℹ Adding segment with index 27 to segments included in the inference.
[1] 28
[1] 29
ℹ Adding segment with index 29 to segments included in the inference.
[1] 30
ℹ Adding segment with index 30 to segments included in the inference.
[1] 31
[1] 32
ℹ Adding segment with index 32 to segments included in the inference.
[1] 33
ℹ Adding segment with index 33 to segments included in the inference.
[1] 34
[1] 35
ℹ Adding segment with index 35 to segments included in the inference.
[1] 36
[1] 37
ℹ Adding segment with index 37 to segments included in the inference.
[1] 38
ℹ Adding segment with index 38 to segments included in the inference.
[1] 39
ℹ Adding segment with index 39 to segments included in the inference.
[1] 40
[1] 41
[1] 42
[1] 43
ℹ Adding segment with index 43 to segments included in the inference.
[1] 44
[1] 45
[1] 46
ℹ Adding segment with index 46 to segments included in the inference.
[1] 47
ℹ Adding segment with index 47 to segments included in the inference.
[1] 48
ℹ Adding segment with index 48 to segments included in the inference.
[1] 49
ℹ Adding segment with index 49 to segments included in the inference.
[1] 50
[1] 51
ℹ Adding segment with index 51 to segments included in the inference.
[1] 52
ℹ Adding segment with index 52 to segments included in the inference.
[1] 53
[1] 54
ℹ Adding segment with index 54 to segments included in the inference.
[1] 55
ℹ Adding segment with index 55 to segments included in the inference.
[1] 56
[1] 57
[1] 58
ℹ Adding segment with index 58 to segments included in the inference.
[1] 59
ℹ Adding segment with index 59 to segments included in the inference.
[1] 60
[1] 61
[1] 62
[1] 63
[1] 64
[1] 65
[1] 66
ℹ Adding segment with index 66 to segments included in the inference.
[1] 67
ℹ Adding segment with index 67 to segments included in the inference.
[1] 68
ℹ Adding segment with index 68 to segments included in the inference.
[1] 69
[1] 70
[1] 71
[1] 72
[1] 73
[1] 74
[1] 75
[1] 76
[1] 77
[1] 78
[1] 79
[1] 80
[1] 81
ℹ Adding segment with index 81 to segments included in the inference.
[1] 82
[1] 83
[1] 84
[1] 85
ℹ Adding segment with index 85 to segments included in the inference.
[1] 86
ℹ Adding segment with index 86 to segments included in the inference.
[1] 87
[1] 88
ℹ Adding segment with index 88 to segments included in the inference.
[1] 89
ℹ Adding segment with index 89 to segments included in the inference.
[1] 90
ℹ Adding segment with index 90 to segments included in the inference.
[1] 91
ℹ Adding segment with index 91 to segments included in the inference.
[1] 92
[1] 93
[1] 94
ℹ Adding segment with index 94 to segments included in the inference.
[1] 95
ℹ Adding segment with index 95 to segments included in the inference.
[1] 96
[1] 97
[1] 98
[1] 99
ℹ Adding segment with index 99 to segments included in the inference.
[1] 100
ℹ Adding segment with index 100 to segments included in the inference.
[1] 101
[1] 102
ℹ Adding segment with index 102 to segments included in the inference.
[1] 103
ℹ Adding segment with index 103 to segments included in the inference.
[1] 104
ℹ Adding segment with index 104 to segments included in the inference.
[1] 105
ℹ Adding segment with index 105 to segments included in the inference.
[1] 106
ℹ Adding segment with index 106 to segments included in the inference.
[1] 107
[1] 108
ℹ Adding segment with index 108 to segments included in the inference.
[1] 109
ℹ Adding segment with index 109 to segments included in the inference.
[1] 110
[1] 111
ℹ Adding segment with index 111 to segments included in the inference.
[1] 112
[1] 113
[1] 114
ℹ Adding segment with index 114 to segments included in the inference.
[1] 115
ℹ Adding segment with index 115 to segments included in the inference.
[1] 116
[1] 117
ℹ Adding segment with index 117 to segments included in the inference.
[1] 118
ℹ Adding segment with index 118 to segments included in the inference.
[1] 119
[1] 120
ℹ Adding segment with index 120 to segments included in the inference.
[1] 121
[1] 122
[1] 123
[1] 124
ℹ Adding segment with index 124 to segments included in the inference.
[1] 125
[1] 126
[1] 127
[1] 128
[1] 129
[1] 130
[1] 131
[1] 132
[1] 133
[1] 134
[1] 135
[1] 136
[1] 137
ℹ Adding segment with index 137 to segments included in the inference.
[1] 138
[1] 139
ℹ Adding segment with index 139 to segments included in the inference.
[1] 140
[1] 141
[1] 142
[1] 143
[1] 144
[1] 145
[1] 146
[1] 147
[1] 148
[1] 149
[1] 150
[1] 151
[1] 152
[1] 153
[1] 154
ℹ Adding segment with index 154 to segments included in the inference.
[1] 155
ℹ Adding segment with index 155 to segments included in the inference.
[1] 156
[1] 157
ℹ Adding segment with index 157 to segments included in the inference.
[1] 158
ℹ Adding segment with index 158 to segments included in the inference.
[1] 159
[1] 160
ℹ Adding segment with index 160 to segments included in the inference.
[1] 161
[1] 162
[1] 163
[1] 164
ℹ Adding segment with index 164 to segments included in the inference.
[1] 165
[1] 166
[1] 167
ℹ Adding segment with index 167 to segments included in the inference.
[1] 168
ℹ Adding segment with index 168 to segments included in the inference.
[1] 169
ℹ Adding segment with index 169 to segments included in the inference.
[1] 170
[1] 171
ℹ Adding segment with index 171 to segments included in the inference.
[1] 172
ℹ Adding segment with index 172 to segments included in the inference.
[1] 173
ℹ Adding segment with index 173 to segments included in the inference.
[1] 174
[1] 175
ℹ Adding segment with index 175 to segments included in the inference.
[1] 176
ℹ Adding segment with index 176 to segments included in the inference.
[1] 177
ℹ Adding segment with index 177 to segments included in the inference.
[1] 178
ℹ Adding segment with index 178 to segments included in the inference.
[1] 179
ℹ Adding segment with index 179 to segments included in the inference.
[1] 180
ℹ Adding segment with index 180 to segments included in the inference.
[1] 181
ℹ Adding segment with index 181 to segments included in the inference.
[1] 182
ℹ Adding segment with index 182 to segments included in the inference.
[1] 183
[1] 184
ℹ Adding segment with index 184 to segments included in the inference.
[1] 185
[1] 186
ℹ Adding segment with index 186 to segments included in the inference.
[1] 187
ℹ Adding segment with index 187 to segments included in the inference.
[1] 188
[1] 189
ℹ Adding segment with index 189 to segments included in the inference.
[1] 190
[1] 191
ℹ Adding segment with index 191 to segments included in the inference.
[1] 192
[1] 193
ℹ Adding segment with index 193 to segments included in the inference.
[1] 194
[1] 195
ℹ Adding segment with index 195 to segments included in the inference.
[1] 196
[1] 197
ℹ Adding segment with index 197 to segments included in the inference.
[1] 198
[1] 199
ℹ Adding segment with index 199 to segments included in the inference.
[1] 200
[1] 201
ℹ Adding segment with index 201 to segments included in the inference.
[1] 202
[1] 203
ℹ Adding segment with index 203 to segments included in the inference.
[1] 204
[1] 205
ℹ Adding segment with index 205 to segments included in the inference.
[1] 206
ℹ Adding segment with index 206 to segments included in the inference.
[1] 207
[1] 208
ℹ Adding segment with index 208 to segments included in the inference.
[1] 209
ℹ Adding segment with index 209 to segments included in the inference.
[1] 210
ℹ Adding segment with index 210 to segments included in the inference.
[1] 211
[1] 212
[1] 213
[1] 214
[1] 215
ℹ Adding segment with index 215 to segments included in the inference.
[1] 216
[1] 217
ℹ Adding segment with index 217 to segments included in the inference.
[1] 218
[1] 219
[1] 220
[1] 221
ℹ Adding segment with index 221 to segments included in the inference.
[1] 222
[1] 223
[1] 224
ℹ Adding segment with index 224 to segments included in the inference.
[1] 225
[1] 226
[1] 227
[1] 228
[1] 229
[1] 230
[1] 231
[1] 232
[1] 233
[1] 234
[1] 235
[1] 236
ℹ Adding segment with index 236 to segments included in the inference.
[1] 237
[1] 238
[1] 239
ℹ Adding segment with index 239 to segments included in the inference.
[1] 240
[1] 241
ℹ Adding segment with index 241 to segments included in the inference.
[1] 242
[1] 243
ℹ Adding segment with index 243 to segments included in the inference.
[1] 244
ℹ Adding segment with index 244 to segments included in the inference.
[1] 245
ℹ Adding segment with index 245 to segments included in the inference.
[1] 246
ℹ Adding segment with index 246 to segments included in the inference.
[1] 247
[1] 248
ℹ Adding segment with index 248 to segments included in the inference.
[1] 249
ℹ Adding segment with index 249 to segments included in the inference.
[1] 250
[1] 251
[1] 252
ℹ Adding segment with index 252 to segments included in the inference.
[1] 253
ℹ Adding segment with index 253 to segments included in the inference.
[1] 254
[1] 255
[1] 256
[1] 257
[1] 258
[1] 259
ℹ Adding segment with index 259 to segments included in the inference.
[1] 260
[1] 261
ℹ Adding segment with index 261 to segments included in the inference.
[1] 262
[1] 263
ℹ Adding segment with index 263 to segments included in the inference.
[1] 264
[1] 265
ℹ Adding segment with index 265 to segments included in the inference.
[1] 266
ℹ Adding segment with index 266 to segments included in the inference.
[1] 267
ℹ Adding segment with index 267 to segments included in the inference.
[1] 268
ℹ Adding segment with index 268 to segments included in the inference.
[1] 269
[1] 270
[1] 271
ℹ Adding segment with index 271 to segments included in the inference.
[1] 272
ℹ Adding segment with index 272 to segments included in the inference.
[1] 273
[1] 274
ℹ Adding segment with index 274 to segments included in the inference.
[1] 275
[1] 276
ℹ Adding segment with index 276 to segments included in the inference.
[1] 277
[1] 278
ℹ Adding segment with index 278 to segments included in the inference.
[1] 279
[1] 280
[1] 281
[1] 282
[1] 283
[1] 284
[1] 285
ℹ Adding segment with index 285 to segments included in the inference.
[1] 286
[1] 287
ℹ Adding segment with index 287 to segments included in the inference.
[1] 288
ℹ Adding segment with index 288 to segments included in the inference.
[1] 289
ℹ Adding segment with index 289 to segments included in the inference.
[1] 290
ℹ Adding segment with index 290 to segments included in the inference.
[1] 291
ℹ Adding segment with index 291 to segments included in the inference.
[1] 292
[1] 293
ℹ Adding segment with index 293 to segments included in the inference.
[1] 294
ℹ Adding segment with index 294 to segments included in the inference.
[1] 295
ℹ Adding segment with index 295 to segments included in the inference.
[1] 296
ℹ Adding segment with index 296 to segments included in the inference.
[1] 297
ℹ Adding segment with index 297 to segments included in the inference.
[1] 298
ℹ Adding segment with index 298 to segments included in the inference.
[1] 299
[1] 300
ℹ Adding segment with index 300 to segments included in the inference.
[1] 301
ℹ Adding segment with index 301 to segments included in the inference.
[1] 302
ℹ Adding segment with index 302 to segments included in the inference.
[1] 303
[1] 304
ℹ Adding segment with index 304 to segments included in the inference.
[1] 305
[1] 306
ℹ Adding segment with index 306 to segments included in the inference.
[1] 307
[1] 308
ℹ Adding segment with index 308 to segments included in the inference.
[1] 309
[1] 310
ℹ Adding segment with index 310 to segments included in the inference.
[1] 311
[1] 312
ℹ Adding segment with index 312 to segments included in the inference.
[1] 313
[1] 314
[1] 315
[1] 316
ℹ Adding segment with index 316 to segments included in the inference.
[1] 317
[1] 318
[1] 319
[1] 320
ℹ Adding segment with index 320 to segments included in the inference.
[1] 321
[1] 322
ℹ Adding segment with index 322 to segments included in the inference.
[1] 323
ℹ Adding segment with index 323 to segments included in the inference.
[1] 324
ℹ Adding segment with index 324 to segments included in the inference.
[1] 325
[1] 326
ℹ Adding segment with index 326 to segments included in the inference.
[1] 327
[1] 328
[1] 329
[1] 330
[1] 331
ℹ Adding segment with index 331 to segments included in the inference.
[1] 332
[1] 333
ℹ Adding segment with index 333 to segments included in the inference.
[1] 334
ℹ Adding segment with index 334 to segments included in the inference.
[1] 335
ℹ Adding segment with index 335 to segments included in the inference.
[1] 336
[1] 337
ℹ Adding segment with index 337 to segments included in the inference.
[1] 338
ℹ Adding segment with index 338 to segments included in the inference.
[1] 339
[1] 340
ℹ Adding segment with index 340 to segments included in the inference.
[1] 341
[1] 342
[1] 343
[1] 344
[1] 345
[1] 346
[1] 347
[1] 348
ℹ Adding segment with index 348 to segments included in the inference.
[1] 349
[1] 350
[1] 351
ℹ Adding segment with index 351 to segments included in the inference.
[1] 352
ℹ Adding segment with index 352 to segments included in the inference.
[1] 353
[1] 354
ℹ Adding segment with index 354 to segments included in the inference.
[1] 355
[1] 356
ℹ Adding segment with index 356 to segments included in the inference.
[1] 357
[1] 358
[1] 359
ℹ Adding segment with index 359 to segments included in the inference.
[1] 360
[1] 361
[1] 362
[1] 363
[1] 364
ℹ Adding segment with index 364 to segments included in the inference.
[1] 365
ℹ Adding segment with index 365 to segments included in the inference.
[1] 366
[1] 367
[1] 368
[1] 369
[1] 370
[1] 371
ℹ Adding segment with index 371 to segments included in the inference.
[1] 372
[1] 373
ℹ Adding segment with index 373 to segments included in the inference.
[1] 374
ℹ Adding segment with index 374 to segments included in the inference.
[1] 375
[1] 376
[1] 377
ℹ Adding segment with index 377 to segments included in the inference.
[1] 378
[1] 379
[1] 380
ℹ Adding segment with index 380 to segments included in the inference.
[1] 381
ℹ Adding segment with index 381 to segments included in the inference.
[1] 382
[1] 383
[1] 384
[1] 385
ℹ Adding segment with index 385 to segments included in the inference.
[1] 386
[1] 387
[1] 388
[1] 389
[1] 390
[1] 391
[1] 392
[1] 393
init_taus from clustering  0.300543914784966Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.010018 seconds 
1000 transitions using 10 leapfrog steps per transition would take 100.18 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -38100.211             1.000            1.000 
     2       -37572.325             0.507            1.000 
     3       -37512.430             0.339            0.014 
     4       -37493.609             0.254            0.014 
     5       -37493.449             0.203            0.002 
     6       -37483.609             0.169            0.002 
     7       -37466.021             0.145            0.001 
     8       -37472.689             0.127            0.001 
     9       -37481.306             0.113            0.000 
    10       -37460.424             0.102            0.001 
    11       -37463.348             0.093            0.000 
    12       -37472.561             0.085            0.000 
    13       -37460.913             0.078            0.000 
    14       -37457.947             0.073            0.000 
    15       -37458.505             0.068            0.000 
    16       -37454.840             0.064            0.000 
    17       -37459.166             0.060            0.000 
    18       -37448.684             0.057            0.000 
    19       -37453.132             0.054            0.000 
    20       -37453.294             0.051            0.000 
    21       -37457.030             0.001            0.000 
    22       -37446.652             0.000            0.000 
    23       -37447.180             0.000            0.000 
    24       -37447.028             0.000            0.000 
    25       -37444.558             0.000            0.000 
    26       -37446.619             0.000            0.000 
    27       -37445.303             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  32.2 seconds.
[[1]]
[[1]]$w
       [,1]
  [1,]    1
  [2,]    1
  [3,]    1
  [4,]    1
  [5,]    1
  [6,]    1
  [7,]    1
  [8,]    1
  [9,]    1
 [10,]    1
 [11,]    1
 [12,]    1
 [13,]    1
 [14,]    1
 [15,]    1
 [16,]    1
 [17,]    1
 [18,]    1
 [19,]    1
 [20,]    1
 [21,]    1
 [22,]    1
 [23,]    1
 [24,]    1
 [25,]    1
 [26,]    1
 [27,]    1
 [28,]    1
 [29,]    1
 [30,]    1
 [31,]    1
 [32,]    1
 [33,]    1
 [34,]    1
 [35,]    1
 [36,]    1
 [37,]    1
 [38,]    1
 [39,]    1
 [40,]    1
 [41,]    1
 [42,]    1
 [43,]    1
 [44,]    1
 [45,]    1
 [46,]    1
 [47,]    1
 [48,]    1
 [49,]    1
 [50,]    1
 [51,]    1
 [52,]    1
 [53,]    1
 [54,]    1
 [55,]    1
 [56,]    1
 [57,]    1
 [58,]    1
 [59,]    1
 [60,]    1
 [61,]    1
 [62,]    1
 [63,]    1
 [64,]    1
 [65,]    1
 [66,]    1
 [67,]    1
 [68,]    1
 [69,]    1
 [70,]    1
 [71,]    1
 [72,]    1
 [73,]    1
 [74,]    1
 [75,]    1
 [76,]    1
 [77,]    1
 [78,]    1
 [79,]    1
 [80,]    1
 [81,]    1
 [82,]    1
 [83,]    1
 [84,]    1
 [85,]    1
 [86,]    1
 [87,]    1
 [88,]    1
 [89,]    1
 [90,]    1
 [91,]    1
 [92,]    1
 [93,]    1
 [94,]    1
 [95,]    1
 [96,]    1
 [97,]    1
 [98,]    1
 [99,]    1
[100,]    1
[101,]    1
[102,]    1
[103,]    1
[104,]    1
[105,]    1
[106,]    1
[107,]    1
[108,]    1
[109,]    1
[110,]    1
[111,]    1
[112,]    1
[113,]    1
[114,]    1
[115,]    1
[116,]    1
[117,]    1
[118,]    1
[119,]    1
[120,]    1
[121,]    1
[122,]    1
[123,]    1
[124,]    1
[125,]    1
[126,]    1
[127,]    1
[128,]    1
[129,]    1
[130,]    1
[131,]    1
[132,]    1
[133,]    1
[134,]    1
[135,]    1
[136,]    1
[137,]    1
[138,]    1
[139,]    1
[140,]    1
[141,]    1
[142,]    1
[143,]    1
[144,]    1
[145,]    1
[146,]    1
[147,]    1
[148,]    1
[149,]    1
[150,]    1
[151,]    1
[152,]    1
[153,]    1
[154,]    1
[155,]    1
[156,]    1
[157,]    1
[158,]    1
[159,]    1
[160,]    1
[161,]    1
[162,]    1
[163,]    1
[164,]    1
[165,]    1
[166,]    1
[167,]    1
[168,]    1
[169,]    1
[170,]    1
[171,]    1
[172,]    1
[173,]    1
[174,]    1

[[1]]$tau
[1] 0.3005439

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -37512.4
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.010671 seconds 
1000 transitions using 10 leapfrog steps per transition would take 106.71 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -37892.711             1.000            1.000 
     2       -37520.538             0.505            1.000 
     3       -37495.154             0.337            0.010 
     4       -37499.018             0.253            0.010 
     5       -37498.456             0.202            0.001 
     6       -37497.535             0.168            0.001 
     7       -37510.343             0.144            0.000 
     8       -37478.418             0.126            0.001 
     9       -37482.548             0.112            0.000 
    10       -37474.934             0.101            0.000 
    11       -37490.499             0.092            0.000 
    12       -37472.164             0.084            0.000 
    13       -37471.330             0.078            0.000 
    14       -37463.262             0.072            0.000 
    15       -37468.215             0.068            0.000 
    16       -37463.288             0.063            0.000 
    17       -37464.324             0.060            0.000 
    18       -37463.251             0.056            0.000 
    19       -37461.901             0.053            0.000 
    20       -37460.108             0.051            0.000 
    21       -37461.199             0.001            0.000 
    22       -37459.198             0.000            0.000 
    23       -37457.848             0.000            0.000 
    24       -37462.438             0.000            0.000 
    25       -37459.982             0.000            0.000 
    26       -37456.547             0.000            0.000 
    27       -37463.820             0.000            0.000 
    28       -37453.114             0.000            0.000 
    29       -37447.664             0.000            0.000 
    30       -37449.202             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  33.5 seconds.
[[1]]
[[1]]$w
       [,1]
  [1,]    1
  [2,]    1
  [3,]    1
  [4,]    1
  [5,]    1
  [6,]    1
  [7,]    1
  [8,]    1
  [9,]    1
 [10,]    1
 [11,]    1
 [12,]    1
 [13,]    1
 [14,]    1
 [15,]    1
 [16,]    1
 [17,]    1
 [18,]    1
 [19,]    1
 [20,]    1
 [21,]    1
 [22,]    1
 [23,]    1
 [24,]    1
 [25,]    1
 [26,]    1
 [27,]    1
 [28,]    1
 [29,]    1
 [30,]    1
 [31,]    1
 [32,]    1
 [33,]    1
 [34,]    1
 [35,]    1
 [36,]    1
 [37,]    1
 [38,]    1
 [39,]    1
 [40,]    1
 [41,]    1
 [42,]    1
 [43,]    1
 [44,]    1
 [45,]    1
 [46,]    1
 [47,]    1
 [48,]    1
 [49,]    1
 [50,]    1
 [51,]    1
 [52,]    1
 [53,]    1
 [54,]    1
 [55,]    1
 [56,]    1
 [57,]    1
 [58,]    1
 [59,]    1
 [60,]    1
 [61,]    1
 [62,]    1
 [63,]    1
 [64,]    1
 [65,]    1
 [66,]    1
 [67,]    1
 [68,]    1
 [69,]    1
 [70,]    1
 [71,]    1
 [72,]    1
 [73,]    1
 [74,]    1
 [75,]    1
 [76,]    1
 [77,]    1
 [78,]    1
 [79,]    1
 [80,]    1
 [81,]    1
 [82,]    1
 [83,]    1
 [84,]    1
 [85,]    1
 [86,]    1
 [87,]    1
 [88,]    1
 [89,]    1
 [90,]    1
 [91,]    1
 [92,]    1
 [93,]    1
 [94,]    1
 [95,]    1
 [96,]    1
 [97,]    1
 [98,]    1
 [99,]    1
[100,]    1
[101,]    1
[102,]    1
[103,]    1
[104,]    1
[105,]    1
[106,]    1
[107,]    1
[108,]    1
[109,]    1
[110,]    1
[111,]    1
[112,]    1
[113,]    1
[114,]    1
[115,]    1
[116,]    1
[117,]    1
[118,]    1
[119,]    1
[120,]    1
[121,]    1
[122,]    1
[123,]    1
[124,]    1
[125,]    1
[126,]    1
[127,]    1
[128,]    1
[129,]    1
[130,]    1
[131,]    1
[132,]    1
[133,]    1
[134,]    1
[135,]    1
[136,]    1
[137,]    1
[138,]    1
[139,]    1
[140,]    1
[141,]    1
[142,]    1
[143,]    1
[144,]    1
[145,]    1
[146,]    1
[147,]    1
[148,]    1
[149,]    1
[150,]    1
[151,]    1
[152,]    1
[153,]    1
[154,]    1
[155,]    1
[156,]    1
[157,]    1
[158,]    1
[159,]    1
[160,]    1
[161,]    1
[162,]    1
[163,]    1
[164,]    1
[165,]    1
[166,]    1
[167,]    1
[168,]    1
[169,]    1
[170,]    1
[171,]    1
[172,]    1
[173,]    1
[174,]    1

[[1]]$tau
[1] 0.3717373

[[1]]$phi
[1] 1

[[1]]$kappa
[1] 5


ELBO for this run: -37495.2
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412182004-1-57b9ba.csv\n"
init_taus from clustering  0.199272099838314 init_taus from clustering  0.507786639899857Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.017077 seconds 
1000 transitions using 10 leapfrog steps per transition would take 170.77 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -38003.851             1.000            1.000 
     2       -37929.476             0.501            1.000 
     3       -38027.433             0.335            0.003 
     4       -37682.664             0.253            0.009 
     5       -37644.072             0.203            0.003 
     6       -37605.539             0.169            0.003 
     7       -37613.259             0.145            0.002 
     8       -37582.627             0.127            0.002 
     9       -37571.077             0.113            0.001 
    10       -37562.913             0.102            0.001 
    11       -37561.557             0.092            0.001 
    12       -37550.737             0.085            0.001 
    13       -37539.973             0.078            0.001 
    14       -37548.248             0.073            0.001 
    15       -37555.640             0.068            0.000 
    16       -37535.594             0.064            0.001 
    17       -37530.965             0.060            0.000 
    18       -37533.238             0.057            0.000 
    19       -37519.405             0.054            0.000 
    20       -37523.246             0.051            0.000 
    21       -37524.654             0.001            0.000 
    22       -37515.839             0.001            0.000 
    23       -37509.664             0.001            0.000 
    24       -37520.878             0.000            0.000 
    25       -37508.402             0.000            0.000 
    26       -37506.555             0.000            0.000 
    27       -37507.537             0.000            0.000 
    28       -37506.716             0.000            0.000 
    29       -37503.328             0.000            0.000 
    30       -37502.279             0.000            0.000 
    31       -37492.407             0.000            0.000 
    32       -37500.481             0.000            0.000 
    33       -37514.838             0.000            0.000 
    34       -37494.912             0.000            0.000 
    35       -37500.995             0.000            0.000 
    36       -37499.836             0.000            0.000 
    37       -37491.564             0.000            0.000 
    38       -37491.793             0.000            0.000 
    39       -37488.067             0.000            0.000 
    40       -37492.357             0.000            0.000 
    41       -37486.253             0.000            0.000 
    42       -37486.917             0.000            0.000 
    43       -37484.836             0.000            0.000 
    44       -37484.630             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  102.5 seconds.
[[1]]
[[1]]$w
               [,1]         [,2]
  [1,] 0.9979720398 0.0020279602
  [2,] 0.0504243405 0.9495756595
  [3,] 0.9905802915 0.0094197085
  [4,] 0.8666162529 0.1333837471
  [5,] 0.6454250667 0.3545749333
  [6,] 0.8193719736 0.1806280264
  [7,] 0.0007566673 0.9992433327
  [8,] 0.2233912257 0.7766087743
  [9,] 0.8822066960 0.1177933040
 [10,] 0.0301290594 0.9698709406
 [11,] 0.9825847129 0.0174152871
 [12,] 0.4503047093 0.5496952907
 [13,] 0.9909242319 0.0090757681
 [14,] 0.6280080269 0.3719919731
 [15,] 0.9970875526 0.0029124474
 [16,] 0.8666162529 0.1333837471
 [17,] 0.9998919898 0.0001080102
 [18,] 0.4341066550 0.5658933450
 [19,] 0.9853572587 0.0146427413
 [20,] 0.9624051314 0.0375948686
 [21,] 0.8666162529 0.1333837471
 [22,] 0.8666162529 0.1333837471
 [23,] 0.8666162529 0.1333837471
 [24,] 0.6280080269 0.3719919731
 [25,] 0.9455164466 0.0544835534
 [26,] 0.9996339829 0.0003660171
 [27,] 0.9812050414 0.0187949586
 [28,] 0.9441008327 0.0558991673
 [29,] 0.8666162529 0.1333837471
 [30,] 0.8666162529 0.1333837471
 [31,] 0.8666162529 0.1333837471
 [32,] 0.9934005251 0.0065994749
 [33,] 0.9825847129 0.0174152871
 [34,] 0.8255457937 0.1744542063
 [35,] 0.8593276143 0.1406723857
 [36,] 0.9784248674 0.0215751326
 [37,] 0.3058121046 0.6941878954
 [38,] 0.7133702850 0.2866297150
 [39,] 0.8678956640 0.1321043360
 [40,] 0.0005346499 0.9994653501
 [41,] 0.2742847307 0.7257152693
 [42,] 0.8666162529 0.1333837471
 [43,] 0.2233912257 0.7766087743
 [44,] 0.0285513324 0.9714486676
 [45,] 0.0007566673 0.9992433327
 [46,] 0.1281249430 0.8718750570
 [47,] 0.0370887419 0.9629112581
 [48,] 0.8666162529 0.1333837471
 [49,] 0.0007566673 0.9992433327
 [50,] 0.8666162529 0.1333837471
 [51,] 0.1914164498 0.8085835502
 [52,] 0.8666162529 0.1333837471
 [53,] 0.9970875526 0.0029124474
 [54,] 0.4341066550 0.5658933450
 [55,] 0.2233912257 0.7766087743
 [56,] 0.9984315070 0.0015684930
 [57,] 0.0118347784 0.9881652216
 [58,] 0.6280080269 0.3719919731
 [59,] 0.8678956640 0.1321043360
 [60,] 0.1036950235 0.8963049765
 [61,] 0.0184573638 0.9815426362
 [62,] 0.9902233212 0.0097766788
 [63,] 0.9998919898 0.0001080102
 [64,] 0.6184221430 0.3815778570
 [65,] 0.9350918857 0.0649081143
 [66,] 0.9271270437 0.0728729563
 [67,] 0.8666162529 0.1333837471
 [68,] 0.9012024246 0.0987975754
 [69,] 0.8271758679 0.1728241321
 [70,] 0.6691212547 0.3308787453
 [71,] 0.9870181164 0.0129818836
 [72,] 0.0163284911 0.9836715089
 [73,] 0.0118347784 0.9881652216
 [74,] 0.1621656807 0.8378343193
 [75,] 0.1956840380 0.8043159620
 [76,] 0.8678956640 0.1321043360
 [77,] 0.4574585157 0.5425414843
 [78,] 0.8255457937 0.1744542063
 [79,] 0.9333875120 0.0666124880
 [80,] 0.4503047093 0.5496952907
 [81,] 0.9490337633 0.0509662367
 [82,] 0.3271153485 0.6728846515
 [83,] 0.2233912257 0.7766087743
 [84,] 0.9931628978 0.0068371022
 [85,] 0.6953135192 0.3046864808
 [86,] 0.9624051314 0.0375948686
 [87,] 0.9998919898 0.0001080102
 [88,] 0.9780725175 0.0219274825
 [89,] 0.8666162529 0.1333837471
 [90,] 0.9637499581 0.0362500419
 [91,] 0.5836281829 0.4163718171
 [92,] 0.9849192339 0.0150807661
 [93,] 0.3628644500 0.6371355500
 [94,] 0.2233912257 0.7766087743
 [95,] 0.4516483027 0.5483516973
 [96,] 0.8449156127 0.1550843873
 [97,] 0.4419223777 0.5580776223
 [98,] 0.8666162529 0.1333837471
 [99,] 0.2456757196 0.7543242804
[100,] 0.6774106816 0.3225893184
[101,] 0.8666162529 0.1333837471
[102,] 0.7904523229 0.2095476771
[103,] 0.9784248674 0.0215751326
[104,] 0.9513715584 0.0486284416
[105,] 0.8666162529 0.1333837471
[106,] 0.9533921419 0.0466078581
[107,] 0.9766726426 0.0233273574
[108,] 0.9885885456 0.0114114544
[109,] 0.9449940476 0.0550059524
[110,] 0.7723991589 0.2276008411
[111,] 0.1323915214 0.8676084786
[112,] 0.8255457937 0.1744542063
[113,] 0.5296887083 0.4703112917
[114,] 0.8666162529 0.1333837471
[115,] 0.0515069577 0.9484930423
[116,] 0.1036950235 0.8963049765
[117,] 0.6280080269 0.3719919731
[118,] 0.8484755339 0.1515244661
[119,] 0.4844177134 0.5155822866
[120,] 0.8666162529 0.1333837471
[121,] 0.8380929352 0.1619070648
[122,] 0.9942277702 0.0057722298
[123,] 0.9801992247 0.0198007753
[124,] 0.9719082051 0.0280917949
[125,] 0.8929175284 0.1070824716
[126,] 0.9807964302 0.0192035698
[127,] 0.9909242319 0.0090757681
[128,] 0.7813463188 0.2186536812
[129,] 0.1036950235 0.8963049765
[130,] 0.9952894497 0.0047105503
[131,] 0.4341066550 0.5658933450
[132,] 0.3189028015 0.6810971985
[133,] 0.9105876078 0.0894123922
[134,] 0.9894812983 0.0105187017
[135,] 0.8666162529 0.1333837471
[136,] 0.9402616018 0.0597383982
[137,] 0.9837935949 0.0162064051
[138,] 0.7745403062 0.2254596938
[139,] 0.8400595796 0.1599404204
[140,] 0.8666162529 0.1333837471
[141,] 0.6075193664 0.3924806336
[142,] 0.0362369788 0.9637630212
[143,] 0.1036950235 0.8963049765
[144,] 0.4831698824 0.5168301176
[145,] 0.9105876078 0.0894123922
[146,] 0.9905802915 0.0094197085
[147,] 0.1036950235 0.8963049765
[148,] 0.9905802915 0.0094197085
[149,] 0.3807653527 0.6192346473
[150,] 0.0504243405 0.9495756595
[151,] 0.8666162529 0.1333837471
[152,] 0.1914164498 0.8085835502
[153,] 0.9934005251 0.0065994749
[154,] 0.5854636222 0.4145363778
[155,] 0.0001060370 0.9998939630
[156,] 0.9624051314 0.0375948686
[157,] 0.2917171818 0.7082828182
[158,] 0.8666162529 0.1333837471
[159,] 0.1064104553 0.8935895447
[160,] 0.9053214857 0.0946785143
[161,] 0.0624584903 0.9375415097
[162,] 0.0285513324 0.9714486676
[163,] 0.2200349503 0.7799650497
[164,] 0.0097402205 0.9902597795
[165,] 0.2200349503 0.7799650497
[166,] 0.0826857928 0.9173142072
[167,] 0.9825847129 0.0174152871
[168,] 0.9991570015 0.0008429985
[169,] 0.9771283561 0.0228716439
[170,] 0.9934005251 0.0065994749
[171,] 0.9624051314 0.0375948686
[172,] 0.8064767037 0.1935232963
[173,] 0.1692409922 0.8307590078
[174,] 0.9822391347 0.0177608653

[[1]]$tau
[1] 0.1992721 0.5077866

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -38027.4
Attempt 2 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.017888 seconds 
1000 transitions using 10 leapfrog steps per transition would take 178.88 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -38195.969             1.000            1.000 
     2       -37629.191             0.508            1.000 
     3       -37613.567             0.338            0.015 
     4       -37596.466             0.254            0.015 
     5       -37568.458             0.203            0.001 
     6       -37557.468             0.169            0.001 
     7       -37555.772             0.145            0.000 
     8       -37547.126             0.127            0.000 
     9       -37535.092             0.113            0.000 
    10       -37532.071             0.102            0.000 
    11       -37527.080             0.093            0.000 
    12       -37522.232             0.085            0.000 
    13       -37524.398             0.078            0.000 
    14       -37519.282             0.073            0.000 
    15       -37521.711             0.068            0.000 
    16       -37512.625             0.064            0.000 
    17       -37513.635             0.060            0.000 
    18       -37509.220             0.057            0.000 
    19       -37497.717             0.054            0.000 
    20       -37503.573             0.051            0.000 
    21       -37499.962             0.001            0.000 
    22       -37495.277             0.000            0.000 
    23       -37492.195             0.000            0.000 
    24       -37493.765             0.000            0.000 
    25       -37496.145             0.000            0.000 
    26       -37493.411             0.000            0.000 
    27       -37492.552             0.000            0.000 
    28       -37484.437             0.000            0.000 
    29       -37484.833             0.000            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  92.2 seconds.
[[1]]
[[1]]$w
               [,1]         [,2]
  [1,] 0.9979720398 0.0020279602
  [2,] 0.0504243405 0.9495756595
  [3,] 0.9905802915 0.0094197085
  [4,] 0.8666162529 0.1333837471
  [5,] 0.6454250667 0.3545749333
  [6,] 0.8193719736 0.1806280264
  [7,] 0.0007566673 0.9992433327
  [8,] 0.2233912257 0.7766087743
  [9,] 0.8822066960 0.1177933040
 [10,] 0.0301290594 0.9698709406
 [11,] 0.9825847129 0.0174152871
 [12,] 0.4503047093 0.5496952907
 [13,] 0.9909242319 0.0090757681
 [14,] 0.6280080269 0.3719919731
 [15,] 0.9970875526 0.0029124474
 [16,] 0.8666162529 0.1333837471
 [17,] 0.9998919898 0.0001080102
 [18,] 0.4341066550 0.5658933450
 [19,] 0.9853572587 0.0146427413
 [20,] 0.9624051314 0.0375948686
 [21,] 0.8666162529 0.1333837471
 [22,] 0.8666162529 0.1333837471
 [23,] 0.8666162529 0.1333837471
 [24,] 0.6280080269 0.3719919731
 [25,] 0.9455164466 0.0544835534
 [26,] 0.9996339829 0.0003660171
 [27,] 0.9812050414 0.0187949586
 [28,] 0.9441008327 0.0558991673
 [29,] 0.8666162529 0.1333837471
 [30,] 0.8666162529 0.1333837471
 [31,] 0.8666162529 0.1333837471
 [32,] 0.9934005251 0.0065994749
 [33,] 0.9825847129 0.0174152871
 [34,] 0.8255457937 0.1744542063
 [35,] 0.8593276143 0.1406723857
 [36,] 0.9784248674 0.0215751326
 [37,] 0.3058121046 0.6941878954
 [38,] 0.7133702850 0.2866297150
 [39,] 0.8678956640 0.1321043360
 [40,] 0.0005346499 0.9994653501
 [41,] 0.2742847307 0.7257152693
 [42,] 0.8666162529 0.1333837471
 [43,] 0.2233912257 0.7766087743
 [44,] 0.0285513324 0.9714486676
 [45,] 0.0007566673 0.9992433327
 [46,] 0.1281249430 0.8718750570
 [47,] 0.0370887419 0.9629112581
 [48,] 0.8666162529 0.1333837471
 [49,] 0.0007566673 0.9992433327
 [50,] 0.8666162529 0.1333837471
 [51,] 0.1914164498 0.8085835502
 [52,] 0.8666162529 0.1333837471
 [53,] 0.9970875526 0.0029124474
 [54,] 0.4341066550 0.5658933450
 [55,] 0.2233912257 0.7766087743
 [56,] 0.9984315070 0.0015684930
 [57,] 0.0118347784 0.9881652216
 [58,] 0.6280080269 0.3719919731
 [59,] 0.8678956640 0.1321043360
 [60,] 0.1036950235 0.8963049765
 [61,] 0.0184573638 0.9815426362
 [62,] 0.9902233212 0.0097766788
 [63,] 0.9998919898 0.0001080102
 [64,] 0.6184221430 0.3815778570
 [65,] 0.9350918857 0.0649081143
 [66,] 0.9271270437 0.0728729563
 [67,] 0.8666162529 0.1333837471
 [68,] 0.9012024246 0.0987975754
 [69,] 0.8271758679 0.1728241321
 [70,] 0.6691212547 0.3308787453
 [71,] 0.9870181164 0.0129818836
 [72,] 0.0163284911 0.9836715089
 [73,] 0.0118347784 0.9881652216
 [74,] 0.1621656807 0.8378343193
 [75,] 0.1956840380 0.8043159620
 [76,] 0.8678956640 0.1321043360
 [77,] 0.4574585157 0.5425414843
 [78,] 0.8255457937 0.1744542063
 [79,] 0.9333875120 0.0666124880
 [80,] 0.4503047093 0.5496952907
 [81,] 0.9490337633 0.0509662367
 [82,] 0.3271153485 0.6728846515
 [83,] 0.2233912257 0.7766087743
 [84,] 0.9931628978 0.0068371022
 [85,] 0.6953135192 0.3046864808
 [86,] 0.9624051314 0.0375948686
 [87,] 0.9998919898 0.0001080102
 [88,] 0.9780725175 0.0219274825
 [89,] 0.8666162529 0.1333837471
 [90,] 0.9637499581 0.0362500419
 [91,] 0.5836281829 0.4163718171
 [92,] 0.9849192339 0.0150807661
 [93,] 0.3628644500 0.6371355500
 [94,] 0.2233912257 0.7766087743
 [95,] 0.4516483027 0.5483516973
 [96,] 0.8449156127 0.1550843873
 [97,] 0.4419223777 0.5580776223
 [98,] 0.8666162529 0.1333837471
 [99,] 0.2456757196 0.7543242804
[100,] 0.6774106816 0.3225893184
[101,] 0.8666162529 0.1333837471
[102,] 0.7904523229 0.2095476771
[103,] 0.9784248674 0.0215751326
[104,] 0.9513715584 0.0486284416
[105,] 0.8666162529 0.1333837471
[106,] 0.9533921419 0.0466078581
[107,] 0.9766726426 0.0233273574
[108,] 0.9885885456 0.0114114544
[109,] 0.9449940476 0.0550059524
[110,] 0.7723991589 0.2276008411
[111,] 0.1323915214 0.8676084786
[112,] 0.8255457937 0.1744542063
[113,] 0.5296887083 0.4703112917
[114,] 0.8666162529 0.1333837471
[115,] 0.0515069577 0.9484930423
[116,] 0.1036950235 0.8963049765
[117,] 0.6280080269 0.3719919731
[118,] 0.8484755339 0.1515244661
[119,] 0.4844177134 0.5155822866
[120,] 0.8666162529 0.1333837471
[121,] 0.8380929352 0.1619070648
[122,] 0.9942277702 0.0057722298
[123,] 0.9801992247 0.0198007753
[124,] 0.9719082051 0.0280917949
[125,] 0.8929175284 0.1070824716
[126,] 0.9807964302 0.0192035698
[127,] 0.9909242319 0.0090757681
[128,] 0.7813463188 0.2186536812
[129,] 0.1036950235 0.8963049765
[130,] 0.9952894497 0.0047105503
[131,] 0.4341066550 0.5658933450
[132,] 0.3189028015 0.6810971985
[133,] 0.9105876078 0.0894123922
[134,] 0.9894812983 0.0105187017
[135,] 0.8666162529 0.1333837471
[136,] 0.9402616018 0.0597383982
[137,] 0.9837935949 0.0162064051
[138,] 0.7745403062 0.2254596938
[139,] 0.8400595796 0.1599404204
[140,] 0.8666162529 0.1333837471
[141,] 0.6075193664 0.3924806336
[142,] 0.0362369788 0.9637630212
[143,] 0.1036950235 0.8963049765
[144,] 0.4831698824 0.5168301176
[145,] 0.9105876078 0.0894123922
[146,] 0.9905802915 0.0094197085
[147,] 0.1036950235 0.8963049765
[148,] 0.9905802915 0.0094197085
[149,] 0.3807653527 0.6192346473
[150,] 0.0504243405 0.9495756595
[151,] 0.8666162529 0.1333837471
[152,] 0.1914164498 0.8085835502
[153,] 0.9934005251 0.0065994749
[154,] 0.5854636222 0.4145363778
[155,] 0.0001060370 0.9998939630
[156,] 0.9624051314 0.0375948686
[157,] 0.2917171818 0.7082828182
[158,] 0.8666162529 0.1333837471
[159,] 0.1064104553 0.8935895447
[160,] 0.9053214857 0.0946785143
[161,] 0.0624584903 0.9375415097
[162,] 0.0285513324 0.9714486676
[163,] 0.2200349503 0.7799650497
[164,] 0.0097402205 0.9902597795
[165,] 0.2200349503 0.7799650497
[166,] 0.0826857928 0.9173142072
[167,] 0.9825847129 0.0174152871
[168,] 0.9991570015 0.0008429985
[169,] 0.9771283561 0.0228716439
[170,] 0.9934005251 0.0065994749
[171,] 0.9624051314 0.0375948686
[172,] 0.8064767037 0.1935232963
[173,] 0.1692409922 0.8307590078
[174,] 0.9822391347 0.0177608653

[[1]]$tau
[1] 0.2400835 0.5227494

[[1]]$phi
[1] 0.5 0.5

[[1]]$kappa
[1] 5


ELBO for this run: -37613.6
[1] "output_files /tmp/Rtmpyyp8eS/timing_mixed_simple-diagnostic-202412182006-1-ce4b90.csv\n"
init_taus from clustering  0.0397922068805185 init_taus from clustering  0.300380485512464 init_taus from clustering  0.630213892875199Attempt 1 of 2
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.025759 seconds 
1000 transitions using 10 leapfrog steps per transition would take 257.59 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
     1       -38428.280             1.000            1.000 
     2       -38076.499             0.505            1.000 
     3       -37804.270             0.339            0.009 
     4       -37740.047             0.255            0.009 
     5       -37708.349             0.204            0.007 
     6       -37674.816             0.170            0.007 
     7       -37665.256             0.146            0.002 
     8       -37652.962             0.128            0.002 
     9       -37621.957             0.113            0.001 
    10       -37622.497             0.102            0.001 
    11       -37613.047             0.093            0.001 
    12       -37614.759             0.085            0.001 
    13       -37614.493             0.079            0.001 
    14       -37591.542             0.073            0.001 
    15       -37596.728             0.068            0.001 
    16       -37594.337             0.064            0.001 
    17       -37591.769             0.060            0.000 
    18       -37582.820             0.057            0.000 
    19       -37569.937             0.054            0.000 
    20       -37567.546             0.051            0.000 
    21       -37565.564             0.001            0.000 
    22       -37566.057             0.001            0.000 
    23       -37560.499             0.000            0.000 
